[
  {
    "objectID": "Take-Home_Exercise/Take-Home_Exercise01/TE01.html",
    "href": "Take-Home_Exercise/Take-Home_Exercise01/TE01.html",
    "title": "Take-Home Exercise 01",
    "section": "",
    "text": "This report investigates the drivers of income inequality and socio-economic mobility among rural informal labourers in Northern Vietnam. Using tidyverse for sophisticated data wrangling and ggplot2 for high-dimensional visual analytics, the study progresses from structural disparities to the psychological drivers of economic transition.\n\nMacro Context & Distribution: Mapping regional demographics and the concentration of income across quintiles to establish a baseline of inequality.\nStructural Gaps: Examining how ethnicity and gender intersect with livelihood strategies to create systemic earning gaps.\nMicro-Level Productivity Drivers: Quantifying the marginal returns of education, vocational training, and technology access on daily wage efficiency.\nSocial Outlook & Aspiration: Synthesizing material living conditions (housing) with policy perceptions to identify the “Aspiration Awakening”—the link between asset stability and the desire for economic transition."
  },
  {
    "objectID": "Take-Home_Exercise/Take-Home_Exercise01/TE01.html#overview",
    "href": "Take-Home_Exercise/Take-Home_Exercise01/TE01.html#overview",
    "title": "Take-Home Exercise 01",
    "section": "",
    "text": "This report investigates the drivers of income inequality and socio-economic mobility among rural informal labourers in Northern Vietnam. Using tidyverse for sophisticated data wrangling and ggplot2 for high-dimensional visual analytics, the study progresses from structural disparities to the psychological drivers of economic transition.\n\nMacro Context & Distribution: Mapping regional demographics and the concentration of income across quintiles to establish a baseline of inequality.\nStructural Gaps: Examining how ethnicity and gender intersect with livelihood strategies to create systemic earning gaps.\nMicro-Level Productivity Drivers: Quantifying the marginal returns of education, vocational training, and technology access on daily wage efficiency.\nSocial Outlook & Aspiration: Synthesizing material living conditions (housing) with policy perceptions to identify the “Aspiration Awakening”—the link between asset stability and the desire for economic transition."
  },
  {
    "objectID": "Take-Home_Exercise/Take-Home_Exercise01/TE01.html#getting-started",
    "href": "Take-Home_Exercise/Take-Home_Exercise01/TE01.html#getting-started",
    "title": "Take-Home Exercise 01",
    "section": "1 Getting Started",
    "text": "1 Getting Started\n\n1.1 Installing and loading the packages\n\n\n\n\n\n\n\nLibrary\nDescription\n\n\n\n\ntidyverse\nA collection of core packages designed for data science, used extensively for data preparation and wrangling.\n\n\nreadxl\nAllows R to read Excel files (.xlsx).\n\n\npatchwork\nFor arranging multiple ggplot2 figures into a composite figure.\n\n\npatchwork\nAn R package used to combine separate ggplot2 objects into a unified, multi-panel layout using an intuitive mathematical syntax.\n\n\nggthemes\nProvides extra themes, geoms, and scales for ggplot2.\n\n\nscales\nSupplies scale functions and tools for customizing axes, labels, and legends in ggplot2.\n\n\nggdist\nAn extension of ggplot2 for visualising distributions and uncertainty, useful for half-violin or raincloud plots.\n\n\n\n\npacman::p_load(tidyverse, readxl, patchwork, ggthemes, scales, ggdist,DescTools, ggpubr)\n\n\n\n1.2 Analytical Framework\nThis section outlines the end-to-end research pipeline developed for this study. The workflow integrates systematic data wrangling, advanced feature engineering—such as the derivation of the Daily Wage and Aspiration Index—and multidimensional visual analytics.\n\n\nCode\nflowchart TB\n\n%% ==========================================\n%% 1. Professional Style Definitions\n%% ==========================================\nclassDef data fill:none,stroke:#8e9aaf,stroke-width:1.5px,color:#333333;\nclassDef proc fill:none,stroke:#8e9aaf,stroke-width:1.5px,color:#333333;\nclassDef feat fill:none,stroke:#547d9d,stroke-width:2.5px,color:#547d9d;\nclassDef out  fill:none,stroke:#547d9d,stroke-width:2.5px,color:#547d9d;\n\n%% ==========================================\n%% 2. Data Pipeline Logic\n%% ==========================================\nA[\"Raw survey dataset&lt;br/&gt;725 obs × 30 vars\"]:::data\n  --&gt; B[\"Import Excel&lt;br/&gt;read_excel()\"]:::data\n\n%% --- Subgraph 1: Processing (Invisible) ---\nsubgraph S1 [\" \"]\n  direction LR\n  B --&gt; C[\"Data Selection&lt;br/&gt;& Audit\"]:::proc\n  C --&gt; D[\"Data Wrangling&lt;br/&gt;& Recoding\"]:::proc\nend\n\n%% --- Subgraph 2: Features (Invisible) ---\nsubgraph S2 [\" \"]\n  direction LR\n  D --&gt; J[\"Daily Wage&lt;br/&gt;(Productivity)\"]:::feat\n  D --&gt; K[\"Income Shares&lt;br/&gt;(Composition)\"]:::feat\n  D --&gt; L[\"Aspiration Index&lt;br/&gt;(Social Outlook)\"]:::feat\nend\n\n%% --- Subgraph 3: Analysis (Invisible) ---\nsubgraph S3 [\" \"]\n  direction TB\n  J --&gt; M[\"2.1 Macro context\"]:::out\n  K --&gt; N[\"2.2 Inequality\"]:::out\n  J --&gt; O[\"2.3 Structural gaps\"]:::out\n  K --&gt; P[\"2.4 Composition\"]:::out\n  J --&gt; Q[\"2.5 Micro drivers\"]:::out\n  L --&gt; R[\"2.6 Social outlook\"]:::out\nend\n\n%%\nM & N & O & P & Q & R --&gt; Z[\"Synthesis & Conclusion&lt;br/&gt;(Strategic Recommendations)\"]:::out\n\n%% ==========================================\n%% 3. Hide Subgraph Borders & Backgrounds\n%% ==========================================\nstyle S1 fill:none,stroke:none\nstyle S2 fill:none,stroke:none\nstyle S3 fill:none,stroke:none\n\n\n\n\n\nflowchart TB\n\n%% ==========================================\n%% 1. Professional Style Definitions\n%% ==========================================\nclassDef data fill:none,stroke:#8e9aaf,stroke-width:1.5px,color:#333333;\nclassDef proc fill:none,stroke:#8e9aaf,stroke-width:1.5px,color:#333333;\nclassDef feat fill:none,stroke:#547d9d,stroke-width:2.5px,color:#547d9d;\nclassDef out  fill:none,stroke:#547d9d,stroke-width:2.5px,color:#547d9d;\n\n%% ==========================================\n%% 2. Data Pipeline Logic\n%% ==========================================\nA[\"Raw survey dataset&lt;br/&gt;725 obs × 30 vars\"]:::data\n  --&gt; B[\"Import Excel&lt;br/&gt;read_excel()\"]:::data\n\n%% --- Subgraph 1: Processing (Invisible) ---\nsubgraph S1 [\" \"]\n  direction LR\n  B --&gt; C[\"Data Selection&lt;br/&gt;& Audit\"]:::proc\n  C --&gt; D[\"Data Wrangling&lt;br/&gt;& Recoding\"]:::proc\nend\n\n%% --- Subgraph 2: Features (Invisible) ---\nsubgraph S2 [\" \"]\n  direction LR\n  D --&gt; J[\"Daily Wage&lt;br/&gt;(Productivity)\"]:::feat\n  D --&gt; K[\"Income Shares&lt;br/&gt;(Composition)\"]:::feat\n  D --&gt; L[\"Aspiration Index&lt;br/&gt;(Social Outlook)\"]:::feat\nend\n\n%% --- Subgraph 3: Analysis (Invisible) ---\nsubgraph S3 [\" \"]\n  direction TB\n  J --&gt; M[\"2.1 Macro context\"]:::out\n  K --&gt; N[\"2.2 Inequality\"]:::out\n  J --&gt; O[\"2.3 Structural gaps\"]:::out\n  K --&gt; P[\"2.4 Composition\"]:::out\n  J --&gt; Q[\"2.5 Micro drivers\"]:::out\n  L --&gt; R[\"2.6 Social outlook\"]:::out\nend\n\n%%\nM & N & O & P & Q & R --&gt; Z[\"Synthesis & Conclusion&lt;br/&gt;(Strategic Recommendations)\"]:::out\n\n%% ==========================================\n%% 3. Hide Subgraph Borders & Backgrounds\n%% ==========================================\nstyle S1 fill:none,stroke:none\nstyle S2 fill:none,stroke:none\nstyle S3 fill:none,stroke:none\n\n\n\n\n\n\n\n\n1.3 Data Import\nThe dataset used in this study is derived from a socio-economic survey of 725 informal labourers across five provinces in the Northern Mountainous Region of Vietnam. The data consists of 725 observations and 30 variables, categorized into six key dimensions: Characteristics (C), Income Types (T), Impact Factors (F), Living Conditions (L), Policy Opinions (P), and Social Assessments (A).\n\nraw_df &lt;- read_excel(\"data/Upload for elsiver.xlsx\",\n                     sheet = 1,\n                     na = c(\"\", \"NA\"))\n\n\n\n1.4 Filtering data for selected variables\nTo ensure a focused analysis, a subset of variables was extracted from the raw dataset, covering six critical socio-economic dimensions:\n\nDemographics (CPRO, CGEN, CRAC): Capturing province, gender, and ethnicity to identify structural grouping.\nIncome Profiles (TEIN, TAIN, TSII, TOIN): Identifying total income and its breakdown across agriculture, service, and other sectors.\nHuman Capital & Credit (FEDU, FVTP, FCRA, FTAP): Measuring education, vocational training, credit access, and technology adoption.\nLabor Supply (LWDA): Recording working days to calculate daily wage efficiency.\nPolicy & Wellbeing (PPO, ARO4): Assessing respondent perceptions of rural development policies and self-reported wellbeing improvements.\nLiving Conditions (LHO): Using housing characteristics as a proxy for material asset stability.\n\n\nselected_df &lt;- raw_df %&gt;%\n  select(\n    CPRO, CGEN, CRAC, CJOB, CQUI,        \n    TEIN, TAIN, TSII, TOIN,              \n    FEDU, FVTP, FCRA, FTAP,              \n    LWDA,                                \n    starts_with(\"PPO\"),                  \n    ARO4,                                \n    starts_with(\"LHO\")                \n  )\n\n\n\n1.5 Data Preprocessing\n\n1.5.1 Checking Duplicate Rows\nUsing the duplicated() function to see whether there are duplicate entries in the data.\n\nraw_dup &lt;- raw_df[duplicated(raw_df), ]\nraw_dup\n\n# A tibble: 2 × 30\n   CPRO CGEN   CRAC  CJOB  CQUI  TEIN  TAIN  TSII  TOIN  FEDU  FVTP  FCRA  FTAP\n  &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     3 1         2     1     4    26    26     0     0     0     1     1     1\n2     5 1         1     1     5    18     7    11     0     0     1     1     1\n# ℹ 17 more variables: LHO1 &lt;dbl&gt;, LHO2 &lt;dbl&gt;, LHO3 &lt;dbl&gt;, LHO4 &lt;dbl&gt;,\n#   LCRE &lt;dbl&gt;, LSAV &lt;dbl&gt;, LWDA &lt;dbl&gt;, PPO1 &lt;dbl&gt;, PPO2 &lt;dbl&gt;, PPO3 &lt;dbl&gt;,\n#   PPO4 &lt;dbl&gt;, PPO5 &lt;dbl&gt;, ARO1 &lt;dbl&gt;, ARO2 &lt;dbl&gt;, ARO3 &lt;dbl&gt;, ARO4 &lt;chr&gt;,\n#   ARO5 &lt;dbl&gt;\n\n\n\nsel_dup &lt;- selected_df[duplicated(selected_df), ]\nsel_dup\n\n# A tibble: 5 × 24\n   CPRO CGEN   CRAC  CJOB  CQUI  TEIN  TAIN  TSII  TOIN  FEDU  FVTP  FCRA  FTAP\n  &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     3 1         2     1     5    24    24     0     0     0     1     1     1\n2     3 1         2     1     5    22    22     0     0     0     1     1     1\n3     3 1         2     1     5    22    22     0     0     0     1     1     1\n4     3 1         2     1     4    26    26     0     0     0     1     1     1\n5     5 1         1     1     5    18     7    11     0     0     1     1     1\n# ℹ 11 more variables: LWDA &lt;dbl&gt;, PPO1 &lt;dbl&gt;, PPO2 &lt;dbl&gt;, PPO3 &lt;dbl&gt;,\n#   PPO4 &lt;dbl&gt;, PPO5 &lt;dbl&gt;, ARO4 &lt;chr&gt;, LHO1 &lt;dbl&gt;, LHO2 &lt;dbl&gt;, LHO3 &lt;dbl&gt;,\n#   LHO4 &lt;dbl&gt;\n\n\n\n\n\n\n\n\nNote\n\n\n\nInterpretation of duplicates\nWe checked duplicates at two levels:\n\nraw_df: duplicates here indicate exactly repeated records across all variables (data-entry duplication).\nselected_df: duplicates here may arise because, after selecting a subset of variables, multiple respondents can share identical profiles on the selected features (projection duplicates).\n\nSince this is a survey dataset without respondent IDs, and projection duplicates can legitimately reflect homogeneous socio-economic profiles in the target population, we retain all records to avoid artificially altering the sample distribution.\n\n\n\n\n1.5.2 Checking Missing Value\n\nna_summary &lt;- selected_df %&gt;%\n  summarise(across(everything(), ~sum(is.na(.)))) %&gt;%\n  pivot_longer(everything(),\n               names_to = \"variable\",\n               values_to = \"na_count\") %&gt;%\n  arrange(desc(na_count))\n\nna_summary\n\n# A tibble: 24 × 2\n   variable na_count\n   &lt;chr&gt;       &lt;int&gt;\n 1 LHO4          653\n 2 LHO3          616\n 3 LHO1          512\n 4 LHO2          402\n 5 PPO2          230\n 6 PPO1          209\n 7 LWDA          160\n 8 ARO4          111\n 9 PPO5          106\n10 FTAP          102\n# ℹ 14 more rows\n\n\n\n\n1.5.3 Renaming Columns and Transforming Feature\nFor categorical grouping variables, missing values are retained as an explicit category (“Unknown”) to preserve the full income distribution and avoid unnecessary sample loss.\n\n\nCode\nclean_df &lt;- selected_df %&gt;%\n  \n  # 1) Listwise deletion on core income metric\n  filter(!is.na(TEIN)) %&gt;%\n  \n  # 2) Rename columns first (more readable downstream)\n  rename(\n    total_income         = TEIN,\n    agri_income          = TAIN,\n    service_industry_inc = TSII,\n    other_income         = TOIN,\n    working_days         = LWDA,\n    policy_training      = PPO1,\n    policy_agri_chain    = PPO2,\n    policy_healthcare    = PPO3,\n    policy_elderly_care  = PPO4,\n    policy_urban_jobs    = PPO5,\n    wellbeing_improve    = ARO4,\n    house_cottage        = LHO1,\n    house_roofed         = LHO2,\n    house_solid          = LHO3,\n    house_buildings      = LHO4\n  ) %&gt;%\n  \n  # 3) Binary indicators: NA -&gt; 0\n  mutate(across(starts_with(\"house_\"),\n                ~replace_na(as.numeric(.), 0))) %&gt;%\n  \n  # 4) PPO series: NA -&gt; \"Not Answered\"\n  mutate(across(starts_with(\"policy_\"),\n                ~replace_na(as.character(.), \"Not Answered\"))) %&gt;%\n  \n  # 5) Recode coded variables into factors (and explicitly keep missing as \"Unknown\")\n  mutate(\n    province = factor(CPRO, levels = 1:5,\n                      labels = c(\"Tuyen Quang\", \"Quang Ninh\", \"Ha Giang\", \"Yen Bai\", \"Bac Giang\")),\n    \n    gender = factor(CGEN, levels = c(1, 2),\n                    labels = c(\"Male\", \"Female\")) |&gt; \n      forcats::fct_explicit_na(\"Unknown\"),\n    \n    race = factor(CRAC, levels = c(1, 2),\n                  labels = c(\"Kinh\", \"Minority\")) |&gt;\n      forcats::fct_explicit_na(\"Unknown\"),\n    \n    job_type = factor(CJOB, levels = c(1, 2, 3),\n                      labels = c(\"Agricultural\", \"Service/Industrial\", \"Other\")) |&gt;\n      forcats::fct_explicit_na(\"Unknown\"),\n    \n    # Keep income group order from lowest -&gt; top (useful for plots)\n    income_group = factor(CQUI, levels = c(5, 4, 3, 2, 1),\n                          labels = c(\"Lowest\", \"Second\", \"Middle\", \"Fourth\", \"Top\")) |&gt;\n      forcats::fct_explicit_na(\"Unknown\"),\n    \n    education = factor(FEDU, levels = c(0, 1, 2, 3),\n                       labels = c(\"Primary\", \"Lower secondary\", \"Upper secondary\", \"Other\")) |&gt;\n      forcats::fct_explicit_na(\"Unknown\"),\n    \n    training_status = factor(FVTP, levels = c(1, 2),\n                             labels = c(\"Short course\", \"Long course\")) |&gt;\n      forcats::fct_explicit_na(\"Unknown\"),\n    \n    credit_status = factor(FCRA, levels = c(1, 2),\n                           labels = c(\"Inaccessible\", \"Accessible\")) |&gt;\n      forcats::fct_explicit_na(\"Unknown\"),\n    \n    tech_level = factor(FTAP, levels = c(1, 2),\n                        labels = c(\"Low\", \"Adequate\")) |&gt;\n      forcats::fct_explicit_na(\"Unknown\"),\n    \n    # Convert binary house indicators to factor labels\n    across(starts_with(\"house_\"),\n           ~factor(.x, levels = c(0, 1), labels = c(\"No\", \"Yes\"))),\n    \n    # Recode wellbeing (ARO4) if it's numeric 1-5; otherwise keep Unknown\n    wellbeing_improve = replace_na(as.character(wellbeing_improve), \"Unknown\"),\n    wellbeing_improve = case_when(\n      wellbeing_improve == \"1\" ~ \"Strongly Disagree\",\n      wellbeing_improve == \"2\" ~ \"Disagree\",\n      wellbeing_improve == \"3\" ~ \"Neutral\",\n      wellbeing_improve == \"4\" ~ \"Agree\",\n      wellbeing_improve == \"5\" ~ \"Strongly Agree\",\n      TRUE ~ \"Unknown\"\n    ) %&gt;% factor(levels = c(\"Strongly Disagree\",\"Disagree\",\"Neutral\",\"Agree\",\"Strongly Agree\",\"Unknown\")),\n    \n    # PPO recode (keep Not Answered)\n    across(starts_with(\"policy_\"), ~case_when(\n      .x == \"1\" ~ \"Strongly Disagree\",\n      .x == \"2\" ~ \"Disagree\",\n      .x == \"3\" ~ \"Neutral\",\n      .x == \"4\" ~ \"Agree\",\n      .x == \"5\" ~ \"Strongly Agree\",\n      .x == \"Not Answered\" ~ \"Not Answered\",\n      TRUE ~ \"Not Answered\"\n    ) %&gt;% factor(levels = c(\"Strongly Disagree\",\"Disagree\",\"Neutral\",\"Agree\",\"Strongly Agree\",\"Not Answered\"))),\n    \n    # Feature engineering\n    daily_wage = if_else(!is.na(working_days) & working_days &gt; 0,\n                         total_income / working_days,\n                         NA_real_),\n    \n    agri_inc_ratio = if_else(total_income &gt; 0, agri_income / total_income, NA_real_),\n    service_inc_ratio = if_else(total_income &gt; 0, service_industry_inc / total_income, NA_real_),\n    other_inc_ratio = if_else(total_income &gt; 0, other_income / total_income, NA_real_)\n  ) %&gt;%\n  \n  # Drop original coded columns (optional but keeps dataset clean)\n  select(-CPRO, -CGEN, -CRAC, -CJOB, -CQUI, -FEDU, -FVTP, -FCRA, -FTAP)\n\n# Final verification\nglimpse(clean_df)\n\n\nRows: 724\nColumns: 28\n$ total_income         &lt;dbl&gt; 37, 25, 33, 35, 36, 21, 35, 36, 38, 30, 58, 24, 3…\n$ agri_income          &lt;dbl&gt; 25, 22, 25, 30, 28, 17, 25, 28, 26, 22, 40, 24, 2…\n$ service_industry_inc &lt;dbl&gt; 7, 0, 0, 5, 0, 0, 0, 0, 12, 2, 0, 0, 0, 0, 0, 50,…\n$ other_income         &lt;dbl&gt; 5, 3, 8, 0, 8, 4, 10, 8, 0, 6, 18, 0, 9, 0, 2, 15…\n$ working_days         &lt;dbl&gt; 240, 350, 260, 300, 360, 360, 260, 260, 300, 300,…\n$ policy_training      &lt;fct&gt; Strongly Agree, Disagree, Strongly Agree, Not Ans…\n$ policy_agri_chain    &lt;fct&gt; Disagree, Strongly Agree, Strongly Agree, Not Ans…\n$ policy_healthcare    &lt;fct&gt; Neutral, Neutral, Strongly Disagree, Not Answered…\n$ policy_elderly_care  &lt;fct&gt; Strongly Disagree, Strongly Disagree, Strongly Di…\n$ policy_urban_jobs    &lt;fct&gt; Neutral, Strongly Disagree, Strongly Disagree, No…\n$ wellbeing_improve    &lt;fct&gt; Neutral, Neutral, Unknown, Unknown, Disagree, Dis…\n$ house_cottage        &lt;fct&gt; No, Yes, No, Yes, No, No, No, No, No, No, No, No,…\n$ house_roofed         &lt;fct&gt; Yes, No, No, No, Yes, Yes, No, Yes, Yes, Yes, Yes…\n$ house_solid          &lt;fct&gt; No, No, No, No, No, No, Yes, No, No, No, No, No, …\n$ house_buildings      &lt;fct&gt; No, No, Yes, No, No, No, No, No, No, No, No, No, …\n$ province             &lt;fct&gt; Tuyen Quang, Tuyen Quang, Tuyen Quang, Tuyen Quan…\n$ gender               &lt;fct&gt; Male, Male, Female, Male, Female, Female, Male, M…\n$ race                 &lt;fct&gt; Minority, Minority, Minority, Minority, Minority,…\n$ job_type             &lt;fct&gt; Agricultural, Agricultural, Other, Agricultural, …\n$ income_group         &lt;fct&gt; Middle, Lowest, Middle, Middle, Middle, Second, T…\n$ education            &lt;fct&gt; Lower secondary, Primary, Lower secondary, Lower …\n$ training_status      &lt;fct&gt; Short course, Short course, Short course, Short c…\n$ credit_status        &lt;fct&gt; Inaccessible, Accessible, Inaccessible, Inaccessi…\n$ tech_level           &lt;fct&gt; Low, Low, Adequate, Unknown, Adequate, Adequate, …\n$ daily_wage           &lt;dbl&gt; 0.15416667, 0.07142857, 0.12692308, 0.11666667, 0…\n$ agri_inc_ratio       &lt;dbl&gt; 0.6756757, 0.8800000, 0.7575758, 0.8571429, 0.777…\n$ service_inc_ratio    &lt;dbl&gt; 0.18918919, 0.00000000, 0.00000000, 0.14285714, 0…\n$ other_inc_ratio      &lt;dbl&gt; 0.13513514, 0.12000000, 0.24242424, 0.00000000, 0…\n\n\n\nFor Likert-scale items (PPO and ARO4), missing responses are treated as non-substantive answers.\nWe label PPO missing values as “Not Answered” to distinguish non-response from agreement levels, and recode ARO4 into ordered agreement categories while keeping missing/invalid entries as “Unknown”."
  },
  {
    "objectID": "Take-Home_Exercise/Take-Home_Exercise01/TE01.html#visualization",
    "href": "Take-Home_Exercise/Take-Home_Exercise01/TE01.html#visualization",
    "title": "Take-Home Exercise 01",
    "section": "2 Visualization",
    "text": "2 Visualization\n\n2.1 Macro Context\n\n2.1.1 Regional Workforce Composition by Ethnicity and Gender\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nplot_data_21 &lt;- clean_df %&gt;%\n  count(province, race, gender, name = \"count\") %&gt;%\n  group_by(province) %&gt;%\n  mutate(\n    prov_total = sum(count),\n    percentage = count / prov_total,\n    facet_label = paste0(province, \" \\n(N=\", prov_total, \")\")\n  ) %&gt;%\n  ungroup()\n\nggplot(plot_data_21, aes(x = race, y = percentage, fill = gender)) +\n  geom_col(width = 0.7, alpha = 0.9) +\n  geom_text(\n    aes(label = scales::percent(percentage, accuracy = 1)),\n    position = position_stack(vjust = 0.5),\n    size = 3,\n    color = \"white\"\n  ) +\n  facet_wrap(~facet_label, nrow = 1) +\n  scale_y_continuous(\n    labels = scales::percent_format(accuracy = 1),\n    expand = expansion(mult = c(0, 0.05))\n  ) +\n  scale_fill_manual(\n    values = c(\"Male\" = \"#547d9d\", \"Female\" = \"#d8a437\")\n  ) +\n  labs(\n    title = \"Workforce Composition by Region\",\n    subtitle = \"Proportional share within each province\",\n    x = \"Ethnic Group\",\n    y = \"Share of Province\",\n    fill = \"Gender\"\n  ) +\n  theme_minimal(base_size = 12) +\n  theme(\n    legend.position = \"top\",\n    strip.text = element_text(size = 11, face = \"bold\"),\n    axis.text = element_text(size = 10),\n    panel.spacing = unit(1.2, \"lines\")\n  )\n\n\n\n\nObservation\nThis visualization confirms a balanced sampling design across the five provinces, with each region contributing a comparable number of observations. Clear regional differences emerge in ethnic composition: ethnic minorities dominate the informal labour force in Ha Giang, Tuyen Quang, and Yen Bai, whereas Kinh workers represent a larger share in Bac Giang and Quang Ninh. This highlights the strong association between remoteness and minority participation in informal employment.\nIn contrast, gender composition exhibits a consistent structural imbalance rather than a geographic pattern. Male workers account for the majority of informal labourers across all provinces and ethnic groups, with only modest variation in female participation. These differences occur within an overall male-dominated workforce and do not show systematic spatial variation. This suggests that gender disparities in informal labour participation reflect broader labour market or household-level constraints, while regional variation is more strongly driven by ethnicity and location.\n\n\n\n2.2 Income Distribution & Inequality\n\n\n\n\n\n\n\n\n\nObservation\nIncome among rural informal labourers is concentrated in the lower-to-middle strata, yet the Lorenz curve shows that income accumulation remains uneven. Most respondents fall within the bottom and middle income quintiles, indicating that low-to-mid income conditions are widespread rather than limited to a small disadvantaged subgroup. However, the Lorenz curve deviates from the line of equality, implying that a relatively smaller share of higher earners holds a disproportionate share of total income. Together, these patterns suggest persistent inequality within an overall low-income population, reflecting structural constraints alongside unequal income capture at the upper tail.\n\n2.2.1 Income Quintile Distribution\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nplot_data_22 &lt;- clean_df %&gt;%\n  count(income_group) %&gt;%\n  mutate(percentage = n / sum(n))\n\np_quintile &lt;- ggplot(plot_data_22, aes(x = income_group, y = percentage)) +\n  geom_col(fill = \"#547d9d\", alpha = 0.9) +\n  geom_text(\n    aes(label = scales::percent(percentage, accuracy = 1)),\n    vjust = -0.3,\n    size = 3.5\n  ) +\n  scale_y_continuous(\n    labels = scales::percent_format(accuracy = 1),\n    expand = expansion(mult = c(0, 0.08))\n  ) +\n  labs(\n    title = \"Income Quintile Distribution\",\n    subtitle = \"Share of respondents by income group\",\n    x = \"Income Quintile\",\n    y = \"Share of Respondents\"\n  ) +\n  theme_minimal(base_size = 11) +\n  theme(\n    plot.title = element_text(face = \"bold\"),\n    panel.grid.minor = element_blank()\n  )\n\np_quintile\n\n\n\n\n\n\n2.2.2 Lorenz Curve of Income Distribution\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ngini_val &lt;- Gini(clean_df$total_income, na.rm = TRUE)\n\nlorenz_df &lt;- clean_df %&gt;%\n  filter(!is.na(total_income), total_income &gt;= 0) %&gt;%\n  arrange(total_income) %&gt;%\n  mutate(\n    cum_pop = row_number() / n(),\n    cum_income = cumsum(total_income) / sum(total_income)\n  )\n\nlorenz_50 &lt;- lorenz_df %&gt;%\n  filter(cum_pop &gt;= 0.5) %&gt;%\n  slice(1)\n\np_lorenz &lt;- ggplot(lorenz_df, aes(x = cum_pop, y = cum_income)) +\n  geom_line(color = \"#547d9d\", linewidth = 1.1) +\n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\", color = \"grey60\") +\n  geom_point(\n    data = lorenz_50,\n    aes(x = cum_pop, y = cum_income),\n    color = \"#d8a437\",\n    size = 2.8\n  ) +\n  scale_x_continuous(labels = scales::percent_format(accuracy = 1), limits = c(0, 1)) +\n  scale_y_continuous(labels = scales::percent_format(accuracy = 1), limits = c(0, 1)) +\n  labs(\n    title = \"Lorenz Curve of Income Distribution\",\n    subtitle = paste0(\"Bottom 50% hold ~\", scales::percent(lorenz_50$cum_income, accuracy = 1), \" of total income\"),\n    x = \"Cumulative Share of Population\",\n    y = \"Cumulative Share of Income\"\n  ) +\n  theme_minimal(base_size = 11) +\n  theme(\n    plot.title = element_text(face = \"bold\"),\n    panel.grid.minor = element_blank()\n  )\n\np_lorenz &lt;- p_lorenz + \n  labs(subtitle = paste0(\"Gini Coefficient: \", round(gini_val, 3), \n                         \" | Widespread low-income clustering in the 20-60 range\"))\n\np_lorenz\n\n\n\n\n\n\n\n2.3 Structural Disparities\n\n\n\n\n\n\n\n\n\nObservation\nMost respondents’ total income is concentrated below 100, with distributions tightly clustered in the 20–60 range, indicating generally low income levels across the sample. Clear ethnic disparities emerge: ethnic minority workers exhibit lower median incomes and a left-shifted distribution compared with Kinh workers, suggesting structurally constrained earning capacity rather than isolated poverty. Gender differences are not uniform across groups. Among Kinh workers, male and female income distributions largely overlap, whereas among ethnic minorities, male incomes are more compressed at the lower end, with weaker upper-tail dispersion. Together, these patterns indicate that income inequality is shaped by ethnicity and that gender-based income advantages are conditional on ethnic context, pointing to intersecting structural constraints rather than single-factor effects.\n\n2.3.1 Income Spread (Raincloud)\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npal &lt;- c(\"Male\" = \"#547d9d\", \"Female\" = \"#d8a437\")\n\ndf_income &lt;- clean_df %&gt;% \n  filter(!is.na(total_income), total_income &gt;= 0) %&gt;%\n  mutate(\n    race   = droplevels(race),\n    gender = droplevels(gender)\n  )\n\nx_max &lt;- as.numeric(quantile(df_income$total_income, 0.95, na.rm = TRUE))\n\np_rain_split &lt;- ggplot(df_income, aes(x = total_income, y = race, fill = gender)) +\n  ggdist::stat_halfeye(\n    adjust = 0.65,\n    width  = 0.55,\n    .width = 0,\n    alpha  = 0.55,\n    point_colour = NA,\n    justification = 0.85,\n    position = position_dodge(width = 0.75)\n  ) +\n  geom_point(\n    aes(color = gender),\n    position = position_jitterdodge(\n      jitter.height = 0.18,\n      dodge.width   = 0.75,\n      seed          = 2022\n    ),\n    alpha = 0.22,\n    size  = 0.75\n  ) +\n  coord_cartesian(xlim = c(0, x_max)) +\n  scale_fill_manual(values = pal) +\n  scale_color_manual(values = pal) +\n  scale_x_continuous(labels = scales::comma) +\n  labs(\n    title = \"Income Spread by Ethnicity and Gender\",\n    subtitle = \"Distribution shape + individual observations (trimmed to 95th percentile)\",\n    x = \"Total Income\",\n    y = \"Ethnic Group\",\n    fill = \"Gender\"\n  ) +\n  theme_minimal(base_size = 11) +\n  theme(\n    plot.title = element_text(face = \"bold\"),\n    panel.grid.minor = element_blank(),\n    legend.position = \"top\"\n  ) +\n  guides(color = \"none\")\n\np_rain_split &lt;- p_rain_split + \n  stat_compare_means(aes(group = gender), \n                     method = \"wilcox.test\", \n                     label = \"p.signif\", \n                     label.x = 1.5)\n\np_rain_split\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nTo improve readability, the x-axis is trimmed to the 95th percentile using coord_cartesian().\nThis keeps the main distribution visible while preventing a small number of extreme incomes from stretching the scale.\n\n\n\n\n\n2.3.2 Income Distribution (Boxplot)\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\np_box_23 &lt;- ggplot(df_income, aes(x = race, y = total_income, fill = gender)) +\n  geom_boxplot(width = 0.6, outlier.alpha = 0.25) +\n  coord_cartesian(ylim = c(0, 150)) +\n  scale_fill_manual(values = pal) +\n  labs(\n    title = \"Income Distribution (Boxplot)\",\n    subtitle = \"Median and IQR highlighted (zoomed to 0–150)\",\n    x = \"Ethnic Group\",\n    y = \"Total Income\"\n  ) +\n  theme_minimal(base_size = 11) +\n  theme(\n    plot.title = element_text(face = \"bold\"),\n    panel.grid.minor = element_blank(),\n    legend.position = \"top\"\n  )\n\np_box_23\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nThe y-axis is zoomed to 0–150 via coord_cartesian() to highlight differences in the median and IQR.\nOutliers are still present in the dataset; they are only de-emphasized visually to avoid compressing the box region.\n\n\n\n\n\n2.3.3 Within-Group Income Distribution (Density)\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\np_density_23 &lt;- ggplot(df_income, aes(x = total_income, fill = gender)) +\n  geom_density(alpha = 0.55) +\n  facet_wrap(~ race, scales = \"free_y\") +\n  coord_cartesian(xlim = c(0, x_max)) +\n  scale_fill_manual(values = pal) +\n  labs(\n    title = \"Within-Group Income Distribution\",\n    subtitle = \"Gender density within each ethnic group (trimmed to 95th percentile)\",\n    x = \"Total Income\",\n    y = \"Density\"\n  ) +\n  theme_minimal(base_size = 11) +\n  theme(\n    plot.title = element_text(face = \"bold\"),\n    panel.grid.minor = element_blank(),\n    legend.position = \"top\"\n  )\n\np_density_23\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nDensity plots are faceted by ethnicity with scales = \"free_y\" so each group’s distribution shape is readable.\nThe x-axis is trimmed to the 95th percentile, focusing attention on the dominant income range.\n\n\n\n\n\n\n2.4 Income Composition\n\n\n\n\n\n\n\n\n\nObservation\nWhile higher income quintiles mechanically exhibit higher average income, the key distinction lies in income composition. Lower quintiles depend predominantly on agricultural income, with limited diversification across income sources. As income levels rise, the share of service and other non-agricultural income increases substantially, alongside a marked rise in average total income. This pattern suggests that upward income mobility is associated with structural shifts in livelihood strategies, rather than proportional increases within the same income source.\n\n2.4.1 Income Source Composition by Quintile\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmosaic_df &lt;- clean_df %&gt;%\n  filter(!is.na(total_income), total_income &gt; 0, income_group != \"Unknown\") %&gt;%\n  mutate(income_group = factor(income_group, \n                               levels = c(\"Lowest\", \"Second\", \"Middle\", \"Fourth\", \"Top\"))) %&gt;%\n  group_by(income_group) %&gt;%\n  summarise(\n    n = n(),\n    Agriculture = mean(agri_inc_ratio, na.rm = TRUE),\n    Service = mean(service_inc_ratio, na.rm = TRUE),\n    Other = mean(other_inc_ratio, na.rm = TRUE),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    width = n / sum(n),\n    xmax = cumsum(width),\n    xmin = xmax - width,\n    xmid = (xmin + xmax) / 2\n  ) %&gt;%\n  pivot_longer(cols = c(\"Agriculture\", \"Service\", \"Other\"), \n               names_to = \"source\", values_to = \"share\") %&gt;%\n  group_by(income_group) %&gt;%\n  mutate(\n    share = share / sum(share), \n    ymax = cumsum(share),\n    ymin = ymax - share,\n    ymid = (ymin + ymax) / 2\n  ) %&gt;%\n  ungroup()\n\nggplot(mosaic_df) +\n  geom_rect(aes(xmin = xmin, xmax = xmax, ymin = ymin, ymax = ymax, fill = source), \n            color = \"white\", linewidth = 0.3) +\n  \n  geom_text(aes(x = xmid, y = ymid, \n                label = ifelse(share &gt; 0.05, scales::percent(share, accuracy = 1), \"\")),\n            color = \"white\", size = 3, fontface = \"bold\") +\n  \n  annotate(\"text\", \n           x = mosaic_df$xmid[seq(1, nrow(mosaic_df), 3)], \n           y = 1.05, \n           label = paste0(levels(mosaic_df$income_group), \"\\n(n=\", mosaic_df$n[seq(1, nrow(mosaic_df), 3)], \")\"),\n           size = 3.2, fontface = \"bold\", lineheight = 0.9) +\n  \n  scale_fill_manual(values = pal_src) +\n  scale_y_continuous(labels = scales::percent_format(), breaks = seq(0, 1, 0.2)) +\n  \n  scale_x_continuous(expand = expansion(mult = c(0.01, 0.05))) +\n  \n  labs(title = \"Mosaic Plot of Income Composition\",\n       subtitle = \"Width: Group Size | Height: Source Share\",\n       x = \"Relative Population Weight\",\n       y = \"Income Source Proportion\",\n       fill = \"Source\") +\n  \n  theme_minimal() +\n  theme(\n    panel.grid = element_blank(),\n    axis.text.x = element_blank(),\n    plot.title = element_text(face = \"bold\", size = 14),\n    legend.position = \"bottom\",\n    plot.margin = margin(t = 20, r = 30, b = 20, l = 10)\n  )\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThis figure uses a 100% stacked bar (each bar sums to 100%) to compare income structure across quintiles. Values are based on average income shares (ratios) rather than raw income levels, so the focus is on composition, not magnitude.\n\n\n\n\n2.4.2 Average Total Income by Quintile\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nquintile_order &lt;- c(\"Unknown\", \"Lowest\", \"Second\", \"Middle\", \"Fourth\", \"Top\")\n\nmean_df &lt;- df_24 %&gt;%\n  group_by(income_group) %&gt;%\n  summarise(\n    mean_income = mean(total_income, na.rm = TRUE),\n    se = sd(total_income, na.rm = TRUE) / sqrt(n()),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    ci_low  = mean_income - 1.96 * se,\n    ci_high = mean_income + 1.96 * se\n  )\n\np_mean &lt;- ggplot(mean_df, aes(x = income_group, y = mean_income)) +\n  geom_col(fill = \"#547d9d\", width = 0.6, alpha = 0.9) +\n  geom_errorbar(aes(ymin = ci_low, ymax = ci_high), width = 0.2) +\n  scale_y_continuous(labels = scales::comma) +\n  labs(\n    title = \"Average Total Income by Quintile\",\n    subtitle = \"Mean income with 95% confidence intervals\",\n    x = \"Income Quintile\",\n    y = \"Mean Total Income\"\n  ) +\n  theme_minimal(base_size = 11) +\n  theme(\n    plot.title = element_text(face = \"bold\"),\n    panel.grid.minor = element_blank()\n  )\n\np_mean\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nError bars show 95% confidence intervals of the mean, computed as mean ± 1.96 × SE. This chart complements the composition plot by showing income magnitude, addressing the limitation that “high share” does not necessarily imply “high income”.\n\n\n\n\n\n2.5 Micro-Level Drivers of Income and Productivity\n\n\n\n\n\n\n\n\n\nObservation\nIncome dispersion increases with education level and training intensity. Higher education groups, especially those with long-course training, display not only higher mean income but also wider income distributions driven by an expanded upper tail. Training therefore raises income in a heterogeneous manner rather than uniformly benefiting all workers.\nThe daily wage analysis clarifies the mechanism behind this pattern. Daily wages decline as working days increase, suggesting diminishing returns to labor intensity in informal work. However, service and industrial jobs consistently offer higher daily wages than agricultural work, and adequate technology access further lifts productivity per day. These results indicate that higher income is achieved not by working more days, but by accessing higher-productivity jobs and technologies.\n\n2.5.1 Income by Education & Training (Boxplot)\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\np_edu_train &lt;- ggplot(df_25, aes(x = education, y = total_income, fill = training_status)) +\n  geom_boxplot(width = 0.65, outlier.alpha = 0.18) +\n  coord_cartesian(ylim = c(0, y99_inc), clip = \"off\") +\n  scale_x_discrete(guide = guide_axis(n.dodge = 2)) +\n  scale_fill_manual(values = pal_train) +\n  labs(\n    title = \"Income by Education & Training\",\n    subtitle = \"Wider spread at higher levels\",\n    x = \"Education\",\n    y = \"Total Income\",\n    fill = \"Training\"\n  ) +\n  theme_25\n\np_edu_train\n\n\n\n\n\n\n2.5.2 Average Income by Education (Mean + 95% CI)\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nedu_mean &lt;- df_25 %&gt;%\n  group_by(education) %&gt;%\n  summarise(\n    mean_income = mean(total_income, na.rm = TRUE),\n    se = sd(total_income, na.rm = TRUE) / sqrt(n()),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    ci_low  = mean_income - 1.96 * se,\n    ci_high = mean_income + 1.96 * se\n  )\n\np_edu_ci &lt;- ggplot(edu_mean, aes(x = education, y = mean_income)) +\n  geom_col(fill = \"#547d9d\", alpha = 0.9, width = 0.65) +\n  geom_errorbar(aes(ymin = ci_low, ymax = ci_high), width = 0.2) +\n  coord_cartesian(clip = \"off\") +\n  scale_x_discrete(guide = guide_axis(n.dodge = 2)) +\n  scale_y_continuous(labels = scales::comma) +\n  labs(\n    title = \"Average Income by Education\",\n    subtitle = \"Mean (95% CI)\",\n    x = \"Education\",\n    y = \"Mean Income\"\n  ) +\n  theme_25\n\np_edu_ci\n\n\n\n\n\n\n2.5.3 Daily Wage vs Working Days (Job Type)\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\np_job &lt;- ggplot(df_25, aes(x = working_days, y = daily_wage, color = job_type)) +\n  geom_point(alpha = 0.8, size = 1.4) +\n  geom_smooth(method = \"lm\", se = FALSE, linewidth = 0.85) +\n  coord_cartesian(xlim = c(0, x99_days), ylim = c(0, y99_wage), clip = \"off\") +\n  scale_x_continuous(breaks = scales::breaks_pretty(n = 5)) +\n  scale_color_manual(values = pal_job) +\n  labs(\n    title = \"Daily Wage vs Working Days\",\n    subtitle = \"Higher wage in non-farm jobs\",\n    x = \"Working Days\",\n    y = \"Daily Wage\",\n    color = \"Job\"\n  ) +\n  theme_25\n\np_job\n\n\n\n\n\n\n2.5.4 Daily Wage vs Working Days (Technology)\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\np_tech &lt;- ggplot(df_25, aes(x = working_days, y = daily_wage, color = tech_level)) +\n  geom_point(alpha = 0.8, size = 1.4) +\n  geom_smooth(method = \"lm\", se = FALSE, linewidth = 0.85) +\n  coord_cartesian(xlim = c(0, x99_days), ylim = c(0, y99_wage), clip = \"off\") +\n  scale_x_continuous(breaks = scales::breaks_pretty(n = 5)) +\n  scale_color_manual(values = pal_tech) +\n  labs(\n    title = \"Daily Wage vs Working Days\",\n    subtitle = \"Tech lifts wage per day\",\n    x = \"Working Days\",\n    y = \"Daily Wage\",\n    color = \"Tech\"\n  ) +\n  theme_25\n\np_tech\n\n\n\n\n\n\n\n2.6 Social Outlook: Material Reality and Policy Aspiration\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nConstruction of aspiration index\nThe aspiration score is constructed using only two policy items—urban job opportunities and vocational training—which directly reflect forward-looking economic transition and mobility. Other policy items (e.g. healthcare, elderly care) relate primarily to social protection rather than aspirational change, and are therefore excluded to maintain conceptual clarity.\n\n\nObservation\nThis section reveals a clear divergence between material deprivation and policy aspiration. Ethnic minorities are disproportionately concentrated in lower-quality housing, indicating weaker material living conditions. However, support for transition-oriented policies increases with housing quality, rather than deprivation severity. Importantly, the aspiration index focuses exclusively on urban job opportunities and vocational training, capturing forward-looking economic mobility rather than general welfare demand. Individuals with more secure housing conditions appear better positioned—financially and psychologically—to perceive these policies as viable pathways for further advancement. In contrast, those in precarious housing face binding constraints that limit optimism toward long-term transition policies, despite greater material need.\nTogether, these patterns suggest that policy aspiration reflects perceived capacity to benefit, not merely exposure to hardship. Structural inequality thus operates not only through unequal living conditions, but also through unequal access to hope and future-oriented expectations—linking material reality to aspirational asymmetry.\n\n2.6.1 Housing Modernization by Ethnic Group\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndf_race_cleaned &lt;- clean_df %&gt;%\n  filter(race != \"Unknown\") %&gt;%\n  mutate(house_type = case_when(\n    house_buildings == \"Yes\" ~ \"Multi-story\",\n    house_solid     == \"Yes\" ~ \"Solid/Perm\",\n    house_roofed    == \"Yes\" ~ \"Semi-perm\",\n    house_cottage   == \"Yes\" ~ \"Cottage/Temp\",\n    TRUE                     ~ \"Semi-perm\"\n  )) %&gt;%\n  mutate(house_type = factor(house_type, \n                             levels = c(\"Cottage/Temp\", \"Semi-perm\", \"Solid/Perm\", \"Multi-story\")))\n\nrace_x_axis &lt;- df_race_cleaned %&gt;%\n  group_by(race) %&gt;%\n  summarise(n = n(), .groups = \"drop\") %&gt;%\n  mutate(\n    width = n / sum(n),\n    xmax = cumsum(width),\n    xmin = xmax - width,\n    xmid = (xmin + xmax) / 2\n  )\n\nrace_housing_mosaic &lt;- df_race_cleaned %&gt;%\n  count(race, house_type) %&gt;%\n  group_by(race) %&gt;%\n  mutate(share = n / sum(n)) %&gt;%\n  ungroup() %&gt;%\n  left_join(race_x_axis, by = \"race\") %&gt;%\n  arrange(race, house_type) %&gt;%\n  group_by(race) %&gt;%\n  mutate(\n    ymax = cumsum(share),\n    ymin = ymax - share,\n    ymid = (ymin + ymax) / 2\n  ) %&gt;%\n  ungroup()\n\nggplot(race_housing_mosaic) +\n  geom_rect(aes(xmin = xmin, xmax = xmax, ymin = ymin, ymax = ymax, fill = house_type, alpha = 0.9), \n            color = \"white\", linewidth = 0.4) +\n\n  geom_text(aes(x = xmid, y = ymid, \n                label = ifelse(share &gt; 0.05, scales::percent(share, accuracy = 1), \"\")),\n            color = \"white\", size = 3.2, fontface = \"bold\") +\n\n  annotate(\"text\", \n           x = race_x_axis$xmid, \n           y = 1.06, \n           label = paste0(race_x_axis$race, \"\\n(n=\", race_x_axis$n, \")\"),\n           size = 3.5, fontface = \"bold\", lineheight = 0.85) +\n  \n  scale_fill_manual(values = c(\"#d8a437\", \"#cedbd3\", \"#8aa6b8\", \"#547d9d\")) +\n  scale_y_continuous(labels = scales::percent_format(), expand = expansion(mult = c(0, 0.05))) +\n\n  scale_x_continuous(expand = expansion(mult = c(0.02, 0.1))) +\n  \n  labs(title = \"Structural Mosaic: Housing Standards across Ethnic Groups\",\n       subtitle = \"Width represents ethnic population size; Height represents housing tier distribution\",\n       x = \"Population Weight of Ethnic Minorities\",\n       y = \"Housing Type Share\",\n       fill = \"Housing Level\") +\n  \n  theme_minimal(base_size = 11) +\n  theme(\n    panel.grid = element_blank(),\n    axis.text.x = element_blank(),\n    plot.title = element_text(face = \"bold\", size = 15),\n    legend.position = \"bottom\",\n    plot.margin = margin(t = 30, r = 50, b = 20, l = 20)\n  )\n\n\n\n\n\n\n2.6.2 Policy Aspiration by Housing Level\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nplot_gantt_data &lt;- df_26_final %&gt;%\n  mutate(aspiration_score = round(transition_aspiration)) %&gt;%\n  mutate(aspiration_label = factor(aspiration_score, \n                                   levels = 1:5, \n                                   labels = c(\"Strongly Disagree\", \"Disagree\", \"Neutral\", \"Agree\", \"Strongly Agree\"))) %&gt;%\n  count(house_rank, aspiration_label) %&gt;%\n  group_by(house_rank) %&gt;%\n  mutate(\n    total_n = sum(n),\n    percentage = n / total_n\n  ) %&gt;%\n  mutate(\n    neutral_mid = sum(percentage[aspiration_label %in% c(\"Strongly Disagree\", \"Disagree\")]) + \n                  0.5 * sum(percentage[aspiration_label == \"Neutral\"]),\n  \n    category_order = as.numeric(aspiration_label)\n  ) %&gt;%\n  arrange(house_rank, aspiration_label) %&gt;%\n  mutate(\n    xmax = cumsum(percentage) - neutral_mid,\n    xmin = xmax - percentage,\n    label_pos = (xmin + xmax) / 2,\n    label_text = ifelse(percentage &gt; 0.04, scales::percent(percentage, accuracy = 1), \"\")\n  ) %&gt;%\n  ungroup()\n\nggplot(plot_gantt_data, aes(y = house_rank)) +\n  geom_rect(aes(xmin = xmin, xmax = xmax, \n                ymin = as.numeric(factor(house_rank)) - 0.35, \n                ymax = as.numeric(factor(house_rank)) + 0.35, \n                fill = aspiration_label), alpha = 0.9) +\n  geom_text(aes(x = label_pos, label = label_text), \n            size = 3.2, color = \"white\", fontface = \"bold\") +\n  \n  geom_text(aes(x = 0.6, label = paste0(\"N=\", total_n)), \n            hjust = 0, size = 3.5, color = \"#666666\", fontface = \"italic\") +\n  \n  scale_x_continuous(labels = function(x) scales::percent(abs(x)), \n                     breaks = seq(-1, 1, 0.25),\n                     expand = expansion(mult = c(0.1, 0.2))) +\n  \n  scale_fill_manual(values = c(\"#d8a437\", \"#f1e3c4\", \"#cedbd3\", \"#8aa6b8\", \"#547d9d\")) +\n\n  labs(title = \"Diverging Policy Aspiration Profile\",\n       subtitle = \"Centered on 'Neutral' sentiment to highlight the shift toward 'Strongly Agree'\",\n       y = \"\", x = \"Percentage\",\n       fill = \"Sentiment Level\") +\n  \n  theme_minimal(base_size = 11) +\n  theme(legend.position = \"bottom\",\n        panel.grid.minor = element_blank(),\n        axis.text.y = element_text(face = \"bold\", size = 11),\n        plot.title = element_text(face = \"bold\", size = 14),\n        plot.margin = margin(10, 40, 10, 10))"
  },
  {
    "objectID": "Take-Home_Exercise/Take-Home_Exercise01/TE01.html#synthesis-conclusion",
    "href": "Take-Home_Exercise/Take-Home_Exercise01/TE01.html#synthesis-conclusion",
    "title": "Take-Home Exercise 01",
    "section": "3 Synthesis & Conclusion",
    "text": "3 Synthesis & Conclusion\nBased on the progressive visual analytics conducted in this report, we draw the following integrated conclusions regarding income inequality and social outlook among rural informal labourers in Northern Vietnam:\n\n3.1 Key Findings\n\nThe Ethnicity-Income Trap: There is a profound structural gap where Ethnic Minorities are not only geographically remote but also trapped in low-productivity agricultural roles with significantly lower median incomes compared to the Kinh majority.\nEducation as a Double-Edged Sword: While higher education and long-term vocational training significantly lift the “income ceiling,” they also increase income dispersion. This suggests that education provides the opportunity for high earnings, but the actual returns depend on other factors like technology access and job type.\nThe Diminishing Returns of Labor: Our analysis reveals that working more days does not linearly increase daily wages; in fact, labor intensity often shows diminishing returns. True economic mobility is driven by technological adequacy and transitioning from agriculture to service/industrial sectors.\nThe “Aspiration Awakening”: Perhaps the most critical insight is that policy support is not a simple function of poverty. Instead, as labourers improve their material living standards (housing), their desire for structural transition (urban jobs and training) intensifies. Stability breeds ambition.\n\n\n\n3.2 Strategic Recommendations\n\nTargeted Skill Transformation: Vocational training should be specifically tailored to the “awakened” group (those with basic stability) to maximize transition success, while basic social safety nets should remain the priority for those in temporary housing.\nBridging the Tech-Gap: Since technology access significantly lifts the wage curve regardless of working days, subsidized access to digital tools and modern equipment could be a more efficient poverty reduction tool than direct cash transfers.\nRegional Integration: Policy focus should shift from “keeping labourers on the farm” to facilitating a smooth transition into urban and industrial value chains, as this is where the highest productivity gains are observed."
  },
  {
    "objectID": "In-Class_Exercise/In-Class_Exercise02/IE02.html",
    "href": "In-Class_Exercise/In-Class_Exercise02/IE02.html",
    "title": "In-Class Exercise 02",
    "section": "",
    "text": "This exercise focuses on the strategic selection of chart types and the enhancement of user interpretation through effective annotation. The goal is to move beyond mere data display to intentional “data storytelling."
  },
  {
    "objectID": "In-Class_Exercise/In-Class_Exercise02/IE02.html#overview",
    "href": "In-Class_Exercise/In-Class_Exercise02/IE02.html#overview",
    "title": "In-Class Exercise 02",
    "section": "",
    "text": "This exercise focuses on the strategic selection of chart types and the enhancement of user interpretation through effective annotation. The goal is to move beyond mere data display to intentional “data storytelling."
  },
  {
    "objectID": "In-Class_Exercise/In-Class_Exercise02/IE02.html#monthly-sales-with-reference-lines",
    "href": "In-Class_Exercise/In-Class_Exercise02/IE02.html#monthly-sales-with-reference-lines",
    "title": "In-Class Exercise 02",
    "section": "1. Monthly Sales with Reference Lines",
    "text": "1. Monthly Sales with Reference Lines\nAdding Reference Lines (e.g., average or target) provides a benchmark for the data. This allows analysts to instantly identify months with above-average performance, adding essential “context” to a standard line chart.\n\n\n\nMonthly Sales"
  },
  {
    "objectID": "In-Class_Exercise/In-Class_Exercise02/IE02.html#monthly-profit-bar-chart",
    "href": "In-Class_Exercise/In-Class_Exercise02/IE02.html#monthly-profit-bar-chart",
    "title": "In-Class Exercise 02",
    "section": "2. Monthly Profit (Bar Chart)",
    "text": "2. Monthly Profit (Bar Chart)\nSwitching to a bar chart for profit emphasizes divergence. By contrasting color and bar length, the intensity of profits and losses becomes much more visually impactful than a continuous line.\n\n\n\nMonthly Profit"
  },
  {
    "objectID": "In-Class_Exercise/In-Class_Exercise02/IE02.html#relationship-between-monthly-profit-and-sales",
    "href": "In-Class_Exercise/In-Class_Exercise02/IE02.html#relationship-between-monthly-profit-and-sales",
    "title": "In-Class Exercise 02",
    "section": "3. Relationship between Monthly Profit and Sales",
    "text": "3. Relationship between Monthly Profit and Sales\nThis view explores correlation. Does high sales volume always translate to high profit? This helps identify months with “high revenue but low margin,” signaling a need for cost structure optimization.\n\n\n\nMonthly Profit by Sales"
  },
  {
    "objectID": "In-Class_Exercise/In-Class_Exercise02/IE02.html#pareto-chart-sales-by-sub-category",
    "href": "In-Class_Exercise/In-Class_Exercise02/IE02.html#pareto-chart-sales-by-sub-category",
    "title": "In-Class Exercise 02",
    "section": "4. Pareto Chart: Sales by Sub-Category",
    "text": "4. Pareto Chart: Sales by Sub-Category\nThis chart identifies the primary revenue drivers among sub-categories. It helps in optimizing the product mix, ensuring high-value categories receive adequate visibility and marketing budget.\n\n\n\nPareto Chart Sales by Sub-Category"
  },
  {
    "objectID": "In-Class_Exercise/In-Class_Exercise02/IE02.html#pareto-analysis-of-sales-by-stateprovince",
    "href": "In-Class_Exercise/In-Class_Exercise02/IE02.html#pareto-analysis-of-sales-by-stateprovince",
    "title": "In-Class Exercise 02",
    "section": "5. Pareto Analysis of Sales by State/Province",
    "text": "5. Pareto Analysis of Sales by State/Province\nA classic application of the 80/20 Rule. It identifies the “vital few” states (top 20% of regions) that generate 80% of total sales. This is strategically crucial for resource allocation, such as the placement of logistics hubs and regional marketing expenditures.\n\n\n\nPareto Analysis of Sales by State Province"
  },
  {
    "objectID": "In-Class_Exercise/In-Class_Exercise02/IE02.html#dashboard-presentation",
    "href": "In-Class_Exercise/In-Class_Exercise02/IE02.html#dashboard-presentation",
    "title": "In-Class Exercise 02",
    "section": "6. Dashboard Presentation",
    "text": "6. Dashboard Presentation\nFinally, we integrate these multi-dimensional views into a Dashboard. This provides a holistic perspective and utilizes interactivity to allow users to instantly identify the core regions and products driving the business.\n\n\n\nDashboard"
  },
  {
    "objectID": "Hands-On_Exercise/Hands-On_Exercise05/HE05-4.html",
    "href": "Hands-On_Exercise/Hands-On_Exercise05/HE05-4.html",
    "title": "Hands-On Exercise 05-4",
    "section": "",
    "text": "Parallel coordinates plot is a data visualisation specially designed for visualising and analysing multivariate, numerical data. It is ideal for comparing multiple variables together and seeing the relationships between them. For example, the variables contribute to Happiness Index. Parallel coordinates was invented by Alfred Inselberg in the 1970s as a way to visualize high-dimensional data. This data visualisation technique is more often found in academic and scientific communities than in business and consumer data visualizations. As pointed out by Stephen Few(2006), “This certainly isn’t a chart that you would present to the board of directors or place on your Web site for the general public. In fact, the strength of parallel coordinates isn’t in their ability to communicate some truth in the data to others, but rather in their ability to bring meaningful multivariate patterns and comparisons to light when used interactively for analysis.” For example, parallel coordinates plot can be used to characterise clusters detected during customer segmentation.\nBy the end of this hands-on exercise, you will gain hands-on experience on:\n\nplotting statistic parallel coordinates plots by using ggparcoord() of GGally package, and\nplotting interactive parallel coordinates plots by using parallelPlot package."
  },
  {
    "objectID": "Hands-On_Exercise/Hands-On_Exercise05/HE05-4.html#overview",
    "href": "Hands-On_Exercise/Hands-On_Exercise05/HE05-4.html#overview",
    "title": "Hands-On Exercise 05-4",
    "section": "",
    "text": "Parallel coordinates plot is a data visualisation specially designed for visualising and analysing multivariate, numerical data. It is ideal for comparing multiple variables together and seeing the relationships between them. For example, the variables contribute to Happiness Index. Parallel coordinates was invented by Alfred Inselberg in the 1970s as a way to visualize high-dimensional data. This data visualisation technique is more often found in academic and scientific communities than in business and consumer data visualizations. As pointed out by Stephen Few(2006), “This certainly isn’t a chart that you would present to the board of directors or place on your Web site for the general public. In fact, the strength of parallel coordinates isn’t in their ability to communicate some truth in the data to others, but rather in their ability to bring meaningful multivariate patterns and comparisons to light when used interactively for analysis.” For example, parallel coordinates plot can be used to characterise clusters detected during customer segmentation.\nBy the end of this hands-on exercise, you will gain hands-on experience on:\n\nplotting statistic parallel coordinates plots by using ggparcoord() of GGally package, and\nplotting interactive parallel coordinates plots by using parallelPlot package."
  },
  {
    "objectID": "Hands-On_Exercise/Hands-On_Exercise05/HE05-4.html#getting-started",
    "href": "Hands-On_Exercise/Hands-On_Exercise05/HE05-4.html#getting-started",
    "title": "Hands-On Exercise 05-4",
    "section": "1 Getting Started",
    "text": "1 Getting Started\n\n1.1 Installing and launching R packages\nFor this exercise, the GGally, parallelPlot and tidyverse packages will be used.\nThe code chunks below are used to install and load the packages in R.\n\npacman::p_load(GGally, parallelPlot, tidyverse)\n\n\n\n1.2 Data Preparation\nIn this hands-on exercise, the World Happinees 2018 (http://worldhappiness.report/ed/2018/) data will be used. The data set is download at https://s3.amazonaws.com/happiness-report/2018/WHR2018Chapter2OnlineData.xls. The original data set is in Microsoft Excel format. It has been extracted and saved in csv file called WHData-2018.csv.\nIn the code chunk below, read_csv() of readr package is used to import WHData-2018.csv into R and save it into a tibble data frame object called wh.\n\nwh &lt;- read_csv(\"data/WHData-2018.csv\")"
  },
  {
    "objectID": "Hands-On_Exercise/Hands-On_Exercise05/HE05-4.html#plotting-static-parallel-coordinates-plot",
    "href": "Hands-On_Exercise/Hands-On_Exercise05/HE05-4.html#plotting-static-parallel-coordinates-plot",
    "title": "Hands-On Exercise 05-4",
    "section": "2 Plotting Static Parallel Coordinates Plot",
    "text": "2 Plotting Static Parallel Coordinates Plot\nIn this section, you will learn how to plot static parallel coordinates plot by using ggparcoord() of GGally package. Before getting started, it is a good practice to read the function description in detail.\n\n2.1 Plotting a simple parallel coordinates\nCode chunk below shows a typical syntax used to plot a basic static parallel coordinates plot by using ggparcoord().\n\nggparcoord(data = wh, \n           columns = c(7:12))\n\n\n\n\n\n\n\n\nNotice that only two argument namely data and columns is used. Data argument is used to map the data object (i.e. wh) and columns is used to select the columns for preparing the parallel coordinates plot.\n\n\n2.2 Plotting a parallel coordinates with boxplot\nThe basic parallel coordinates failed to reveal any meaning understanding of the World Happiness measures. In this section, you will learn how to makeover the plot by using a collection of arguments provided by ggparcoord().\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn =2,\n           scale = \"uniminmax\",\n           alphaLines = 0.3,\n           boxplot = TRUE, \n           title = \"Parallel Coordinates Plot of World Happines Variables\")\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above.\n\ngroupColumn argument is used to group the observations (i.e. parallel lines) by using a single variable (i.e. Region) and colour the parallel coordinates lines by region name.\nscale argument is used to scale the variables in the parallel coordinate plot by using uniminmax method. The method univariately scale each variable so the minimum of the variable is zero and the maximum is one.\nalphaLines argument is used to reduce the intensity of the line colour to 0.2. The permissible value range is between 0 to 1.\nboxplot argument is used to turn on the boxplot by using logical TRUE. The default is FALSE.\ntitle argument is used to provide the parallel coordinates plot a title.\n\n\n\n2.3 Parallel coordinates with facet\nSince ggparcoord() is developed by extending ggplot2 package, we can combination use some of the ggplot2 function when plotting a parallel coordinates plot.\nIn the code chunk below, facet_wrap() of ggplot2 is used to plot 10 small multiple parallel coordinates plots. Each plot represent one geographical region such as East Asia.\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region) +\n  theme(\n    legend.position = \"right\",           \n    legend.key.size = unit(0.4, \"cm\"),   \n    legend.text = element_text(size = 7),\n    legend.title = element_text(size = 8),\n\n    axis.text.x = element_text(angle = 45, hjust = 1) \n  )\n\n\n\n\n\n\n\n\nOne of the aesthetic defect of the current design is that some of the variable names overlap on x-axis.\n\n\n2.4 Rotating x-axis text label\nTo make the x-axis text label easy to read, let us rotate the labels by 30 degrees. We can rotate axis text labels using theme() function in ggplot2 as shown in the code chunk below\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region)\n\n\n\n\n\n\n\n\nThing to learn from the code chunk above:\nTo rotate x-axis text labels, we use axis.text.x as argument to theme() function. And we specify element_text(angle = 30) to rotate the x-axis text by an angle 30 degree.\n\n\n2.5 Adjusting the rotated x-axis text label\nRotating x-axis text labels to 30 degrees makes the label overlap with the plot and we can avoid this by adjusting the text location using hjust argument to theme’s text element with element_text(). We use axis.text.x as we want to change the look of x-axis text.\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region) + \n  theme(axis.text.x = element_text(angle = 30, hjust=1))"
  },
  {
    "objectID": "Hands-On_Exercise/Hands-On_Exercise05/HE05-4.html#plotting-interactive-parallel-coordinates-plot-parallelplot-methods",
    "href": "Hands-On_Exercise/Hands-On_Exercise05/HE05-4.html#plotting-interactive-parallel-coordinates-plot-parallelplot-methods",
    "title": "Hands-On Exercise 05-4",
    "section": "3 Plotting Interactive Parallel Coordinates Plot: parallelPlot methods",
    "text": "3 Plotting Interactive Parallel Coordinates Plot: parallelPlot methods\nparallelPlot is an R package specially designed to plot a parallel coordinates plot by using ‘htmlwidgets’ package and d3.js. In this section, you will learn how to use functions provided in parallelPlot package to build interactive parallel coordinates plot.\n\n3.1 The basic plot\nThe code chunk below plot an interactive parallel coordinates plot by using parallelPlot().\n\nwh &lt;- wh %&gt;%\n  select(\"Happiness score\", c(7:12))\nparallelPlot(wh,\n             width = 320,\n             height = 250)\n\n\n\n\n\nNotice that some of the axis labels are too long. You will learn how to overcome this problem in the next step.\n\n\n3.2 Rotate axis label\nIn the code chunk below, rotateTitle argument is used to avoid overlapping axis labels.\n\nparallelPlot(wh,\n             rotateTitle = TRUE)\n\n\n\n\n\nOne of the useful interactive feature of parallelPlot is we can click on a variable of interest, for example Happiness score, the monotonous blue colour (default) will change a blues with different intensity colour scheme will be used.\n\n\n3.3 Changing the colour scheme\nWe can change the default blue colour scheme by using continousCS argument as shown in the code chunl below.\n\nparallelPlot(wh,\n             continuousCS = \"YlOrRd\",\n             rotateTitle = TRUE)\n\n\n\n\n\n\n\n3.4 Parallel coordinates plot with histogram\nIn the code chunk below, histoVisibility argument is used to plot histogram along the axis of each variables.\n\nhistoVisibility &lt;- rep(TRUE, ncol(wh))\nparallelPlot(wh,\n             rotateTitle = TRUE,\n             histoVisibility = histoVisibility)"
  },
  {
    "objectID": "Hands-On_Exercise/Hands-On_Exercise05/HE05-2.html",
    "href": "Hands-On_Exercise/Hands-On_Exercise05/HE05-2.html",
    "title": "Hands-On Exercise 05-2",
    "section": "",
    "text": "Correlation coefficient is a popular statistic that use to measure the type and strength of the relationship between two variables. The values of a correlation coefficient ranges between -1.0 and 1.0. A correlation coefficient of 1 shows a perfect linear relationship between the two variables, while a -1.0 shows a perfect inverse relationship between the two variables. A correlation coefficient of 0.0 shows no linear relationship between the two variables.\nWhen multivariate data are used, the correlation coefficeints of the pair comparisons are displayed in a table form known as correlation matrix or scatterplot matrix.\nThere are three broad reasons for computing a correlation matrix.\n\nTo reveal the relationship between high-dimensional variables pair-wisely.\nTo input into other analyses. For example, people commonly use correlation matrices as inputs for exploratory factor analysis, confirmatory factor analysis, structural equation models, and linear regression when excluding missing values pairwise.\nAs a diagnostic when checking other analyses. For example, with linear regression a high amount of correlations suggests that the linear regression’s estimates will be unreliable.\n\nWhen the data is large, both in terms of the number of observations and the number of variables, Corrgram tend to be used to visually explore and analyse the structure and the patterns of relations among variables. It is designed based on two main schemes:\nRendering the value of a correlation to depict its sign and magnitude, and Reordering the variables in a correlation matrix so that “similar” variables are positioned adjacently, facilitating perception. In this hands-on exercise, you will learn how to plot data visualisation for visualising correlation matrix with R. It consists of three main sections. First, you will learn how to create correlation matrix using pairs() of R Graphics. Next, you will learn how to plot corrgram using corrplot package of R. Lastly, you will learn how to create an interactive correlation matrix using plotly R."
  },
  {
    "objectID": "Hands-On_Exercise/Hands-On_Exercise05/HE05-2.html#overview",
    "href": "Hands-On_Exercise/Hands-On_Exercise05/HE05-2.html#overview",
    "title": "Hands-On Exercise 05-2",
    "section": "",
    "text": "Correlation coefficient is a popular statistic that use to measure the type and strength of the relationship between two variables. The values of a correlation coefficient ranges between -1.0 and 1.0. A correlation coefficient of 1 shows a perfect linear relationship between the two variables, while a -1.0 shows a perfect inverse relationship between the two variables. A correlation coefficient of 0.0 shows no linear relationship between the two variables.\nWhen multivariate data are used, the correlation coefficeints of the pair comparisons are displayed in a table form known as correlation matrix or scatterplot matrix.\nThere are three broad reasons for computing a correlation matrix.\n\nTo reveal the relationship between high-dimensional variables pair-wisely.\nTo input into other analyses. For example, people commonly use correlation matrices as inputs for exploratory factor analysis, confirmatory factor analysis, structural equation models, and linear regression when excluding missing values pairwise.\nAs a diagnostic when checking other analyses. For example, with linear regression a high amount of correlations suggests that the linear regression’s estimates will be unreliable.\n\nWhen the data is large, both in terms of the number of observations and the number of variables, Corrgram tend to be used to visually explore and analyse the structure and the patterns of relations among variables. It is designed based on two main schemes:\nRendering the value of a correlation to depict its sign and magnitude, and Reordering the variables in a correlation matrix so that “similar” variables are positioned adjacently, facilitating perception. In this hands-on exercise, you will learn how to plot data visualisation for visualising correlation matrix with R. It consists of three main sections. First, you will learn how to create correlation matrix using pairs() of R Graphics. Next, you will learn how to plot corrgram using corrplot package of R. Lastly, you will learn how to create an interactive correlation matrix using plotly R."
  },
  {
    "objectID": "Hands-On_Exercise/Hands-On_Exercise05/HE05-2.html#getting-started",
    "href": "Hands-On_Exercise/Hands-On_Exercise05/HE05-2.html#getting-started",
    "title": "Hands-On Exercise 05-2",
    "section": "1 Getting Started",
    "text": "1 Getting Started\n\n1.1 Installing and launching R packages\nBefore you get started, you are required to open a new Quarto document. Keep the default html authoring format.\nNext, you will use the code chunk below to install and launch corrplot, ggpubr, plotly and tidyverse in RStudio.\n\npacman::p_load(corrplot, ggstatsplot, tidyverse)\n\n\n\n1.2 Importing and Preparing The Data Set\nIn this hands-on exercise, the Wine Quality Data Set of UCI Machine Learning Repository will be used. The data set consists of 13 variables and 6497 observations. For the purpose of this exercise, we have combined the red wine and white wine data into one data file. It is called wine_quality and is in csv file format.\n\n1.2.1 Importing Data\nFirst, let us import the data into R by using read_csv() of readr package.\n\nwine &lt;- read_csv(\"data/wine_quality.csv\")"
  },
  {
    "objectID": "Hands-On_Exercise/Hands-On_Exercise05/HE05-2.html#building-correlation-matrix-pairs-method",
    "href": "Hands-On_Exercise/Hands-On_Exercise05/HE05-2.html#building-correlation-matrix-pairs-method",
    "title": "Hands-On Exercise 05-2",
    "section": "2 Building Correlation Matrix: pairs() method",
    "text": "2 Building Correlation Matrix: pairs() method\n\n2.1 Introduction\nThere are more than one way to build scatterplot matrix with R. In this section, you will learn how to create a scatterplot matrix by using the pairs function of R Graphics.\nBefore you continue to the next step, you should read the syntax description of pairs function.\n\n\n2.2 Building a basic correlation matrix\nFigure below shows the scatter plot matrix of Wine Quality Data. It is a 11 by 11 matrix.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npairs(wine[,1:11])\n\n\n\n\nThe required input of pairs() can be a matrix or data frame. The code chunk used to create the scatterplot matrix is relatively simple. It uses the default pairs function. Columns 2 to 12 of wine dataframe is used to build the scatterplot matrix. The variables are: fixed acidity, volatile acidity, citric acid, residual sugar, chlorides, free sulfur dioxide, total sulfur dioxide, density, pH, sulphates and alcohol.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npairs(wine[,2:12])\n\n\n\n\n\n\n2.3 Drawing the lower corner\npairs function of R Graphics provided many customisation arguments. For example, it is a common practice to show either the upper half or lower half of the correlation matrix instead of both. This is because a correlation matrix is symmetric.\nTo show the lower half of the correlation matrix, the upper.panel argument will be used as shown in the code chunk below.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npairs(wine[,2:12], upper.panel = NULL)\n\n\n\n\nSimilarly, you can display the upper half of the correlation matrix by using the code chun below.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npairs(wine[,2:12], lower.panel = NULL)\n\n\n\n\n\n\n2.4 Including with correlation coefficients\nTo show the correlation coefficient of each pair of variables instead of a scatter plot, panel.cor function will be used. This will also show higher correlations in a larger font.\nDon’t worry about the details for now-just type this code into your R session or script. Let’s have more fun way to display the correlation matrix.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npanel.cor &lt;- function(x, y, digits=2, prefix=\"\", cex.cor, ...) {\nusr &lt;- par(\"usr\")\non.exit(par(usr))\npar(usr = c(0, 1, 0, 1))\nr &lt;- abs(cor(x, y, use=\"complete.obs\"))\ntxt &lt;- format(c(r, 0.123456789), digits=digits)[1]\ntxt &lt;- paste(prefix, txt, sep=\"\")\nif(missing(cex.cor)) cex.cor &lt;- 0.8/strwidth(txt)\ntext(0.5, 0.5, txt, cex = cex.cor * (1 + r) / 2)\n}\n\npairs(wine[,2:12], \n      upper.panel = panel.cor)"
  },
  {
    "objectID": "Hands-On_Exercise/Hands-On_Exercise05/HE05-2.html#visualising-correlation-matrix-ggcormat",
    "href": "Hands-On_Exercise/Hands-On_Exercise05/HE05-2.html#visualising-correlation-matrix-ggcormat",
    "title": "Hands-On Exercise 05-2",
    "section": "3 Visualising Correlation Matrix: ggcormat()",
    "text": "3 Visualising Correlation Matrix: ggcormat()\n\n3.1 Introduction\nOne of the major limitation of the correlation matrix is that the scatter plots appear very cluttered when the number of observations is relatively large (i.e. more than 500 observations). To over come this problem, Corrgram data visualisation technique suggested by D. J. Murdoch and E. D. Chow (1996) and Friendly, M (2002) and will be used.\nThe are at least three R packages provide function to plot corrgram, they are:\n\ncorrgram\nellipse\ncorrplot\n\nOn top that, some R package like ggstatsplot package also provides functions for building corrgram.\nIn this section, you will learn how to visualising correlation matrix by using ggcorrmat() of ggstatsplot package.\n\n\n3.2 The basic plot\nOn of the advantage of using ggcorrmat() over many other methods to visualise a correlation matrix is it’s ability to provide a comprehensive and yet professional statistical report as shown in the figure below.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggstatsplot::ggcorrmat(\n  data = wine, \n  cor.vars = 1:11)\n\n\n\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggstatsplot::ggcorrmat(\n  data = wine, \n  cor.vars = 1:11,\n  ggcorrplot.args = list(outline.color = \"black\", \n                         hc.order = TRUE,\n                         tl.cex = 10),\n  title    = \"Correlogram for wine dataset\",\n  subtitle = \"Four pairs are no significant at p &lt; 0.05\"\n)\n\n\n\n\nThings to learn from the code chunk above:\n\ncor.vars argument is used to compute the correlation matrix needed to build the corrgram.\nggcorrplot.args argument provide additional (mostly aesthetic) arguments that will be passed to ggcorrplot::ggcorrplot function. The list should avoid any of the following arguments since they are already internally being used: corr, method, p.mat, sig.level, ggtheme, colors, lab, pch, legend.title, digits.\n\nThe sample sub-code chunk can be used to control specific component of the plot such as the font size of the x-axis, y-axis, and the statistical report.\n\nggplot.component = list(\n    theme(text=element_text(size=5),\n      axis.text.x = element_text(size = 8),\n      axis.text.y = element_text(size = 8)))"
  },
  {
    "objectID": "Hands-On_Exercise/Hands-On_Exercise05/HE05-2.html#building-multiple-plots",
    "href": "Hands-On_Exercise/Hands-On_Exercise05/HE05-2.html#building-multiple-plots",
    "title": "Hands-On Exercise 05-2",
    "section": "4 Building multiple plots",
    "text": "4 Building multiple plots\nSince ggstasplot is an extension of ggplot2, it also supports faceting. However the feature is not available in ggcorrmat() but in the grouped_ggcorrmat() of ggstatsplot.\n\ngrouped_ggcorrmat(\n  data = wine,\n  cor.vars = 1:11,\n  grouping.var = type,\n  type = \"robust\",\n  p.adjust.method = \"holm\",\n  plotgrid.args = list(ncol = 2),\n  ggcorrplot.args = list(outline.color = \"black\", \n                         hc.order = TRUE,\n                         tl.cex = 10),\n  annotation.args = list(\n    tag_levels = \"a\",\n    title = \"Correlogram for wine dataset\",\n    subtitle = \"The measures are: alcohol, sulphates, fixed acidity, citric acid, chlorides, residual sugar, density, free sulfur dioxide and volatile acidity\",\n    caption = \"Dataset: UCI Machine Learning Repository\"\n  )\n)\n\n\n\n\npicture\n\n\nThings to learn from the code chunk above:\n\nto build a facet plot, the only argument needed is grouping.var.\nBehind group_ggcorrmat(), patchwork package is used to create the multiplot. plotgrid.args argument provides a list of additional arguments passed to patchwork::wrap_plots, except for guides argument which is already separately specified earlier.\nLikewise, annotation.args argument is calling plot annotation arguments of patchwork package."
  },
  {
    "objectID": "Hands-On_Exercise/Hands-On_Exercise05/HE05-2.html#visualising-correlation-matrix-using-corrplot-package",
    "href": "Hands-On_Exercise/Hands-On_Exercise05/HE05-2.html#visualising-correlation-matrix-using-corrplot-package",
    "title": "Hands-On Exercise 05-2",
    "section": "5 Visualising Correlation Matrix using corrplot Package",
    "text": "5 Visualising Correlation Matrix using corrplot Package\n\n5.1 Introduction\nIn this hands-on exercise, we will focus on corrplot. However, you are encouraged to explore the other two packages too.\nBefore getting started, you are required to read An Introduction to corrplot Package in order to gain basic understanding of corrplot package.\n\n\n5.2 Getting started with corrplot\nBefore we can plot a corrgram using corrplot(), we need to compute the correlation matrix of wine data frame.\nIn the code chunk below, cor() of R Stats is used to compute the correlation matrix of wine data frame.\n\nwine.cor &lt;- cor(wine[, 1:11])\n\nNext, corrplot() is used to plot the corrgram by using all the default setting as shown in the code chunk below.\n\ncorrplot(wine.cor)\n\n\n\n\n\n\n\n\nNotice that the default visual object used to plot the corrgram is circle. The default layout of the corrgram is a symmetric matrix. The default colour scheme is diverging blue-red. Blue colours are used to represent pair variables with positive correlation coefficients and red colours are used to represent pair variables with negative correlation coefficients. The intensity of the colour or also know as saturation is used to represent the strength of the correlation coefficient. Darker colours indicate relatively stronger linear relationship between the paired variables. On the other hand, lighter colours indicates relatively weaker linear relationship.\n\n\n5.3 Working with visual geometrics\nIn corrplot package, there are seven visual geometrics (parameter method) can be used to encode the attribute values. They are: circle, square, ellipse, number, shade, color and pie. The default is circle. As shown in the previous section, the default visual geometric of corrplot matrix is circle. However, this default setting can be changed by using the method argument as shown in the code chunk below.\n\ncorrplot(wine.cor, \n         method = \"ellipse\") \n\n\n\n\n\n\n\n\n\ncorrplot(wine.cor, \n         method = \"number\") \n\n\n\n\n\n\n\n\n\ncorrplot(wine.cor, \n         method = \"pie\") \n\n\n\n\n\n\n\n\n\n\n5.4 Working with layout\ncorrplor() supports three layout types, namely: “full”, “upper” or “lower”. The default is “full” which display full matrix. The default setting can be changed by using the type argument of corrplot().\n\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         type=\"lower\")\n\n\n\n\n\n\n\n\nThe default layout of the corrgram can be further customised. For example, arguments diag and tl.col are used to turn off the diagonal cells and to change the axis text label colour to black colour respectively as shown in the code chunk and figure below.\n\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         type=\"lower\",\n         diag = FALSE,\n         tl.col = \"black\")\n\n\n\n\n\n\n\n\n\n\n5.5 Working with mixed layout\nWith corrplot package, it is possible to design corrgram with mixed visual matrix of one half and numerical matrix on the other half. In order to create a coorgram with mixed layout, the corrplot.mixed(), a wrapped function for mixed visualisation style will be used.\nFigure below shows a mixed layout corrgram plotted using wine quality data.\n\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"black\")\n\n\n\n\n\n\n\n\n\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"black\")\n\n\n\n\n\n\n\n\nNotice that argument lower and upper are used to define the visualisation method used. In this case ellipse is used to map the lower half of the corrgram and numerical matrix (i.e. number) is used to map the upper half of the corrgram. The argument tl.pos, on the other, is used to specify the placement of the axis label. Lastly, the diag argument is used to specify the glyph on the principal diagonal of the corrgram.\n\n\n5.6 Combining corrgram with the significant test\nIn statistical analysis, we are also interested to know which pair of variables their correlation coefficients are statistically significant.\nFigure below shows a corrgram combined with the significant test. The corrgram reveals that not all correlation pairs are statistically significant. For example the correlation between total sulfur dioxide and free surfur dioxide is statistically significant at significant level of 0.1 but not the pair between total sulfur dioxide and citric acid.\n\n\n\npicture\n\n\nWith corrplot package, we can use the cor.mtest() to compute the p-values and confidence interval for each pair of variables.\n\nwine.sig = cor.mtest(wine.cor, conf.level= .95)\n\nWe can then use the p.mat argument of corrplot function as shown in the code chunk below.\n\ncorrplot(wine.cor,\n         method = \"number\",\n         type = \"lower\",\n         diag = FALSE,\n         tl.col = \"black\",\n         tl.srt = 45,\n         p.mat = wine.sig$p,\n         sig.level = .05)\n\n\n\n\n\n\n\n\n\n\n5.7 Reorder a corrgram\nMatrix reorder is very important for mining the hiden structure and pattern in a corrgram. By default, the order of attributes of a corrgram is sorted according to the correlation matrix (i.e. “original”). The default setting can be over-write by using the order argument of corrplot(). Currently, corrplot package support four sorting methods, they are:\n\n“AOE” is for the angular order of the eigenvectors. See Michael Friendly (2002) for details.\n“FPC” for the first principal component order.\n“hclust” for hierarchical clustering order, and “hclust.method” for the agglomeration method to be used.\n\n“hclust.method” should be one of “ward”, “single”, “complete”, “average”, “mcquitty”, “median” or “centroid”.\n\n“alphabet” for alphabetical order.\n\n“AOE”, “FPC”, “hclust”, “alphabet”. More algorithms can be found in seriation package.\n\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               order=\"AOE\",\n               tl.col = \"black\")\n\n\n\n\n\n\n\n\n\n\n5.8 Reordering a correlation matrix using hclust\nIf using hclust, corrplot() can draw rectangles around the corrgram based on the results of hierarchical clustering.\n\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         tl.pos = \"lt\",\n         tl.col = \"black\",\n         order=\"hclust\",\n         hclust.method = \"ward.D\",\n         addrect = 3)\n\n\n\n\n\n\n\n\n\ncorrplot(wine.cor, \n         method = \"shade\", \n         tl.pos = \"lt\",\n         tl.col = \"black\",\n         order=\"hclust\",\n         hclust.method = \"average\",\n         addrect = 8)"
  },
  {
    "objectID": "Hands-On_Exercise/Hands-On_Exercise04/HE04-4.html",
    "href": "Hands-On_Exercise/Hands-On_Exercise04/HE04-4.html",
    "title": "Hands-On Exercise 04-4",
    "section": "",
    "text": "Funnel plot is a specially designed data visualisation for conducting unbiased comparison between outlets, stores or business entities. By the end of this hands-on exercise, you will gain hands-on experience on:\n\nplotting funnel plots by using funnelPlotR package,\nplotting static funnel plot by using ggplot2 package, and\nplotting interactive funnel plot by using both plotly R and ggplot2 packages."
  },
  {
    "objectID": "Hands-On_Exercise/Hands-On_Exercise04/HE04-4.html#overview",
    "href": "Hands-On_Exercise/Hands-On_Exercise04/HE04-4.html#overview",
    "title": "Hands-On Exercise 04-4",
    "section": "",
    "text": "Funnel plot is a specially designed data visualisation for conducting unbiased comparison between outlets, stores or business entities. By the end of this hands-on exercise, you will gain hands-on experience on:\n\nplotting funnel plots by using funnelPlotR package,\nplotting static funnel plot by using ggplot2 package, and\nplotting interactive funnel plot by using both plotly R and ggplot2 packages."
  },
  {
    "objectID": "Hands-On_Exercise/Hands-On_Exercise04/HE04-4.html#getting-started",
    "href": "Hands-On_Exercise/Hands-On_Exercise04/HE04-4.html#getting-started",
    "title": "Hands-On Exercise 04-4",
    "section": "1 Getting Started",
    "text": "1 Getting Started\n\n1.1 Installing and loading the packages\nIn this exercise, four R packages will be used. They are:\n\nreadr for importing csv into R.\nFunnelPlotR for creating funnel plot.\nggplot2 for creating funnel plot manually.\nknitr for building static html table.\nplotly for creating interactive funnel plot.\n\n\npacman::p_load(tidyverse, FunnelPlotR, plotly, knitr)\n\n\n\n1.2 Importing Data\nIn this section, COVID-19_DKI_Jakarta will be used. The data was downloaded from Open Data Covid-19 Provinsi DKI Jakarta portal. For this hands-on exercise, we are going to compare the cumulative COVID-19 cases and death by sub-district (i.e. kelurahan) as at 31st July 2021, DKI Jakarta.\nThe code chunk below imports the data into R and save it into a tibble data frame object called covid19.\n\nTableCode\n\n\n\n\n\n\n\nSub-district ID\nCity\nDistrict\nSub-district\nPositive\nRecovered\nDeath\n\n\n\n\n3172051003\nJAKARTA UTARA\nPADEMANGAN\nANCOL\n1776\n1691\n26\n\n\n3173041007\nJAKARTA BARAT\nTAMBORA\nANGKE\n1783\n1720\n29\n\n\n3175041005\nJAKARTA TIMUR\nKRAMAT JATI\nBALE KAMBANG\n2049\n1964\n31\n\n\n3175031003\nJAKARTA TIMUR\nJATINEGARA\nBALI MESTER\n827\n797\n13\n\n\n3175101006\nJAKARTA TIMUR\nCIPAYUNG\nBAMBU APUS\n2866\n2792\n27\n\n\n3174031002\nJAKARTA SELATAN\nMAMPANG PRAPATAN\nBANGKA\n1828\n1757\n26\n\n\n\n\n\n\n\n\ncovid19 &lt;- read_csv(\"data/COVID-19_DKI_Jakarta.csv\") %&gt;%\n  mutate_if(is.character, as.factor)"
  },
  {
    "objectID": "Hands-On_Exercise/Hands-On_Exercise04/HE04-4.html#funnelplotr-methods",
    "href": "Hands-On_Exercise/Hands-On_Exercise04/HE04-4.html#funnelplotr-methods",
    "title": "Hands-On Exercise 04-4",
    "section": "2 FunnelPlotR methods",
    "text": "2 FunnelPlotR methods\n\n2.1 Introduction\nFunnelPlotR package uses ggplot to generate funnel plots. It requires a numerator (events of interest), denominator (population to be considered) and group. The key arguments selected for customisation are:\n\nlimit: plot limits (95 or 99).\nlabel_outliers: to label outliers (true or false).\nPoisson_limits: to add Poisson limits to the plot.\nOD_adjust: to add overdispersed limits to the plot.\nxrange and yrange: to specify the range to display for axes, acts like a zoom function.\nOther aesthetic components such as graph title, axis labels etc.\n\n\n\n2.2 FunnelPlotR methods: The basic plot\nThe code chunk below plots a funnel plot.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 0 are outliers. \nPlot is adjusted for overdispersion. \n\n\n\n\n\nfunnel_plot(\n  .data = covid19,\n  numerator = Positive,\n  denominator = Death,\n  group = `Sub-district`\n)\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\ngroup in this function is different from the scatterplot. Here, it defines the level of the points to be plotted i.e. Sub-district, District or City. If Cityc is chosen, there are only six data points.\nBy default, data_type argument is “SR”.\nlimit: Plot limits, accepted values are: 95 or 99, corresponding to 95% or 99.8% quantiles of the distribution.\n\n\n\n\n\n2.3 FunnelPlotR methods: Makeover 1\nThe code chunk below plots a funnel plot.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \n\n\n\n\n\nfunnel_plot(\n  .data = covid19,\n  numerator = Death,\n  denominator = Positive,\n  group = `Sub-district`,\n  data_type = \"PR\",     #&lt;&lt;\n  xrange = c(0, 6500),  #&lt;&lt;\n  yrange = c(0, 0.05)   #&lt;&lt;\n)\n\n\n\n\nThings to learn from the code chunk above. + data_type argument is used to change from default “SR” to “PR” (i.e. proportions). + xrange and yrange are used to set the range of x-axis and y-axis\n\n\n2.4 FunnelPlotR methods: Makeover 2\nThe code chunk below plots a funnel plot.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \n\n\n\n\n\nfunnel_plot(\n  .data = covid19,\n  numerator = Death,\n  denominator = Positive,\n  group = `Sub-district`,\n  data_type = \"PR\",   \n  xrange = c(0, 6500),  \n  yrange = c(0, 0.05),\n  label = NA,\n  title = \"Cumulative COVID-19 Fatality Rate by Cumulative Total Number of COVID-19 Positive Cases\", #&lt;&lt;           \n  x_label = \"Cumulative COVID-19 Positive Cases\", #&lt;&lt;\n  y_label = \"Cumulative Fatality Rate\"  #&lt;&lt;\n)\n\n\n\n\nThings to learn from the code chunk above.\n\nlabel = NA argument is to removed the default label outliers feature.\ntitle argument is used to add plot title.\nx_label and y_label arguments are used to add/edit x-axis and y-axis titles."
  },
  {
    "objectID": "Hands-On_Exercise/Hands-On_Exercise04/HE04-4.html#funnel-plot-for-fair-visual-comparison-ggplot2-methods",
    "href": "Hands-On_Exercise/Hands-On_Exercise04/HE04-4.html#funnel-plot-for-fair-visual-comparison-ggplot2-methods",
    "title": "Hands-On Exercise 04-4",
    "section": "3 Funnel Plot for Fair Visual Comparison: ggplot2 methods",
    "text": "3 Funnel Plot for Fair Visual Comparison: ggplot2 methods\nIn this section, you will gain hands-on experience on building funnel plots step-by-step by using ggplot2. It aims to enhance you working experience of ggplot2 to customise speciallised data visualisation like funnel plot.\n\n3.1 Computing the basic derived fields\nTo plot the funnel plot from scratch, we need to derive cumulative death rate and standard error of cumulative death rate.\n\ndf &lt;- covid19 %&gt;%\n  mutate(rate = Death / Positive) %&gt;%\n  mutate(rate.se = sqrt((rate*(1-rate)) / (Positive))) %&gt;%\n  filter(rate &gt; 0)\n\nNext, the fit.mean is computed by using the code chunk below.\n\nfit.mean &lt;- weighted.mean(df$rate, 1/df$rate.se^2)\n\n\n\n3.2 Calculate lower and upper limits for 95% and 99.9% CI\nThe code chunk below is used to compute the lower and upper limits for 95% confidence interval.\n\nnumber.seq &lt;- seq(1, max(df$Positive), 1)\nnumber.ll95 &lt;- fit.mean - 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul95 &lt;- fit.mean + 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ll999 &lt;- fit.mean - 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul999 &lt;- fit.mean + 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \ndfCI &lt;- data.frame(number.ll95, number.ul95, number.ll999, \n                   number.ul999, number.seq, fit.mean)\n\n\n\n3.3 Plotting a static funnel plot\nIn the code chunk below, ggplot2 functions are used to plot a static funnel plot.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\np &lt;- ggplot(df, aes(x = Positive, y = rate)) +\n  geom_point(aes(label=`Sub-district`), \n             alpha=0.4) +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll95), \n            size = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul95), \n            size = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll999), \n            size = 0.4, \n            colour = \"grey40\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul999), \n            size = 0.4, \n            colour = \"grey40\") +\n  geom_hline(data = dfCI, \n             aes(yintercept = fit.mean), \n             size = 0.4, \n             colour = \"grey40\") +\n  coord_cartesian(ylim=c(0,0.05)) +\n  annotate(\"text\", x = 1, y = -0.13, label = \"95%\", size = 3, colour = \"grey40\") + \n  annotate(\"text\", x = 4.5, y = -0.18, label = \"99%\", size = 3, colour = \"grey40\") + \n  ggtitle(\"Cumulative Fatality Rate by Cumulative Number of COVID-19 Cases\") +\n  xlab(\"Cumulative Number of COVID-19 Cases\") + \n  ylab(\"Cumulative Fatality Rate\") +\n  theme_light() +\n  theme(plot.title = element_text(size=12),\n        legend.position = c(0.91,0.85), \n        legend.title = element_text(size=7),\n        legend.text = element_text(size=7),\n        legend.background = element_rect(colour = \"grey60\", linetype = \"dotted\"),\n        legend.key.height = unit(0.3, \"cm\"))\np\n\n\n\n\n\n\n3.4 Interactive Funnel Plot: plotly + ggplot2\nThe funnel plot created using ggplot2 functions can be made interactive with ggplotly() of plotly r package.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\nfp_ggplotly &lt;- ggplotly(p,\n  tooltip = c(\"label\", \n              \"x\", \n              \"y\"))\nfp_ggplotly"
  },
  {
    "objectID": "Hands-On_Exercise/Hands-On_Exercise04/HE04-2.html",
    "href": "Hands-On_Exercise/Hands-On_Exercise04/HE04-2.html",
    "title": "Hands-On Exercise 04-2",
    "section": "",
    "text": "In this hands-on exercise, you will gain hands-on experience on using:\n\nggstatsplot package to create visual graphics with rich statistical information,\nperformance package to visualise model diagnostics, and\nparameters package to visualise model parameters"
  },
  {
    "objectID": "Hands-On_Exercise/Hands-On_Exercise04/HE04-2.html#overview",
    "href": "Hands-On_Exercise/Hands-On_Exercise04/HE04-2.html#overview",
    "title": "Hands-On Exercise 04-2",
    "section": "",
    "text": "In this hands-on exercise, you will gain hands-on experience on using:\n\nggstatsplot package to create visual graphics with rich statistical information,\nperformance package to visualise model diagnostics, and\nparameters package to visualise model parameters"
  },
  {
    "objectID": "Hands-On_Exercise/Hands-On_Exercise04/HE04-2.html#introduction",
    "href": "Hands-On_Exercise/Hands-On_Exercise04/HE04-2.html#introduction",
    "title": "Hands-On Exercise 04-2",
    "section": "1 Introduction",
    "text": "1 Introduction\n\n1.1 Visual Statistical Analysis with ggstatsplot\nggstatsplot is an extension of ggplot2 package for creating graphics with details from statistical tests included in the information-rich plots themselves.\n\nTo provide alternative statistical inference methods by default.\nTo follow best practices for statistical reporting. For all statistical tests reported in the plots, the default template abides by the APA gold standard for statistical reporting. For example, here are results from a robust t-test:\n\n\n\n\nggstatsplot\n\n\n\n\n1.2 Installing and launching R packages\nIn this exercise, ggstatsplot and tidyverse will be used.\n\npacman::p_load(ggstatsplot, tidyverse)\n\n\n\n1.3 Data import\nFor the purpose of this exercise, Exam_data.csv will be used.\nIn the code chunk below, read_csv() of readr package is used to import Exam_data.csv into R and saved it into a tibble data.frame.\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-On_Exercise/Hands-On_Exercise04/HE04-2.html#visual-statistical-analysis-with-ggstatsplot-1",
    "href": "Hands-On_Exercise/Hands-On_Exercise04/HE04-2.html#visual-statistical-analysis-with-ggstatsplot-1",
    "title": "Hands-On Exercise 04-2",
    "section": "2 Visual Statistical Analysis with ggstatsplot",
    "text": "2 Visual Statistical Analysis with ggstatsplot\n\n2.1 One-sample test: gghistostats() method\nIn the code chunk below, gghistostats() is used to to build an visual of one-sample test on English scores.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nset.seed(1234)\n\ngghistostats(\n  data = exam,\n  x = ENGLISH,\n  type = \"bayes\",\n  test.value = 60,\n  xlab = \"English scores\"\n)\n\n\n\n\nDefault information: - statistical details - Bayes Factor - sample sizes - distribution summary\n\n\n2.2 Unpacking the Bayes Factor\n\nA Bayes factor is the ratio of the likelihood of one particular hypothesis to the likelihood of another. It can be interpreted as a measure of the strength of evidence in favor of one theory among two competing theories.\nThat’s because the Bayes factor gives us a way to evaluate the data in favor of a null hypothesis, and to use external information to do so. It tells us what the weight of the evidence is in favor of a given hypothesis.\nWhen we are comparing two hypotheses, H1 (the alternate hypothesis) and H0 (the null hypothesis), the Bayes Factor is often written as B10. It can be defined mathematically as\n\n The Schwarz criterion is one of the easiest ways to calculate rough approximation of the Bayes Factor.\n\n\n2.3 How to interpret Bayes Factor\nA Bayes Factor can be any positive number. One of the most common interpretations is this one—first proposed by Harold Jeffereys (1961) and slightly modified by Lee and Wagenmakers in 2013:\n ### 2.4 Two-sample mean test: ggbetweenstats()\nIn the code chunk below, ggbetweenstats() is used to build a visual for two-sample mean test of Maths scores by gender.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggbetweenstats(\n  data = exam,\n  x = GENDER, \n  y = MATHS,\n  type = \"np\",\n  messages = FALSE\n)\n\n\n\n\nDefault information: - statistical details - Bayes Factor - sample sizes - distribution summary\n\n\n2.5 Oneway ANOVA Test: ggbetweenstats() method\nIn the code chunk below, ggbetweenstats() is used to build a visual for One-way ANOVA test on English score by race.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggbetweenstats(\n  data = exam,\n  x = RACE, \n  y = ENGLISH,\n  type = \"p\",\n  mean.ci = TRUE, \n  pairwise.comparisons = TRUE, \n  pairwise.display = \"s\",\n  p.adjust.method = \"fdr\",\n  messages = FALSE\n)\n\n\n\n\n\n“ns” → only non-significant\n“s” → only significant\n“all” → everything\n\n\n\n2.6 ggbetweenstats - Summary of tests\n  \n\n\n2.7 Significant Test of Correlation: ggscatterstats()\nIn the code chunk below, ggscatterstats() is used to build a visual for Significant Test of Correlation between Maths scores and English scores.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggscatterstats(\n  data = exam,\n  x = MATHS,\n  y = ENGLISH,\n  marginal = FALSE,\n  )\n\n\n\n\n\n\n2.8 Significant Test of Association (Depedence) : ggbarstats() methods\nIn the code chunk below, the Maths scores is binned into a 4-class variable by using cut().\n\nexam1 &lt;- exam %&gt;% \n  mutate(MATHS_bins = \n           cut(MATHS, \n               breaks = c(0,60,75,85,100))\n)\n\nIn this code chunk below ggbarstats() is used to build a visual for Significant Test of Association\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggbarstats(exam1, \n           x = MATHS_bins, \n           y = GENDER)"
  },
  {
    "objectID": "Hands-On_Exercise/Hands-On_Exercise03/HE03-2.html",
    "href": "Hands-On_Exercise/Hands-On_Exercise03/HE03-2.html",
    "title": "Hands-On Exercise 03-2",
    "section": "",
    "text": "When telling a visually-driven data story, animated graphics tends to attract the interest of the audience and make deeper impression than static graphics. In this hands-on exercise, we will learn how to create animated data visualisation by using gganimate and plotly r packages. At the same time, you will also learn how to (i) reshape data by using tidyr package, and (ii) process, wrangle and transform data by using dplyr package."
  },
  {
    "objectID": "Hands-On_Exercise/Hands-On_Exercise03/HE03-2.html#overview",
    "href": "Hands-On_Exercise/Hands-On_Exercise03/HE03-2.html#overview",
    "title": "Hands-On Exercise 03-2",
    "section": "",
    "text": "When telling a visually-driven data story, animated graphics tends to attract the interest of the audience and make deeper impression than static graphics. In this hands-on exercise, we will learn how to create animated data visualisation by using gganimate and plotly r packages. At the same time, you will also learn how to (i) reshape data by using tidyr package, and (ii) process, wrangle and transform data by using dplyr package."
  },
  {
    "objectID": "Hands-On_Exercise/Hands-On_Exercise03/HE03-2.html#basic-concepts-of-animation",
    "href": "Hands-On_Exercise/Hands-On_Exercise03/HE03-2.html#basic-concepts-of-animation",
    "title": "Hands-On Exercise 03-2",
    "section": "1 Basic concepts of animation",
    "text": "1 Basic concepts of animation\nWhen creating animations, the plot does not actually move. Instead, many individual plots are built and then stitched together as movie frames, just like an old-school flip book or cartoon. Each frame is a different plot when conveying motion, which is built using some relevant subset of the aggregate data. The subset drives the flow of the animation when stitched back together.\n\n\n\nanimation"
  },
  {
    "objectID": "Hands-On_Exercise/Hands-On_Exercise03/HE03-2.html#terminology",
    "href": "Hands-On_Exercise/Hands-On_Exercise03/HE03-2.html#terminology",
    "title": "Hands-On Exercise 03-2",
    "section": "2 Terminology",
    "text": "2 Terminology\nBefore we dive into the steps for creating an animated statistical graph, it’s important to understand some of the key concepts and terminology related to this type of visualization.\n\nFrame: In an animated line graph, each frame represents a different point in time or a different category. When the frame changes, the data points on the graph are updated to reflect the new data.\nAnimation Attributes: The animation attributes are the settings that control how the animation behaves. For example, you can specify the duration of each frame, the easing function used to transition between frames, and whether to start the animation from the current frame or from the beginning.\n\n\n\n\n\n\n\nNote\n\n\n\n\nEffort vs. Value High effort required. Ask first: Does the extra work translate into proportional value?\nKey Scenarios\n\n\nEDA : Internal Efficiency. Prioritize speed and accuracy. Use static charts unless animation reveals insights that statics cannot.\nPresentation : External Impact. Animation is for storytelling. It guides the audience and creates a stronger connection than static figures."
  },
  {
    "objectID": "Hands-On_Exercise/Hands-On_Exercise03/HE03-2.html#getting-started",
    "href": "Hands-On_Exercise/Hands-On_Exercise03/HE03-2.html#getting-started",
    "title": "Hands-On Exercise 03-2",
    "section": "3 Getting Started",
    "text": "3 Getting Started\n\n3.1 Loading R packages\nNote: Ensure that the gifski, plotly, gganimate, tidyverse, gapminder package has already been installed.\nThe code chunk below uses\n\nplotly, R library for plotting interactive statistical graphs.\ngganimate, an ggplot extension for creating animated statistical graphs.\ngifski converts video frames to GIF animations using pngquant’s fancy features for efficient cross-frame palettes and temporal dithering. It produces animated GIFs that use thousands of colors per frame.\ngapminder: An excerpt of the data available at Gapminder.org. We just want to use its country_colors scheme.\ntidyverse, a family of modern R packages specially designed to support data science, analysis and communication task including creating static statistical graphs.\n\n\npacman::p_load(readxl, gifski, gapminder,\n               plotly, gganimate, tidyverse)\n\n\n\n3.2 Importing the data\nIn this hands-on exercise, the Data worksheet from GlobalPopulation Excel workbook will be used.\nWrite a code chunk to import Data worksheet from GlobalPopulation Excel workbook by using appropriate R package from tidyverse family.\n\ncol &lt;- c(\"Country\", \"Continent\")\nglobalPop &lt;- read_xls(\"data/GlobalPopulation.xls\",\n                      sheet=\"Data\") %&gt;%\n  mutate_each_(funs(factor(.)), col) %&gt;%\n  mutate(Year = as.integer(Year))\n\n\n\n\n\n\n\nNote\n\n\n\n\nread_xls() of readxl package is used to import the Excel worksheet.\nmutate_each_() of dplyr package is used to convert all character data type into factor.\nmutate of dplyr package is used to convert data values of Year field into integer.\n\n\n\nUnfortunately, mutate_each_() was deprecated in dplyr 0.7.0. and funs() was deprecated in dplyr 0.8.0. In view of this, we will re-write the code by using mutate_at() as shown in the code chunk below.\n\ncol &lt;- c(\"Country\", \"Continent\")\nglobalPop &lt;- read_xls(\"data/GlobalPopulation.xls\",\n                      sheet=\"Data\") %&gt;%\n  mutate_at(col, as.factor) %&gt;%\n  mutate(Year = as.integer(Year))\n\nInstead of using mutate_at(), across() can be used to derive the same outputs.\n\ncol &lt;- c(\"Country\", \"Continent\")\nglobalPop &lt;- read_xls(\"data/GlobalPopulation.xls\",\n                      sheet=\"Data\") %&gt;%\n  mutate(across(col, as.factor)) %&gt;%\n  mutate(Year = as.integer(Year))"
  },
  {
    "objectID": "Hands-On_Exercise/Hands-On_Exercise03/HE03-2.html#animated-data-visualisation-gganimate-methods",
    "href": "Hands-On_Exercise/Hands-On_Exercise03/HE03-2.html#animated-data-visualisation-gganimate-methods",
    "title": "Hands-On Exercise 03-2",
    "section": "4 Animated Data Visualisation: gganimate methods",
    "text": "4 Animated Data Visualisation: gganimate methods\n\n4.1 Introduction\ngganimate extends the grammar of graphics as implemented by ggplot2 to include the description of animation. It does this by providing a range of new grammar classes that can be added to the plot object in order to customise how it should change with time.\n\ntransition_*() defines how the data should be spread out and how it relates to itself across time.\nview_*() defines how the positional scales should change along the animation.\nshadow_*() defines how data from other points in time should be presented in the given point in time.\nenter_*()/exit_*() defines how new data should appear and how old data should disappear during the course of the animation.\nease_aes() defines how different aesthetics should be eased during transitions.\n\n\n\n4.2 Building a static population bubble plot\nBelow the basic ggplot2 functions are used to create a static bubble plot\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(globalPop, aes(x = Old, y = Young, \n                      size = Population, \n                      colour = Country)) +\n  geom_point(alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(title = 'Year: {frame_time}', \n       x = '% Aged', \n       y = '% Young') \n\n\n\n\n\n\n4.3 Building the animated bubble plot\nIn the code chunk below,\n\ntransition_time() of gganimate is used to create transition through distinct states in time (i.e. Year).\nease_aes() is used to control easing of aesthetics. The default is linear. Other methods are: quadratic, cubic, quartic, quintic, sine, circular, exponential, elastic, back, and bounce.\n\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(globalPop, aes(x = Old, y = Young, \n                      size = Population, \n                      colour = Country)) +\n  geom_point(alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(title = 'Year: {frame_time}', \n       x = '% Aged', \n       y = '% Young') +\n  transition_time(Year) +       \n  ease_aes('linear')"
  },
  {
    "objectID": "Hands-On_Exercise/Hands-On_Exercise03/HE03-2.html#animated-data-visualisation-plotly",
    "href": "Hands-On_Exercise/Hands-On_Exercise03/HE03-2.html#animated-data-visualisation-plotly",
    "title": "Hands-On Exercise 03-2",
    "section": "5 Animated Data Visualisation: plotly",
    "text": "5 Animated Data Visualisation: plotly\n\n5.1 Introduction\nIn Plotly R package, both ggplotly() and plot_ly() support key frame animations through the frame argument/aesthetic. They also support an ids argument/aesthetic to ensure smooth transitions between objects with the same id (which helps facilitate object constancy).\n\n\n5.2 Building an animated bubble plot: ggplotly() method\nIn this sub-section, we will learn how to create an animated bubble plot by using ggplotly() method.\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\ngg &lt;- ggplot(globalPop, \n       aes(x = Old, \n           y = Young, \n           size = Population, \n           colour = Country)) +\n  geom_point(aes(size = Population,\n                 frame = Year),\n             alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(x = '% Aged', \n       y = '% Young')\n\nggplotly(gg)\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nAppropriate ggplot2 functions are used to create a static bubble plot. The output is then saved as an R object called gg.\nggplotly() is then used to convert the R graphic object into an animated svg object.\n\n\n\nNotice that although show.legend = FALSE argument was used, the legend still appears on the plot. To overcome this problem, theme(legend.position='none') should be used as shown in the plot and code chunk below.\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\ngg &lt;- ggplot(globalPop, \n       aes(x = Old, \n           y = Young, \n           size = Population, \n           colour = Country)) +\n  geom_point(aes(size = Population,\n                 frame = Year),\n             alpha = 0.7) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(x = '% Aged', \n       y = '% Young') + \n  theme(legend.position='none')\n\nggplotly(gg)\n\n\n\n\n\n\n5.3 Building an animated bubble plot: plot_ly() method\nIn this sub-section, you will learn how to create an animated bubble plot by using plot_ly() method.\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\nbp &lt;- globalPop %&gt;%\n  plot_ly(x = ~Old, \n          y = ~Young, \n          size = ~Population, \n          color = ~Continent,\n          sizes = c(2, 100),\n          frame = ~Year, \n          text = ~Country, \n          hoverinfo = \"text\",\n          type = 'scatter',\n          mode = 'markers'\n          ) %&gt;%\n  layout(showlegend = FALSE)\nbp"
  },
  {
    "objectID": "Hands-On_Exercise/Hands-On_Exercise02/HE02.html",
    "href": "Hands-On_Exercise/Hands-On_Exercise02/HE02.html",
    "title": "Hands-On Exercise 02",
    "section": "",
    "text": "In this chapter, you will be introduced to several ggplot2 extensions for creating more elegant and effective statistical graphics. By the end of this exercise, you will be able to:\n\ncontrol the placement of annotation on a graph by using functions provided in ggrepel package,\ncreate professional publication quality figure by using functions provided in ggthemes and hrbrthemes packages,\nplot composite figure by combining ggplot2 graphs by using patchwork package."
  },
  {
    "objectID": "Hands-On_Exercise/Hands-On_Exercise02/HE02.html#overview",
    "href": "Hands-On_Exercise/Hands-On_Exercise02/HE02.html#overview",
    "title": "Hands-On Exercise 02",
    "section": "",
    "text": "In this chapter, you will be introduced to several ggplot2 extensions for creating more elegant and effective statistical graphics. By the end of this exercise, you will be able to:\n\ncontrol the placement of annotation on a graph by using functions provided in ggrepel package,\ncreate professional publication quality figure by using functions provided in ggthemes and hrbrthemes packages,\nplot composite figure by combining ggplot2 graphs by using patchwork package."
  },
  {
    "objectID": "Hands-On_Exercise/Hands-On_Exercise02/HE02.html#getting-started",
    "href": "Hands-On_Exercise/Hands-On_Exercise02/HE02.html#getting-started",
    "title": "Hands-On Exercise 02",
    "section": "1 Getting Started",
    "text": "1 Getting Started\n\n1.1 Loading R packages\nNote: Ensure that the pacman package has already been installed.\nThe code chunk below uses p_load() of pacman package to load the tidyverse family of packages.\n\nggridges, a ggplot2 extension specially designed for plotting ridgeline plots,\nggdist, a ggplot2 extension spacially desgin for visualising distribution and uncertainty,\ntidyverse, a family of R packages to meet the modern data science and visual communication needs,\nggthemes, a ggplot extension that provides the user additional themes, scales, and geoms for the ggplots package, and\ncolorspace, an R package provides a broad toolbox for selecting individual colors or color palettes, manipulating these colors, and employing them in various kinds of visualisations.\n\n\npacman::p_load(ggdist, ggridges, ggthemes, colorspace, tidyverse)\n\n\n\n1.2 Importing data\nFor the purpose of this exercise, a data file called Exam_data will be used. It consists of year end examination grades of a cohort of primary 3 students from a local school. It is in csv file format.\n\nThe code chunk below imports exam_data.csv into R environment by using read_csv() function of readr package.\nreadr is one of the tidyverse package.\n\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\n\nData contains:\n\nYear end examination grades of a cohort of primary 3 students from a local school.\nThere are a total of seven attributes. Four of them are categorical data type and the other three are in continuous data type.\n\nThe categorical attributes are: ID, CLASS, GENDER and RACE.\nThe continuous attributes are: MATHS, ENGLISH and SCIENCE."
  },
  {
    "objectID": "Hands-On_Exercise/Hands-On_Exercise02/HE02.html#beyond-ggplot2-annotation-ggrepel",
    "href": "Hands-On_Exercise/Hands-On_Exercise02/HE02.html#beyond-ggplot2-annotation-ggrepel",
    "title": "Hands-On Exercise 02",
    "section": "2 Beyond ggplot2 Annotation: ggrepel",
    "text": "2 Beyond ggplot2 Annotation: ggrepel\nOne of the challenge in plotting statistical graph is annotation, especially with large number of data points.\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  geom_label(aes(label = ID), \n             hjust = .5, \n             vjust = -.5) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\n\n\n\n\n2.1 Introduction of ggrepel\nggrepel is an extension of ggplot2 package which provides geoms for ggplot2 to repel overlapping text seen below. Simply replace geom_text() by geom_text_repel() and geom_label() by geom_label_repel.\n\n\n2.2 Working with ggrepel\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlibrary(ggplot2)\nlibrary(ggrepel)\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  geom_label_repel(aes(label = ID), \n                   fontface = \"bold\") +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\n\n\n\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlibrary(ggplot2)\nlibrary(ggrepel)\n\nggplot(data=exam_data, \n       aes(x= SCIENCE, \n           y=ENGLISH)) +\n  geom_point(color = \"#8E9AAF\") +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5,\n              color=\"#4A4E69\") +  \n  geom_label_repel(aes(label = ID), \n                   fontface = \"bold\") +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Science scores for Primary 3\")\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nBenefits of ggrepel\n\nI think its best feature is how it acts like magnets, automatically “pushing” labels apart. No matter how crowded the data points are, the labels will find their own space and never stack on top of each other.\nEven if a label gets pushed away to avoid clutter, it automatically draws a thin line back to the original dot. This makes it very easy for the audience to see exactly which data point the label belongs to."
  },
  {
    "objectID": "Hands-On_Exercise/Hands-On_Exercise02/HE02.html#beyond-ggplot2-themes",
    "href": "Hands-On_Exercise/Hands-On_Exercise02/HE02.html#beyond-ggplot2-themes",
    "title": "Hands-On Exercise 02",
    "section": "3 Beyond ggplot2 Themes",
    "text": "3 Beyond ggplot2 Themes\nggplot2 has eight built-in themes: theme_gray(),theme_bw(),theme_classic(),theme_dark() ,theme_light(),theme_linedraw(),theme_minimal(), theme_void()\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n             aes(x = SCIENCE)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  theme_classic() +\n  ggtitle(\"Distribution of Maths scores\") \n\n\n\n\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"#8E9AAF\", \n                 fill=\"grey90\") +\n  theme_gray() +\n  ggtitle(\"Distribution of Science scores\") \n\n\n\n\n\n3.1 Working with ggtheme package\nggthemes provides ‘ggplot2’ themes that replicate the look of plots made by:\n\nFivethirtyeight\nThe Economist\nThe Wall Street Journal\namong others\n\nThe Economist theme is used below.\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_economist()\n\n\n\n\nThe Wall Street Journal theme is used below.\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 200,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_wsj() +\n  theme(plot.title = element_text(size = 18))\n\n\n\n\n\n\n3.2 Working with hrbthems package\nhrbrthemes package provides a base theme that focuses on typographic elements, including where various labels are placed as well as the fonts that are used.\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlibrary(ggrepel)\nlibrary(hrbrthemes)\nlibrary(ggplot2)\n\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_ipsum()\n\n\n\n\nThe second goal centers around productivity for a production workflow. In fact, this “production workflow” is the context for where the elements of hrbrthemes should be used.\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_ipsum(axis_title_size = 18,\n              base_size = 15,\n              grid = \"Y\")\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\naxis_title_size argument is used to increase the font size of the axis title to 18,\nbase_size argument is used to increase the default axis label to 15\ngrid argument is used to remove the x-axis grid lines"
  },
  {
    "objectID": "Hands-On_Exercise/Hands-On_Exercise02/HE02.html#beyond-single-graph",
    "href": "Hands-On_Exercise/Hands-On_Exercise02/HE02.html#beyond-single-graph",
    "title": "Hands-On Exercise 02",
    "section": "4 Beyond Single Graph",
    "text": "4 Beyond Single Graph\nTo build a more compelling narrative, it is often necessary to combine multiple visualizations into a single, cohesive figure. This section focuses on using ggplot2 extensions to facilitate professional plot composition. To begin, we will generate three foundational statistical graphics as the building blocks for our exercise.\n\nPlot 1: Distribution of Math Scores (Histogram)\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\np1 &lt;- ggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") + \n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of Maths scores\")\n\np1\n\n\n\n\n\n\nPlot 2: Distribution of English Scores (Histogram)\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\np2 &lt;- ggplot(data=exam_data, \n             aes(x = ENGLISH)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") + \n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of Maths scores\")\n\np2\n\n\n\n\n\n\nPlot 3: English vs Maths score (Scatterplot)\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\np3 &lt;- ggplot(data=exam_data, \n             aes(x= MATHS, \n                 y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English vs Maths scores for Primary 3\")\n\np3\n\n\n\n\n\n\n4.1 Creating Composite Graphics: pathwork methods\nThere are several ggplot2 extension’s functions support the needs to prepare composite figure by combining several graphs such as grid.arrange() of gridExtra package and plot_grid() of cowplot package.\nThis section uses a ggplot2 extension called patchwork, specially designed for combining separate ggplot2 graphs into a single figure.\nPatchwork package has a very simple syntax to create layouts. General syntax:\n\nPlus Sign “+” - Two-Column Layout\nParenthesis “( )” - Create a subplot group.\nDivision Sign “/” - Two-Row Layout\n\n\n\n4.2 Combining two ggplot2 graphs\nFigure in the tabset below shows a composite of two histograms created using patchwork. Note how simple the syntax used to create the plot!\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlibrary(patchwork)\n\np1 + p2\n\n\n\n\n\n\n4.3 Combining three ggplot2 graphs\nWe can plot more complex composite by using appropriate operators. For example, the composite figure below is plotted by using:\nMore complex composites can be achieved by using appropriate operators. For example, the composite figure below uses:\n\n“/” - stack two ggplot2 graphs on top of another\n“|” - place the plots adjacent to each other\n“( )” - define plot sequence\n\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(p1 / p2) | p3\n\n\n\n\n\n\n4.4 Creating a composite figure with tag\nIn order to identify subplots in text, patchwork also provides auto-tagging capabilities as shown in the figure below.\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n((p1 / p2) | p3) + \n  plot_annotation(tag_levels = 'I')\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nNote the I, II, III labels in the subplots have been automatically labelled.\n\n\n\n\n4.5 Creating figure with insert\nBeside providing functions to place plots next to each other based on the provided layout. With inset_element() of patchwork , we can place one or several plots or graphic elements freely on top or below another plot.\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\np3 + inset_element(p2, \n                   left = 0.02, \n                   bottom = 0.7, \n                   right = 0.5, \n                   top = 1)\n\n\n\n\n\n\n4.6 Creating a composite figure by using patchwork and ggtheme\nFigure below is created by combining patchwork and theme_economist() of ggthemes package discussed earlier.\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npatchwork &lt;- (p1 / p2) | p3\npatchwork & theme_economist()\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nIf the text exceeds the plot boundaries, you can add theme(plot.title = element_text(size = 10)) to adjust the font size accordingly\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npatchwork &lt;- (p1 / p2) | p3\npatchwork & theme_economist() & \n  theme(plot.title = element_text(size = 10))"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "Hands-On_Exercise/Hands-On_Exercise01/HE01.html",
    "href": "Hands-On_Exercise/Hands-On_Exercise01/HE01.html",
    "title": "Hands-On Exercise 01",
    "section": "",
    "text": "This chapter covers the fundamental principles and essential components of ggplot2. By integrating practical exercises with the “Layered Grammar of Graphics” framework, it demonstrates how to construct sophisticated and functional statistical visualizations. The ultimate objective is to enable the effective application of graphical elements to produce professional-grade data displays."
  },
  {
    "objectID": "Hands-On_Exercise/Hands-On_Exercise01/HE01.html#overview",
    "href": "Hands-On_Exercise/Hands-On_Exercise01/HE01.html#overview",
    "title": "Hands-On Exercise 01",
    "section": "",
    "text": "This chapter covers the fundamental principles and essential components of ggplot2. By integrating practical exercises with the “Layered Grammar of Graphics” framework, it demonstrates how to construct sophisticated and functional statistical visualizations. The ultimate objective is to enable the effective application of graphical elements to produce professional-grade data displays."
  },
  {
    "objectID": "Hands-On_Exercise/Hands-On_Exercise01/HE01.html#getting-started",
    "href": "Hands-On_Exercise/Hands-On_Exercise01/HE01.html#getting-started",
    "title": "Hands-On Exercise 01",
    "section": "1 Getting Started",
    "text": "1 Getting Started\n\n1.1 Installing and loading the required libraries\nNote: Ensure that the pacman package has already been installed.\nThe code chunk below uses p_load() of pacman package to check if tidyverse packages are installed in the computer. If they are, then they will be launched into R. Otherwise, tidyverse will be installed and launched into R.\n\npacman::p_load(tidyverse)\n\n\n\n1.2 The Data\n\nThe code chunk below imports exam_data.csv into R environment by using read_csv() function of readr package.\nreadr is one of the tidyverse package.\n\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\n\nData contains:\n\nYear end examination grades of a cohort of primary 3 students from a local school.\nThere are a total of seven attributes. Four of them are categorical data type and the other three are in continuous data type.\n\nThe categorical attributes are: ID, CLASS, GENDER and RACE.\nThe continuous attributes are: MATHS, ENGLISH and SCIENCE."
  },
  {
    "objectID": "Hands-On_Exercise/Hands-On_Exercise01/HE01.html#introducing-ggplot",
    "href": "Hands-On_Exercise/Hands-On_Exercise01/HE01.html#introducing-ggplot",
    "title": "Hands-On Exercise 01",
    "section": "2 Introducing ggplot",
    "text": "2 Introducing ggplot\n\n2.1 Overview\nggplot2 is a system for declaratively creating graphics, based on The Grammar of Graphics. You provide the data, tell ggplot2 how to map variables to aesthetics, what graphical primitives to use, and it takes care of the details.\n\n\n2.2 R Graphics VS ggplot\n\nR Graphicsggplot2\n\n\n\nhist(exam_data$MATHS)\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, aes(x = MATHS)) +\n  geom_histogram(bins=10, \n                 boundary = 100,\n                 color=\"black\", \n                 fill=\"grey\") +\n  ggtitle(\"Distribution of Maths scores\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nBenefits of ggplot2 over in-built R graphics\n\nI believe ggplot2 shines most when dealing with complex data because of its layering logic. It works like building blocks—using the + operator to stack points, lines, and labels. This makes the code logic incredibly clear and much easier to maintain or modify.\nI also feel it saves a lot of time because it handles so much automatically. Once I map a column to an axis or a color, it takes care of the scaling and legend generation for me. It’s far more efficient than the manual setup required in Base R.\n\n3.Compared to Base R, I find it much more powerful for multi-dimensional data. With just a single line like facet_wrap, I can instantly generate sub-plots for different categories, which is the best way to visualize and compare trends across groups."
  },
  {
    "objectID": "Hands-On_Exercise/Hands-On_Exercise01/HE01.html#grammar-of-graphics",
    "href": "Hands-On_Exercise/Hands-On_Exercise01/HE01.html#grammar-of-graphics",
    "title": "Hands-On Exercise 01",
    "section": "3 Grammar of Graphics",
    "text": "3 Grammar of Graphics\n\n3.1 Introduction\nThe “Grammar of Graphics” framework was first proposed by Leland Wilkinson in 1999. It breaks down complex visualizations into semantic components, such as Scales and Layers, essentially defining the fundamental nature of what a statistical graphic is.\nThe core of the Grammar of Graphics lies in defining a set of rules for structuring mathematical and aesthetic elements into a meaningful graph. The theory is built upon two key principles:\n\nGraphics = distinct layers of grammatical elements\nMeaningful plots through aesthetic mapping\n\nA good grammar of graphics will allow us to gain insight into the composition of complicated graphics, and reveal unexpected connections between seemingly different graphics (Cox 1978). It also provides a strong foundation for understanding a diverse range of graphics. Furthermore, it may also help guide us on what a well-formed or correct graphic looks like, but there will still be many grammatically correct but nonsensical graphics.\n\n\n3.2 A Layered Grammar of Graphics\nggplot2 is an implementation of Leland Wilkinson’s Grammar of Graphics.  There are seven grammars of ggplot2:\n\nData: The dataset being plotted.\nAesthetics take attributes of the data and use them to influence visual characteristics, such as position, colours, size, shape, or transparency.\nGeometrics: The visual elements used for our data, such as point, bar or line.\nFacets split the data into subsets to create multiple variations of the same graph (paneling, multiple plots).\nStatistics, statiscal transformations that summarise data (e.g. mean, confidence intervals).\nCoordinate systems define the plane on which data are mapped on the graphic.\nThemes modify all non-data components of a plot, such as main title, sub-title, y-aixs title, or legend background."
  },
  {
    "objectID": "Hands-On_Exercise/Hands-On_Exercise01/HE01.html#essential-grammatical-elements-in-ggplot2-data",
    "href": "Hands-On_Exercise/Hands-On_Exercise01/HE01.html#essential-grammatical-elements-in-ggplot2-data",
    "title": "Hands-On Exercise 01",
    "section": "4 Essential Grammatical Elements in ggplot2: data",
    "text": "4 Essential Grammatical Elements in ggplot2: data\nCall the ggplot() function using the code chunk below\n\nggplot(data=exam_data)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nA blank canvas appears.\nggplot() initializes a ggplot object.\nThe data argument defines the dataset to be used for plotting.\nIf the dataset is not already a data.frame, it will be converted to one by fortify()."
  },
  {
    "objectID": "Hands-On_Exercise/Hands-On_Exercise01/HE01.html#essential-grammatical-elements-in-ggplot2-aesthetic-mappings",
    "href": "Hands-On_Exercise/Hands-On_Exercise01/HE01.html#essential-grammatical-elements-in-ggplot2-aesthetic-mappings",
    "title": "Hands-On Exercise 01",
    "section": "5 Essential Grammatical Elements in ggplot2: Aesthetic mappings",
    "text": "5 Essential Grammatical Elements in ggplot2: Aesthetic mappings\nThe aesthetic mappings take attributes of the data and use them to influence visual characteristics, e.g., position, colour, size, shape, or transparency. Each visual characteristic can thus encode an aspect of the data and be used to convey information.\nAll aesthetics of a plot are specified in the aes() function call.\nCode chunk below adds the aesthetic element into the plot.\n\nggplot(data=exam_data, \n       aes(x= MATHS))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nggplot includes the x-axis and the axis’s label."
  },
  {
    "objectID": "Hands-On_Exercise/Hands-On_Exercise01/HE01.html#essential-grammatical-elements-in-ggplot2",
    "href": "Hands-On_Exercise/Hands-On_Exercise01/HE01.html#essential-grammatical-elements-in-ggplot2",
    "title": "Hands-On Exercise 01",
    "section": "6 Essential Grammatical Elements in ggplot2:",
    "text": "6 Essential Grammatical Elements in ggplot2:\ngeom\n\n6.1 Introduction\nGeometric objects are the actual marks we put on a plot. Some examples:\n\ngeom_point for drawing individual points (e.g., a scatter plot)\ngeom_line for drawing lines (e.g., for a line charts)\ngeom_smooth for drawing smoothed lines (e.g., for simple trends or approximations)\ngeom_bar for drawing bars (e.g., for bar charts)\ngeom_histogram for drawing binned values (e.g. a histogram)\ngeom_polygon for drawing arbitrary shapes\ngeom_map for drawing polygons in the shape of a map! (You can access the data to use for these maps by using the map_data() function).\n\n\n\n\n\n\n\nNote\n\n\n\nNote: A plot must have at least one geom; there is no upper limit. A geom can be added to a plot using the + operator.\n\n\n\n\n6.2 Geometric Objects: geom_bar\nThe code chunk below plots a bar chart by using geom_bar()\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n\n\n6.3 Geometric Objects: geom_dotplot\nIn a dot plot, the width of a dot corresponds to the bin width (or maximum width, depending on the binning algorithm), and dots are stacked, with each dot representing one observation.\nIn the code chunk below, geom_dotplot() of ggplot2 is used to plot a dot plot.\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot(dotsize = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCaution\n\n\n\nThe y scale is misleading and not very useful.\n\n\nThe code chunk below does the following:\n\nscale_y_continuous() is used to turn off the y-axis, and\nbinwidth argument is used to change the binwidth to 2.5.\n\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot(binwidth=2.5,         \n               dotsize = 0.5) +      \n  scale_y_continuous(NULL,           \n                     breaks = NULL)  \n\n\n\n\n\n\n\n\n\n\n6.4 Geometric Objects: geom_histogram()\nThe code chunk below, uses geom_histogram() create a simple histogram by using values in MATHS field of exam_data.\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_histogram()       \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe default bin is 30\n\n\n\n\n6.5 Modifying a geometric object by changing geom()\nThe code chunk below, does the following: - bins argument is used to change the number of bins to 20\n\nfill argument uses a Morandi color hex code (e.g., “#A3B18A”) to create a muted and professional aesthetic\ncolor argument is adjusted to “gray” to provide a softer visual outline for the bars compared to standard black\n\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20,           \n                 color=\"gray\",         \n                 fill=\"#93A5B3\") \n\n\n\n\n\n\n\n\n\n\n6.6 Modifying a geometric object by changing aes()\nThe code chunk below changes the interior colour of the histogram (i.e. fill) by using sub-group of aesthetic().\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           fill = GENDER)) +\n  geom_histogram(bins=20, \n                 color=\"grey30\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThis approach can be used to colour, fill and alpha of the geometric.\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           fill = GENDER)) +\n  geom_histogram(bins=20, \n                 color=\"grey30\", \n                 alpha=0.8) + \n  scale_fill_manual(values = c(\"Female\" = \"#C2C5CE\", \"Male\" = \"#8E9AAF\")) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\n6.7 Geometric Objects: geom-density()\ngeom-density() computes and plots kernel density estimate, which is a smoothed version of the histogram.\nIt is a useful alternative to the histogram for continuous data that comes from an underlying smooth distribution.\nThe code below plots the distribution of Maths scores in a kernel density estimate plot.\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_density()           \n\n\n\n\n\n\n\n\nThe code chunk below plots two kernel density lines by using colour or fill arguments of aes()\n\nggplot(data=exam_data, \n       aes(x = MATHS, \n           colour = GENDER)) +\n  geom_density()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nI believe that manual color control is essential for creating a cohesive and professional visual identity.\n\nggplot(data=exam_data, \n       aes(x = MATHS, \n           colour = GENDER)) +\n  geom_density() +\n  scale_colour_manual(values = c(\"#C2C5CE\", \"#8E9AAF\")) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\n6.8 Geometric Objects: geom_boxplot\ngeom_boxplot() displays continuous value list. It visualises five summary statistics (the median, two hinges and two whiskers), and all “outlying” points individually.\nThe code chunk below plots boxplots by using geom_boxplot().\n\nggplot(data=exam_data, \n       aes(y = MATHS,       \n           x= GENDER)) +    \n  geom_boxplot()            \n\n\n\n\n\n\n\n\nNotches are used in box plots to help visually assess whether the medians of distributions differ. If the notches do not overlap, this is evidence that the medians are different.\nThe code chunk below plots the distribution of Maths scores by gender in notched plot instead of boxplot.\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_boxplot(notch=TRUE)\n\n\n\n\n\n\n\n\n\n\n6.8 Geometric Objects: geom_violin\ngeom_violin is designed for creating violin plot. Violin plots are a way of comparing multiple data distributions. With ordinary density curves, it is difficult to compare more than just a few distributions because the lines visually interfere with each other. With a violin plot, it’s easier to compare several distributions since they’re placed side by side.\nThe code below plot the distribution of Maths score by gender in violin plot.\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_violin()\n\n\n\n\n\n\n\n\n\n\n6.9 Geometric Objects: geom_point()\ngeom_point() is especially useful for creating scatterplot.\nThe code chunk below plots a scatterplot showing the Maths and English grades of pupils by using geom_point().\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point()            \n\n\n\n\n\n\n\n\n\n\n6.10 geom objects can be combined\nThe code chunk below plots the data points on the boxplots by using both geom_boxplot() and geom_point().\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_boxplot() +                    \n  geom_point(position=\"jitter\", \n             size = 0.5)"
  },
  {
    "objectID": "Hands-On_Exercise/Hands-On_Exercise01/HE01.html#essential-grammatical-elements-in-ggplot2-stat",
    "href": "Hands-On_Exercise/Hands-On_Exercise01/HE01.html#essential-grammatical-elements-in-ggplot2-stat",
    "title": "Hands-On Exercise 01",
    "section": "7 Essential Grammatical Elements in ggplot2: stat",
    "text": "7 Essential Grammatical Elements in ggplot2: stat\n\n7.1 Introduction\nThe Statistics functions statistically transform data, usually as some form of summary. For example:\n\nfrequency of values of a variable (bar graph)\n\na mean\na confidence limit\n\nThere are two ways to use these functions:\n\nadd a stat_() function and override the default geom, or\nadd a geom_() function and override the default stat.\n\n\n\n\n7.2 Working with stat()\nThe boxplots below are incomplete because the positions of the means were not shown.\n\nggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\n\n\n7.3 Working with stat - the stat_summary() method\nThe code chunk below adds mean values by using stat_summary() function and overriding the default geom.\n\nggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot() +\n  stat_summary(geom = \"point\",       \n               fun.y=\"mean\",         \n               colour =\"#B47471\",        \n               size=4)               \n\n\n\n\n\n\n\n\n\n\n7.4 Adding a best fit curve on a scatterplot\nThe interpretability of scatterplots can be improved by adding a best fit curve. n the code chunk below, geom_smooth() is used to plot a best fit curve on the scatterplot.\n\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(size=0.5)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe default method used is loess.\n\n\nThe default smoothing method can be overridden as shown below.\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5)"
  },
  {
    "objectID": "Hands-On_Exercise/Hands-On_Exercise01/HE01.html#essential-grammatical-elements-in-ggplot2-facets",
    "href": "Hands-On_Exercise/Hands-On_Exercise01/HE01.html#essential-grammatical-elements-in-ggplot2-facets",
    "title": "Hands-On Exercise 01",
    "section": "8 Essential Grammatical Elements in ggplot2: Facets",
    "text": "8 Essential Grammatical Elements in ggplot2: Facets\n\n8.1 Introduction\nFacetting generates small multiples (aka trellis plot), each displaying a different subset of the data. They are an alternative to aesthetics for displaying additional discrete variables. ggplot2 supports two types of factes: facet_grid() and facet_wrap.\n\n\n8.2 Working with facet_wrap()\nfacet_wrap wraps a 1d sequence of panels into 2d. This is generally a better use of screen space than facet_grid because most displays are roughly rectangular.\nThe code chunk below plots a trellis plot using facet-wrap().\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20) +\n    facet_wrap(~ CLASS)\n\n\n\n\n\n\n\n\n\n\n8.3 facet_grid() function\nfacet_grid() forms a matrix of panels defined by row and column facetting variables. It is most useful when you have two discrete variables, and all combinations of the variables exist in the data.\nThe code chunk below plots a trellis plot using facet_grid().\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20) +\n    facet_grid(~ CLASS)"
  },
  {
    "objectID": "Hands-On_Exercise/Hands-On_Exercise01/HE01.html#essential-grammatical-elements-in-ggplot2-coordinates",
    "href": "Hands-On_Exercise/Hands-On_Exercise01/HE01.html#essential-grammatical-elements-in-ggplot2-coordinates",
    "title": "Hands-On Exercise 01",
    "section": "9 Essential Grammatical Elements in ggplot2: Coordinates",
    "text": "9 Essential Grammatical Elements in ggplot2: Coordinates\n\n9.1 Introduction\nThe Coordinates functions map the position of objects onto the plane of the plot. There are a number of different possible coordinate systems to use, they are:\n\ncoord_cartesian(): the default cartesian coordinate systems, where you specify x and y values (e.g. allows you to zoom in or out\ncoord_flip(): a cartesian system with the x and y flipped.\ncoord_fixed(): a cartesian system with a “fixed” aspect ratio (e.g. 1.78 for a “widescreen” plot).\ncoord_quickmap(): a coordinate system that approximates a good aspect ratio for maps.\n\n\n\n9.2 Working with Coordinate\nBy the default, the bar chart of ggplot2 is in vertical form.\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar()\n\n\n\n\n\n\n\n\nThe code chunk below flips the horizontal bar chart into vertical bar chart by using coord_flip().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip()\n\n\n\n\n\n\n\n\n\n\n9.3 Changing the y- and x-axis range\nThe scatterplot below is slightly misleading because the y-aixs and x-axis range are not equal.\n\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, size=0.5)\n\n\n\n\n\n\n\n\nThe code chunk below fixed both the y-axis and x-axis range from 0-100.\n\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))"
  },
  {
    "objectID": "Hands-On_Exercise/Hands-On_Exercise01/HE01.html#essential-grammatical-elements-in-ggplot2-themes",
    "href": "Hands-On_Exercise/Hands-On_Exercise01/HE01.html#essential-grammatical-elements-in-ggplot2-themes",
    "title": "Hands-On Exercise 01",
    "section": "10 Essential Grammatical Elements in ggplot2: themes",
    "text": "10 Essential Grammatical Elements in ggplot2: themes\n\n10.1 Introduction\nThemes control elements of the graph not related to the data. For example:\n\nbackground colour\nsize of fonts\ngridlines\ncolour of labels\n\nBuilt-in themes include: - theme_gray() (default) - theme_bw() - theme_classic()\nEach theme element can be conceived of as either a line (e.g. x-axis), a rectangle (e.g. graph background), or text (e.g. axis title).\n\n\n10.2 Working with theme\nThe code chunk below plot a horizontal bar chart using theme_gray().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_gray()\n\n\n\n\n\n\n\n\nA horizontal bar chart plotted using theme_classic().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_classic()\n\n\n\n\n\n\n\n\nA horizontal bar chart plotted using theme_minimal().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_minimal()"
  },
  {
    "objectID": "Hands-On_Exercise/Hands-On_Exercise03/HE03-1.html",
    "href": "Hands-On_Exercise/Hands-On_Exercise03/HE03-1.html",
    "title": "Hands-On Exercise 03-1",
    "section": "",
    "text": "We will learn how to create interactive data visualisation by using functions provided by ggiraph and plotlyr packages."
  },
  {
    "objectID": "Hands-On_Exercise/Hands-On_Exercise03/HE03-1.html#overview",
    "href": "Hands-On_Exercise/Hands-On_Exercise03/HE03-1.html#overview",
    "title": "Hands-On Exercise 03-1",
    "section": "",
    "text": "We will learn how to create interactive data visualisation by using functions provided by ggiraph and plotlyr packages."
  },
  {
    "objectID": "Hands-On_Exercise/Hands-On_Exercise03/HE03-1.html#getting-started",
    "href": "Hands-On_Exercise/Hands-On_Exercise03/HE03-1.html#getting-started",
    "title": "Hands-On Exercise 03-1",
    "section": "1 Getting Started",
    "text": "1 Getting Started\n\n1.1 Loading R packages\nNote: Ensure that the ggiraph, plotly, DT, tidyverse, patchwork package has already been installed.\nThe code chunk below uses\n\nggiraph for making ‘ggplot’ graphics interactive.\nplotly, R library for plotting interactive statistical graphs.\nDT provides an R interface to the JavaScript library DataTables that create interactive table on html page.\ntidyverse, a family of modern R packages specially designed to support data science, analysis and communication task including creating static statistical graphs.\npatchwork for combining multiple ggplot2 graphs into one figure.\n\n\npacman::p_load(ggiraph, plotly, \n               patchwork, DT, tidyverse)\n\n\n\n1.2 Importing data\nFor the purpose of this exercise, a data file called Exam_data will be used. It consists of year end examination grades of a cohort of primary 3 students from a local school. It is in csv file format.\n\nThe code chunk below imports exam_data.csv into R environment by using read_csv() function of readr package.\nreadr is one of the tidyverse package.\n\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-On_Exercise/Hands-On_Exercise03/HE03-1.html#interactive-data-visualisation---ggiraph-methods",
    "href": "Hands-On_Exercise/Hands-On_Exercise03/HE03-1.html#interactive-data-visualisation---ggiraph-methods",
    "title": "Hands-On Exercise 03-1",
    "section": "2 Interactive Data Visualisation - ggiraph methods",
    "text": "2 Interactive Data Visualisation - ggiraph methods\n\n2.1 Introduction\nggiraph is an htmlwidget and a ggplot2 extension. It allows ggplot graphics to be interactive.\nInteractive is made with ggplot geometries that can understand three arguments:\n\nTooltip : a column of data-sets that contain tooltips to be displayed when the mouse is over elements.\nOnclick : a column of data-sets that contain a JavaScript function to be executed when elements are clicked.\nData_id : a column of data-sets that contain an id to be associated with elements.\n\nIf it used within a shiny application, elements associated with an id (data_id) can be selected and manipulated on client and server sides.\n\n\n2.2 Tooltip effect with tooltip aesthetic\nBelow shows a typical code chunk to plot an interactive statistical graph by using ggiraph package. Notice that the code chunk consists of two parts. First, an ggplot object will be created. Next, girafe() of ggiraph will be used to create an interactive svg object.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = ID),\n    stackgroups = TRUE, \n    binwidth = 1, \n    method = \"histodot\") +\n  scale_y_continuous(NULL, \n                     breaks = NULL)\ngirafe(\n  ggobj = p,\n  width_svg = 6,\n  height_svg = 6*0.618\n)\n\n\n\n\n\n\n2.3 Displaying multiple information on tooltip\nThe content of the tooltip can be customised by including a list object as shown in the code chunk below. The first three lines of codes in the code chunk create a new field called tooltip. At the same time, it populates text in ID and CLASS fields into the newly created field. Next, this newly created field is used as tooltip field as shown in the code of line 7.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\nexam_data$tooltip &lt;- c(paste0(     \n  \"Name = \", exam_data$ID,         \n  \"\\n Class = \", exam_data$CLASS)) \n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = exam_data$tooltip), \n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(\n  ggobj = p,\n  width_svg = 8,\n  height_svg = 8*0.618\n)\n\n\n\n\n\n\n2.4 Customising Tooltip style\nCode chunk below uses opts_tooltip() of ggiraph to customize tooltip rendering by add css declarations.\n\n\n\n\n\n\nNote\n\n\n\nNotice that the background colour of the tooltip is black and the font colour is white and bold.\n\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\ntooltip_css &lt;- \"background-color:white; #&lt;&lt;\nfont-style:bold; color:black;\" #&lt;&lt;\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = ID),                   \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(    #&lt;&lt;\n    opts_tooltip(    #&lt;&lt;\n      css = tooltip_css)) #&lt;&lt;\n)\n\n\n\n\n\n\n2.5 Displaying statistics on tooltip\nCode chunk below shows an advanced way to customise tooltip. In this example, a function is used to compute 90% confident interval of the mean. The derived statistics are then displayed in the tooltip.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\ntooltip &lt;- function(y, ymax, accuracy = .01) {\n  mean &lt;- scales::number(y, accuracy = accuracy)\n  sem &lt;- scales::number(ymax - y, accuracy = accuracy)\n  paste(\"Mean maths scores:\", mean, \"+/-\", sem)\n}\n\ngg_point &lt;- ggplot(data=exam_data, \n                   aes(x = RACE),\n) +\n  stat_summary(aes(y = MATHS, \n                   tooltip = after_stat(  \n                     tooltip(y, ymax))),  \n    fun.data = \"mean_se\", \n    geom = GeomInteractiveCol,  \n    fill = \"light blue\"\n  ) +\n  stat_summary(aes(y = MATHS),\n    fun.data = mean_se,\n    geom = \"errorbar\", width = 0.2, size = 0.2\n  )\n\ngirafe(ggobj = gg_point,\n       width_svg = 8,\n       height_svg = 8*0.618)\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nIn this visualization, I deliberately chose a Point Plot with Error Bars over a traditional Bar Chart. The primary reasons are:\n\nEliminating “Visual Gravity”: Bar charts create a sense of visual weight that pulls the reader’s attention to the entire area between the zero-axis and the mean.\nPreventing Distribution Illusions: The solid bars can create a false impression that the data is uniformly “filled” or “grown” from zero.\n\n\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\nexam_stats &lt;- exam_data %&gt;%\n  group_by(RACE) %&gt;%\n  summarise(\n    mean_maths = mean(MATHS, na.rm = TRUE),\n    se_maths = sd(MATHS, na.rm = TRUE) / sqrt(n()),\n    .groups = 'drop'\n  ) %&gt;%\n  mutate(tooltip = paste0(\n    \"Race: \", RACE, \n    \"\\nMean: \", round(mean_maths, 2),\n    \"\\nSE: +/- \", round(se_maths, 2)\n  ))\n\n\np &lt;- ggplot(exam_stats, aes(x = RACE, y = mean_maths, data_id = RACE)) +\n  \n  geom_point_interactive(\n    aes(tooltip = tooltip), \n    size = 4, \n    color = \"#91989F\" \n  ) +\n\n  geom_errorbar_interactive(\n    aes(ymin = mean_maths - se_maths, ymax = mean_maths + se_maths),\n    width = 0.1, \n    size = 0.8,\n    color = \"#8E9AAF\"\n  ) +\n  labs(\n    title = \"Average Maths Scores by Race\",\n    x = \"Race\",\n    y = \"Mean Maths Score\"\n  ) +\n  theme_minimal() +\n  theme(panel.grid.minor = element_blank())\n\ngirafe(\n  ggobj = p,\n  options = list(\n    opts_hover(css = \"fill:orange;stroke:black;cursor:pointer;\"),\n    opts_tooltip(css = \"background-color:white; color:black; border-radius:5px; padding:5px;\")\n  )\n)\n\n\n\n\n\n\n2.6 Hover effect with data_id aesthetic\nCode chunk below shows the second interactive feature of ggiraph, namely data_id.\n\n\n\n\n\n\nNote\n\n\n\n\nElements associated with a data_id (i.e CLASS) will be highlighted upon mouse over.\nNote that the default value of the hover css is hover_css = “fill:orange;”.\n\n\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(           \n    aes(data_id = CLASS),             \n    stackgroups = TRUE,               \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618                      \n)             \n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nTo improve the readability of the interactive distribution, I implemented a monochromatic gradient combined with interactive tooltips. By mapping the CLASS variable to a specific color scale and adding data labels:\n\nInstantly distinguish between different class cohorts within a dense dataset.\nAccess granular details (such as specific scores) via tooltips without cluttering the primary visual field.\n\n\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\nstart_color &lt;- \"#015185\" \nend_color &lt;- \"#ccc273\"  \n\n\nn_classes &lt;- length(unique(exam_data$CLASS))\ngradient_colors &lt;- colorRampPalette(c(start_color, end_color))(n_classes)\n\np_gradient &lt;- ggplot(data=exam_data, \n                     aes(x = MATHS, fill = CLASS)) + \n  \n  geom_dotplot_interactive(            \n    aes(data_id = CLASS,           \n        tooltip = paste(\"Class:\", CLASS, \"\\nScore:\", MATHS)), \n    stackgroups = TRUE,               \n    binwidth = 1,                        \n    method = \"histodot\",\n    color = \"white\", \n    dotsize = 0.8                  \n  ) +                \n  \n  scale_y_continuous(NULL, breaks = NULL) +\n  scale_fill_manual(values = gradient_colors) +\n  \n  labs(\n    title = \"Maths Score Distribution (Class-based Gradient)\",\n    x = \"Maths Score\",\n    fill = \"Class (Shaded by ID)\"\n  ) +\n  theme_minimal() +\n  theme(\n    panel.grid.minor = element_blank(),\n    panel.grid.major.y = element_blank(),\n    legend.position = \"bottom\"\n  )\n\ngirafe(\n  ggobj = p_gradient,\n  options = list(\n    opts_hover(css = \"fill:#333333; stroke:#000000; stroke-width:1.5px;\"),\n    opts_hover_inv(css = \"opacity:0.3;\"),\n    opts_tooltip(css = \"background-color:white; color:black; border-radius:5px; padding:5px;\")\n  )\n)        \n\n\n\n\n\n\n2.7 Styling hover effect\nIn the code chunk below, css codes are used to change the highlighting effect.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(data_id = CLASS),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n)         \n\n\n\n\n\n\n2.8 Combining tooltip and hover effect\nThere are time that we want to combine tooltip and hover effect on the interactive statistical graph as shown in the code chunk below.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = CLASS, \n        data_id = CLASS),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n)          \n\n\n\n\n\n\n2.9 Click effect with onclick\nonclick argument of ggiraph provides hotlink interactivity on the web. The code chunk below shown an example of onclick.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\nexam_data$onclick &lt;- sprintf(\"window.open(\\\"%s%s\\\")\",\n\"https://www.moe.gov.sg/schoolfinder?journey=Primary%20school\",\nas.character(exam_data$ID))\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(onclick = onclick),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618)            \n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nNote that click actions must be a string column in the dataset containing valid javascript instructions.\n\n\n\n\n2.10 Coordinated Multiple Views with ggiraph\nNotice that when a data point of one of the dotplot is selected, the corresponding data point ID on the second data visualisation will be highlighted too.\nIn order to build a coordinated multiple views as shown in the example above, the following programming strategy will be used:\n\nAppropriate interactive functions of ggiraph will be used to create the multiple views.\npatchwork function of patchwork package will be used inside girafe function to create the interactive coordinated multiple views.\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\np1 &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(data_id = ID),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +  \n  coord_cartesian(xlim=c(0,100)) + \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\np2 &lt;- ggplot(data=exam_data, \n       aes(x = ENGLISH)) +\n  geom_dotplot_interactive(              \n    aes(data_id = ID),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") + \n  coord_cartesian(xlim=c(0,100)) + \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\ngirafe(code = print(p1 + p2), \n       width_svg = 6,\n       height_svg = 3,\n       options = list(\n         opts_hover(css = \"fill: #202020;\"),\n         opts_hover_inv(css = \"opacity:0.2;\")\n         )\n       )         \n\n\n\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\ntheme_analyst &lt;- function() {\n  theme_minimal() +\n  theme(\n    panel.grid.minor = element_blank(),\n    panel.grid.major.y = element_blank(),\n    axis.title.x = element_text(size = 9, color = \"#4A4E52\"),\n    plot.title = element_text(size = 11, face = \"bold\")\n  )\n}\n\np1 &lt;- ggplot(data=exam_data, aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(data_id = ID, tooltip = ID),\n    stackgroups = TRUE, binwidth = 1, method = \"histodot\",\n    fill = \"#015185\", color = \"white\", dotsize = 0.9 \n  ) +\n  coord_cartesian(xlim=c(0,100)) +\n  scale_y_continuous(NULL, breaks = NULL) +\n  labs(title = \"Mathematics\") +\n  theme_analyst()\n\np2 &lt;- ggplot(data=exam_data, aes(x = ENGLISH)) +\n  geom_dotplot_interactive(\n    aes(data_id = ID, tooltip = ID),\n    stackgroups = TRUE, binwidth = 1, method = \"histodot\",\n    fill = \"#015185\", color = \"white\", dotsize = 0.9 \n  ) +\n  coord_cartesian(xlim=c(0,100)) +\n  scale_y_continuous(NULL, breaks = NULL) +\n  labs(title = \"English\") +\n  theme_analyst()\n\ncombined_plot &lt;- (p1 + p2) + \n  plot_annotation(\n    title = \"Student Performance Distribution: Maths vs English\",\n    theme = theme(plot.title = element_text(size = 14))\n  )\n\ngirafe(\n  ggobj = combined_plot,\n  width_svg = 7,\n  height_svg = 4,\n  options = list(\n    opts_hover(css = \"fill:#4A4E52; stroke:black; stroke-width:1px;\"),\n    opts_hover_inv(css = \"opacity:0.1;\"),\n    opts_tooltip(css = \"background-color:white; color:black; border-radius:3px; padding:5px;\")\n  )\n)"
  },
  {
    "objectID": "Hands-On_Exercise/Hands-On_Exercise03/HE03-1.html#interactive-data-visualisation---plotly-methods",
    "href": "Hands-On_Exercise/Hands-On_Exercise03/HE03-1.html#interactive-data-visualisation---plotly-methods",
    "title": "Hands-On Exercise 03-1",
    "section": "3 Interactive Data Visualisation - plotly methods",
    "text": "3 Interactive Data Visualisation - plotly methods\n\n3.1 Introduction\nPlotly’s R graphing library create interactive web graphics from ggplot2 graphs and/or a custom interface to the (MIT-licensed) JavaScript library plotly.js inspired by the grammar of graphics. Different from other plotly platform, plot.R is free and open source.\nThere are two ways to create interactive graph by using plotly, they are:\n\nby using plot_ly()\nby using ggplotly()\n\n\n\n3.2 Creating an interactive scatter plot: plot_ly() method\nThe tabset below shows an example a basic interactive plot created by using plot_ly().\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\nplot_ly(data = exam_data, \n             x = ~MATHS, \n             y = ~ENGLISH)  \n\n\n\n\n\n\n3.3 Working with visual variable: plot_ly() method\nIn the code chunk below, color argument is mapped to a qualitative visual variable (i.e. RACE).\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\nplot_ly(data = exam_data, \n        x = ~ENGLISH, \n        y = ~MATHS, \n        color = ~RACE)  \n\n\n\n\n\n\n3.4 Creating an interactive scatter plot: ggplotly() method\nThe code chunk below plots an interactive scatter plot by using ggplotly().\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\np &lt;- ggplot(data=exam_data, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nggplotly(p)  \n\n\n\n\n\n\n3.5 Coordinated Multiple Views with plotly\nThe creation of a coordinated linked plot by using plotly involves three steps:\n\nhighlight_key() of plotly package is used as shared data.\nTwo scatterplots will be created by using ggplot2 functions.\nsubplot() of plotly package is used to place them next to each other side-by-side.\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\nd &lt;- highlight_key(exam_data)\np1 &lt;- ggplot(data=d, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\np2 &lt;- ggplot(data=d, \n            aes(x = MATHS,\n                y = SCIENCE)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nsubplot(ggplotly(p1),\n        ggplotly(p2))"
  },
  {
    "objectID": "Hands-On_Exercise/Hands-On_Exercise03/HE03-1.html#interactive-data-visualisation---crosstalk-methods",
    "href": "Hands-On_Exercise/Hands-On_Exercise03/HE03-1.html#interactive-data-visualisation---crosstalk-methods",
    "title": "Hands-On Exercise 03-1",
    "section": "4 Interactive Data Visualisation - crosstalk methods",
    "text": "4 Interactive Data Visualisation - crosstalk methods\n\n4.1 Introduction\nCrosstalk is an add-on to the htmlwidgets package. It extends htmlwidgets with a set of classes, functions, and conventions for implementing cross-widget interactions (currently, linked brushing and filtering).\n\n\n4.2 Interactive Data Table: DT package\n\nA wrapper of the JavaScript Library DataTables\nData objects in R can be rendered as HTML tables using the JavaScript library ‘DataTables’ (typically via R Markdown or Shiny).\n\n\nDT::datatable(exam_data, class= \"compact\")\n\n\n\n\n\n\n\n4.3 Linked brushing: crosstalk method\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nd &lt;- highlight_key(exam_data) \np &lt;- ggplot(d, \n            aes(ENGLISH, \n                MATHS)) + \n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\ngg &lt;- highlight(ggplotly(p),        \n                \"plotly_selected\")  \n\ncrosstalk::bscols(gg,               \n                  DT::datatable(d), \n                  widths = 5)    \n\n\n\n\nThings to learn from the code chunk:\nhighlight() is a function of plotly package. It sets a variety of options for brushing (i.e., highlighting) multiple plots. These options are primarily designed for linking multiple plotly graphs, and may not behave as expected when linking plotly to another htmlwidget package via crosstalk. In some cases, other htmlwidgets will respect these options, such as persistent selection in leaflet.\nbscols() is a helper function of crosstalk package. It makes it easy to put HTML elements side by side. It can be called directly from the console but is especially designed to work in an R Markdown document. Warning: This will bring in all of Bootstrap."
  },
  {
    "objectID": "Hands-On_Exercise/Hands-On_Exercise04/HE04-1.html",
    "href": "Hands-On_Exercise/Hands-On_Exercise04/HE04-1.html",
    "title": "Hands-On Exercise 04-1",
    "section": "",
    "text": "Visualising distribution is not new in statistical analysis. In chapter 1 we have shared with you some of the popular statistical graphics methods for visualising distribution are histogram, probability density curve (pdf), boxplot, notch plot and violin plot and how they can be created by using ggplot2. In this chapter, we are going to share with you two relatively new statistical graphic methods for visualising distribution, namely ridgeline plot and raincloud plot by using ggplot2 and its extensions."
  },
  {
    "objectID": "Hands-On_Exercise/Hands-On_Exercise04/HE04-1.html#overview",
    "href": "Hands-On_Exercise/Hands-On_Exercise04/HE04-1.html#overview",
    "title": "Hands-On Exercise 04-1",
    "section": "",
    "text": "Visualising distribution is not new in statistical analysis. In chapter 1 we have shared with you some of the popular statistical graphics methods for visualising distribution are histogram, probability density curve (pdf), boxplot, notch plot and violin plot and how they can be created by using ggplot2. In this chapter, we are going to share with you two relatively new statistical graphic methods for visualising distribution, namely ridgeline plot and raincloud plot by using ggplot2 and its extensions."
  },
  {
    "objectID": "Hands-On_Exercise/Hands-On_Exercise04/HE04-1.html#getting-started",
    "href": "Hands-On_Exercise/Hands-On_Exercise04/HE04-1.html#getting-started",
    "title": "Hands-On Exercise 04-1",
    "section": "1 Getting Started",
    "text": "1 Getting Started\n\n1.1 Installing and loading the packages\nFor the purpose of this exercise, the following R packages will be used, they are:\n\nggridges, a ggplot2 extension specially designed for plotting ridgeline plots\nggdist, a ggplot2 extension spacially desgin for visualising distribution and uncertainty\ntidyverse, a family of R packages to meet the modern data science and visual communication needs\nggthemes, a ggplot extension that provides the user additional themes, scales, and geoms for the ggplots package, and\ncolorspace, an R package provides a broad toolbox for selecting individual colors or color palettes, manipulating these colors, and employing them in various kinds of visualisations.\n\nThe code chunk below will be used load these R packages into RStudio environment.\n\npacman::p_load(ggdist, ggridges, ggthemes,\n               colorspace, tidyverse)\n\n\n\n1.2 Data import\nFor the purpose of this exercise, Exam_data.csv will be used.\nIn the code chunk below, read_csv() of readr package is used to import Exam_data.csv into R and saved it into a tibble data.frame.\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-On_Exercise/Hands-On_Exercise04/HE04-1.html#visualising-distribution-with-ridgeline-plot",
    "href": "Hands-On_Exercise/Hands-On_Exercise04/HE04-1.html#visualising-distribution-with-ridgeline-plot",
    "title": "Hands-On Exercise 04-1",
    "section": "2 Visualising Distribution with Ridgeline Plot",
    "text": "2 Visualising Distribution with Ridgeline Plot\n\n2.1 Introduction\nRidgeline plot (sometimes called Joyplot) is a data visualisation technique for revealing the distribution of a numeric value for several groups. Distribution can be represented using histograms or density plots, all aligned to the same horizontal scale and presented with a slight overlap.\nFigure below is a ridgelines plot showing the distribution of English score by class.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nRidgeline plots make sense when the number of group to represent is medium to high, and thus a classic window separation would take to much space. Indeed, the fact that groups overlap each other allows to use space more efficiently. If you have less than 5 groups, dealing with other distribution plots is probably better.\nIt works well when there is a clear pattern in the result, like if there is an obvious ranking in groups. Otherwise group will tend to overlap each other, leading to a messy plot not providing any insight.\n\n\n\n\n\n2.2 Plotting ridgeline graph: ggridges method\nThere are several ways to plot ridgeline plot with R. In this section, you will learn how to plot ridgeline plot by using ggridges package.\nggridges package provides two main geom to plot gridgeline plots, they are: geom_ridgeline() and geom_density_ridges(). The former takes height values directly to draw the ridgelines, and the latter first estimates data densities and then draws those using ridgelines.\nThe ridgeline plot below is plotted by using geom_density_ridges().\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = ENGLISH, \n           y = CLASS)) +\n  geom_density_ridges(\n    scale = 3,\n    rel_min_height = 0.01,\n    bandwidth = 3.4,\n    fill = lighten(\"#7097BB\", .3),\n    color = \"white\"\n  ) +\n  scale_x_continuous(\n    name = \"English grades\",\n    expand = c(0, 0)\n    ) +\n  scale_y_discrete(name = NULL, expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()\n\n\n\n\n\n\n2.3 Varying fill colors along the x axis\nSometimes we would like to have the area under a ridgeline not filled with a single solid color but rather with colors that vary in some form along the x axis. This effect can be achieved by using either geom_ridgeline_gradient() or geom_density_ridges_gradient(). Both geoms work just like geom_ridgeline() and geom_density_ridges(), except that they allow for varying fill colors. However, they do not allow for alpha transparency in the fill. For technical reasons, we can have changing fill colors or transparency but not both.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = ENGLISH, \n           y = CLASS,\n           fill = stat(x))) +\n  geom_density_ridges_gradient(\n    scale = 3,\n    rel_min_height = 0.01) +\n  scale_fill_viridis_c(name = \"Temp. [F]\",\n                       option = \"C\") +\n  scale_x_continuous(\n    name = \"English grades\",\n    expand = c(0, 0)\n  ) +\n  scale_y_discrete(name = NULL, expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()\n\n\n\n\n\n\n2.4 Mapping the probabilities directly onto colour\nBeside providing additional geom objects to support the need to plot ridgeline plot, ggridges package also provides a stat function called stat_density_ridges() that replaces stat_density() of ggplot2.\nFigure below is plotted by mapping the probabilities calculated by using stat(ecdf) which represent the empirical cumulative density function for the distribution of English score.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = 0.5 - abs(0.5-stat(ecdf)))) +\n  stat_density_ridges(geom = \"density_ridges_gradient\", \n                      calc_ecdf = TRUE) +\n  scale_fill_viridis_c(name = \"Tail probability\",\n                       direction = -1) +\n  theme_ridges()\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nIt is important include the argument calc_ecdf = TRUE in stat_density_ridges().\nIf we want to change color then use option = \"magma\"\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = 0.5 - abs(0.5-stat(ecdf)))) +\n  stat_density_ridges(geom = \"density_ridges_gradient\", \n                      calc_ecdf = TRUE) +\n  scale_fill_gradient(name = \"Tail probability\",\n                      low = \"royalblue\", \n                      high = \"#015185\") +\n  theme_ridges()\n\n\n\n\n\n\n\n\n2.5 Ridgeline plots with quantile lines\nBy using geom_density_ridges_gradient(), we can colour the ridgeline plot by quantile, via the calculated stat(quantile) aesthetic as shown in the figure below.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = 4,\n    quantile_lines = TRUE) +\n  scale_fill_viridis_d(name = \"Quartiles\") +\n  theme_ridges()\n\n\n\n\nInstead of using number to define the quantiles, we can also specify quantiles by cut points such as 2.5% and 97.5% tails to colour the ridgeline plot as shown in the figure below.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = c(0.025, 0.975)\n    ) +\n  scale_fill_manual(\n    name = \"Probability\",\n    values = c(\"#FF0000A0\", \"#A0A0A0A0\", \"#0000FFA0\"),\n    labels = c(\"(0, 0.025]\", \"(0.025, 0.975]\", \"(0.975, 1]\")\n  ) +\n  theme_ridges()"
  },
  {
    "objectID": "Hands-On_Exercise/Hands-On_Exercise04/HE04-1.html#visualising-distribution-with-raincloud-plot",
    "href": "Hands-On_Exercise/Hands-On_Exercise04/HE04-1.html#visualising-distribution-with-raincloud-plot",
    "title": "Hands-On Exercise 04-1",
    "section": "3 Visualising Distribution with Raincloud Plot",
    "text": "3 Visualising Distribution with Raincloud Plot\n\n3.1 Introduction\nRaincloud Plot is a data visualisation techniques that produces a half-density to a distribution plot. It gets the name because the density plot is in the shape of a “raincloud”. The raincloud (half-density) plot enhances the traditional box-plot by highlighting multiple modalities (an indicator that groups may exist). The boxplot does not show where densities are clustered, but the raincloud plot does!\nIn this section, you will learn how to create a raincloud plot to visualise the distribution of English score by race. It will be created by using functions provided by ggdist and ggplot2 packages.\n\n\n3.2 Plotting a Half Eye graph\nFirst, we will plot a Half-Eye graph by using stat_halfeye() of ggdist package.\nThis produces a Half Eye visualization, which is contains a half-density and a slab-interval.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA)\n\n\n\n\n\n\n\nNote\n\n\n\nWe remove the slab interval by setting .width = 0 and point_colour = NA.\n\n\n\n\n\n\n\n3.3 Adding the boxplot with geom_boxplot()\nNext, we will add the second geometry layer using geom_boxplot() of ggplot2. This produces a narrow boxplot. We reduce the width and adjust the opacity.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA)\n\n\n\n\n\n\n3.4 Adding the Dot Plots with stat_dots()\nNext, we will add the third geometry layer using stat_dots() of ggdist package. This produces a half-dotplot, which is similar to a histogram that indicates the number of samples (number of dots) in each bin. We select side = “left” to indicate we want it on the left-hand side.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA) +\n  stat_dots(side = \"left\", \n            justification = 1.2, \n            binwidth = .5,\n            dotsize = 2)\n\n\n\n\n\n\n3.5 Finishing touch\nLastly, coord_flip() of ggplot2 package will be used to flip the raincloud chart horizontally to give it the raincloud appearance. At the same time, theme_economist() of ggthemes package is used to give the raincloud chart a professional publishing standard look.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA) +\n  stat_dots(side = \"left\", \n            justification = 1.2, \n            binwidth = .5,\n            dotsize = 1.5) +\n  coord_flip() +\n  theme_economist()"
  },
  {
    "objectID": "Hands-On_Exercise/Hands-On_Exercise04/HE04-3.html",
    "href": "Hands-On_Exercise/Hands-On_Exercise04/HE04-3.html",
    "title": "Hands-On Exercise 04-3",
    "section": "",
    "text": "Visualising uncertainty is relatively new in statistical graphics. In this chapter, you will gain hands-on experience on creating statistical graphics for visualising uncertainty. By the end of this chapter you will be able:\n\nto plot statistics error bars by using ggplot2,\nto plot interactive error bars by combining ggplot2, plotly and DT,\nto create advanced by using ggdist, and\nto create hypothetical outcome plots (HOPs) by using ungeviz package."
  },
  {
    "objectID": "Hands-On_Exercise/Hands-On_Exercise04/HE04-3.html#overview",
    "href": "Hands-On_Exercise/Hands-On_Exercise04/HE04-3.html#overview",
    "title": "Hands-On Exercise 04-3",
    "section": "",
    "text": "Visualising uncertainty is relatively new in statistical graphics. In this chapter, you will gain hands-on experience on creating statistical graphics for visualising uncertainty. By the end of this chapter you will be able:\n\nto plot statistics error bars by using ggplot2,\nto plot interactive error bars by combining ggplot2, plotly and DT,\nto create advanced by using ggdist, and\nto create hypothetical outcome plots (HOPs) by using ungeviz package."
  },
  {
    "objectID": "Hands-On_Exercise/Hands-On_Exercise04/HE04-3.html#getting-started",
    "href": "Hands-On_Exercise/Hands-On_Exercise04/HE04-3.html#getting-started",
    "title": "Hands-On Exercise 04-3",
    "section": "1 Getting Started",
    "text": "1 Getting Started\n\n1.1 Installing and loading the packages\nFor the purpose of this exercise, the following R packages will be used, they are:\n\ntidyverse, a family of R packages for data science process,\nplotly for creating interactive plot,\ngganimate for creating animation plot,\nDT for displaying interactive html table,\ncrosstalk for for implementing cross-widget interactions (currently, linked brushing and filtering), and\nggdist for visualising distribution and uncertainty.\n\n\npacman::p_load(plotly, crosstalk, DT, \n               ggdist, ggridges, colorspace,\n               gganimate, tidyverse)\n\n\n\n1.2 Data import\nFor the purpose of this exercise, Exam_data.csv will be used.\nIn the code chunk below, read_csv() of readr package is used to import Exam_data.csv into R and saved it into a tibble data.frame.\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-On_Exercise/Hands-On_Exercise04/HE04-3.html#visualizing-the-uncertainty-of-point-estimates-ggplot2-methods",
    "href": "Hands-On_Exercise/Hands-On_Exercise04/HE04-3.html#visualizing-the-uncertainty-of-point-estimates-ggplot2-methods",
    "title": "Hands-On Exercise 04-3",
    "section": "2 Visualizing the uncertainty of point estimates: ggplot2 methods",
    "text": "2 Visualizing the uncertainty of point estimates: ggplot2 methods\n\n2.1 Introduction\nA point estimate is a single number, such as a mean. Uncertainty, on the other hand, is expressed as standard error, confidence interval, or credible interval.\nIn this section, we will learn how to plot error bars of maths scores by race by using data provided in exam tibble data frame.\nFirstly, code chunk below will be used to derive the necessary summary statistics.\n\n\n\n\n\n\nNote\n\n\n\n\ngroup_by() of dplyr package is used to group the observation by RACE,\nsummarise() is used to compute the count of observations, mean, standard deviation\nmutate() is used to derive standard error of Maths by RACE, and\nthe output is save as a tibble data table called my_sum.\n\n\n\nNext, the code chunk below will be used to display my_sum tibble data frame in an html table format.\n\nTableCode\n\n\n\n\n\n\n\nRACE\nn\nmean\nsd\nse\n\n\n\n\nChinese\n193\n76.50777\n15.69040\n1.132357\n\n\nIndian\n12\n60.66667\n23.35237\n7.041005\n\n\nMalay\n108\n57.44444\n21.13478\n2.043177\n\n\nOthers\n9\n69.66667\n10.72381\n3.791438\n\n\n\n\n\n\n\n\nknitr::kable(head(my_sum), format = 'html')\n\n\n\n\n\n\n2.2 Plotting standard error bars of point estimates\nNow we are ready to plot the standard error bars of mean maths score by race as shown below.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=RACE, \n        ymin=mean-se, \n        ymax=mean+se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    linewidth=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  ggtitle(\"Standard error of mean maths score by rac\")\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nAdding interactive tooltips enhances data accessibility, allowing users to instantly retrieve precise values—such as mean and error bounds—simply by hovering over the data points.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\nlibrary(ggplot2)\nlibrary(plotly)\n\np &lt;- ggplot(my_sum) +\n  geom_errorbar(\n    aes(x = RACE, \n        ymin = mean - se, \n        ymax = mean + se), \n    width = 0.2, \n    colour = \"black\", \n    alpha = 0.9, \n    linewidth = 0.5) +\n  geom_point(aes(\n    x = RACE, \n    y = mean,\n    text = paste0(\"Race: \", RACE, \n                  \"&lt;br&gt;Mean: \", round(mean, 2),\n                  \"&lt;br&gt;Upper limit: \", round(mean + se, 2),\n                  \"&lt;br&gt;Downer limit: \", round(mean - se, 2))\n  ), \n  stat = \"identity\", \n  color = \"red\",\n  size = 1.5,\n  alpha = 1) +\n  ggtitle(\"Standard error of mean maths score by race\") +\n  theme_minimal()\n\nggplotly(p, tooltip = \"text\")\n\n\n\n\n\n\n\n\n2.3 Plotting confidence interval of point estimates\nInstead of plotting the standard error bar of point estimates, we can also plot the confidence intervals of mean maths score by race.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=reorder(RACE, -mean), \n        ymin=mean-1.96*se, \n        ymax=mean+1.96*se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    linewidth=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  labs(x = \"Maths score\",\n       title = \"95% confidence interval of mean maths score by race\")\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nThe confidence intervals are computed by using the formula mean+/-1.96*se.\nThe error bars is sorted by using the average maths scores.\nlabs() argument of ggplot2 is used to change the x-axis label.\n\n\n\n\n\n2.4 Visualizing the uncertainty of point estimates with interactive error bars\nIn this section, you will learn how to plot interactive error bars for the 99% confidence interval of mean maths score by race as shown in the figure below.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nshared_df = SharedData$new(my_sum)\n\nbscols(widths = c(4,8),\n       ggplotly((ggplot(shared_df) +\n                   geom_errorbar(aes(\n                     x=reorder(RACE, -mean),\n                     ymin=mean-2.58*se, \n                     ymax=mean+2.58*se), \n                     width=0.2, \n                     colour=\"black\", \n                     alpha=0.9, \n                     size=0.5) +\n                   geom_point(aes(\n                     x=RACE, \n                     y=mean, \n                     text = paste(\"Race:\", `RACE`, \n                                  \"&lt;br&gt;N:\", `n`,\n                                  \"&lt;br&gt;Avg. Scores:\", round(mean, digits = 2),\n                                  \"&lt;br&gt;95% CI:[\", \n                                  round((mean-2.58*se), digits = 2), \",\",\n                                  round((mean+2.58*se), digits = 2),\"]\")),\n                     stat=\"identity\", \n                     color=\"red\", \n                     size = 1.5, \n                     alpha=1) + \n                   xlab(\"Race\") + \n                   ylab(\"Average Scores\") + \n                   theme_minimal() + \n                   theme(axis.text.x = element_text(\n                     angle = 45, vjust = 0.5, hjust=1)) +\n                   ggtitle(\"99% Confidence interval of average /&lt;br&gt;maths scores by race\")), \n                tooltip = \"text\"), \n       DT::datatable(shared_df, \n                     rownames = FALSE, \n                     class=\"compact\", \n                     width=\"100%\", \n                     options = list(pageLength = 10,\n                                    scrollX=T), \n                     colnames = c(\"No. of pupils\", \n                                  \"Avg Scores\",\n                                  \"Std Dev\",\n                                  \"Std Error\")) %&gt;%\n         formatRound(columns=c('mean', 'sd', 'se'),\n                     digits=2))\n\n\n\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlibrary(htmltools)\nlibrary(ggplot2)\nlibrary(plotly)\nlibrary(DT)\nlibrary(crosstalk)\n\nshared_df = SharedData$new(my_sum)\n\np &lt;- ggplot(shared_df) +\n  geom_errorbar(aes(\n    x = reorder(RACE, -mean),\n    ymin = mean - 2.58 * se, \n    ymax = mean + 2.58 * se), \n    width = 0.2, colour = \"black\", alpha = 0.9, linewidth = 0.5) +\n  geom_point(aes(\n    x = RACE, \n    y = mean, \n    text = paste(\"Race:\", RACE, \n                 \"&lt;br&gt;N:\", n,\n                 \"&lt;br&gt;Avg. Scores:\", round(mean, 2),\n                 \"&lt;br&gt;99% CI: [\", round(mean - 2.58 * se, 2), \",\", \n                 round(mean + 2.58 * se, 2), \"]\")),\n    color = \"red\", size = 1.5) +\n  xlab(\"Race\") + \n  ylab(\"Average Scores\") + \n  theme_minimal() + \n  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) +\n  ggtitle(\"99% CI by Race\")\n\nfig &lt;- ggplotly(p, tooltip = \"text\") %&gt;%\n  layout(\n    margin = list(t = 80, b = 80, l = 60, r = 20), \n    xaxis = list(automargin = TRUE), \n    yaxis = list(automargin = TRUE),\n    title = list(y = 0.95)          \n  )\n\n\nbscols(\n  widths = c(6, 6), \n  fig,\n  div(\n    style = \"padding-top: 50px;\",    \n    DT::datatable(\n      shared_df, \n      rownames = FALSE, \n      class = \"compact stripe\", \n      width = \"100%\", \n      options = list(\n        dom = 'lfrtip',              \n        pageLength = 10,\n        scrollX = TRUE\n      ), \n      colnames = c(\"Race\", \"No. of pupils\", \"Avg Scores\", \"Std Dev\", \"Std Error\")\n    ) %&gt;%\n      formatRound(columns = c('mean', 'sd', 'se'), digits = 2)\n  )\n)"
  },
  {
    "objectID": "Hands-On_Exercise/Hands-On_Exercise04/HE04-3.html#visualising-uncertainty-ggdist-package",
    "href": "Hands-On_Exercise/Hands-On_Exercise04/HE04-3.html#visualising-uncertainty-ggdist-package",
    "title": "Hands-On Exercise 04-3",
    "section": "3 Visualising Uncertainty: ggdist package",
    "text": "3 Visualising Uncertainty: ggdist package\n\n3.1 Introduction\n\nggdist is an R package that provides a flexible set of ggplot2 geoms and stats designed especially for visualising distributions and uncertainty.\nIt is designed for both frequentist and Bayesian uncertainty visualization, taking the view that uncertainty visualization can be unified through the perspective of distribution visualization:\n\nfor frequentist models, one visualises confidence distributions or bootstrap distributions (see vignette(“freq-uncertainty-vis”));\nfor Bayesian models, one visualises probability distributions (see the tidybayes package, which builds on top of ggdist).\n\n\n\n\n3.2 Visualizing the uncertainty of point estimates: ggdist methods\nIn the code chunk below, stat_pointinterval() of ggdist is used to build a visual for displaying distribution of maths scores by race.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nexam %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_pointinterval() +\n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot\")\n\n\n\n\nThis function comes with many arguments, students are advised to read the syntax reference for more detail.\nFor example, in the code chunk below the following arguments are used:\n\nwidth = 0.95\npoint = median\ninterval = qi\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nexam %&gt;%\n  ggplot(aes(x = RACE, y = MATHS)) +\n  stat_pointinterval(.width = 0.95,\n  .point = median,\n  .interval = qi) +\n  labs(\n    title = \"Visualising confidence intervals of median math score\",\n    subtitle = \"Median Point + Multiple-interval plot\")\n\n\n\n\n\n\n3.2.1 Raincloud / Half-eye Plot\nCombining Distribution and Summary: Integrating stat_halfeye with geom_dots creates a ‘Raincloud Plot’ effect. This layout is superior for transparency as it reveals the raw data distribution alongside key statistical summaries in a single view.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nexam %&gt;%\n  ggplot(aes(x = RACE, y = MATHS)) +\n  stat_halfeye(\n    width = 0.6, \n    justification = -0.2, \n    .width = c(0.66, 0.95)\n  ) +\n  geom_dots(side = \"left\", justification = 1.1, binwidth = 1) +\n  labs(title = \"Half-eye Plot with Dots\")\n\n\n\n\n\n\n3.3 Visualizing the uncertainty of point estimates: ggdist methods\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nexam %&gt;%\n  ggplot(aes(x = RACE, y = MATHS)) +\n  stat_pointinterval(.width = c(0.95, 0.99)) +\n  labs(title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot\")\n\n\n\n\n\n\n3.4 Visualizing the uncertainty of point estimates: ggdist methods\nIn the code chunk below, stat_gradientinterval() of ggdist is used to build a visual for displaying distribution of maths scores by race.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nexam %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_gradientinterval(   \n    fill = \"skyblue\",      \n    show.legend = TRUE     \n  ) +                        \n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Gradient + interval plot\")"
  },
  {
    "objectID": "Hands-On_Exercise/Hands-On_Exercise04/HE04-3.html#visualising-uncertainty-with-hypothetical-outcome-plots-hops",
    "href": "Hands-On_Exercise/Hands-On_Exercise04/HE04-3.html#visualising-uncertainty-with-hypothetical-outcome-plots-hops",
    "title": "Hands-On Exercise 04-3",
    "section": "4 Visualising Uncertainty with Hypothetical Outcome Plots (HOPs)",
    "text": "4 Visualising Uncertainty with Hypothetical Outcome Plots (HOPs)\n\n4.1 Installing ungeviz package\n\ndevtools::install_github(\"wilkelab/ungeviz\")\n\n\n\n4.2 Launch the application in R\n\nlibrary(ungeviz)\n\n\n\n4.3 Visualising Uncertainty with Hypothetical Outcome Plots (HOPs)\nNext, the code chunk below will be used to build the HOPs.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = exam, \n       (aes(x = factor(RACE), \n            y = MATHS))) +\n  geom_point(position = position_jitter(\n    height = 0.3, \n    width = 0.05), \n    size = 0.4, \n    color = \"#0072B2\", \n    alpha = 1/2) +\n  geom_hpline(data = sampler(25, \n                             group = RACE), \n              height = 0.6, \n              color = \"#D55E00\") +\n  theme_bw() + \n  transition_states(.draw, 1, 3)"
  },
  {
    "objectID": "Hands-On_Exercise/Hands-On_Exercise05/HE05-1.html",
    "href": "Hands-On_Exercise/Hands-On_Exercise05/HE05-1.html",
    "title": "Hands-On Exercise 05-1",
    "section": "",
    "text": "Ternary plots are a way of displaying the distribution and variability of three-part compositional data. (For example, the proportion of aged, economy active and young population or sand, silt, and clay in soil.) It’s display is a triangle with sides scaled from 0 to 1. Each side represents one of the three components. A point is plotted so that a line drawn perpendicular from the point to each leg of the triangle intersect at the component values of the point.\nIn this hands-on, you will learn how to build ternary plot programmatically using R for visualising and analysing population structure of Singapore.\nThe hands-on exercise consists of four steps:\n\nInstall and launch tidyverse and ggtern packages.\nDerive three new measures using mutate() function of dplyr package.\nBuild a static ternary plot using ggtern() function of ggtern package.\nBuild an interactive ternary plot using plot-ly() function of Plotly R package."
  },
  {
    "objectID": "Hands-On_Exercise/Hands-On_Exercise05/HE05-1.html#overview",
    "href": "Hands-On_Exercise/Hands-On_Exercise05/HE05-1.html#overview",
    "title": "Hands-On Exercise 05-1",
    "section": "",
    "text": "Ternary plots are a way of displaying the distribution and variability of three-part compositional data. (For example, the proportion of aged, economy active and young population or sand, silt, and clay in soil.) It’s display is a triangle with sides scaled from 0 to 1. Each side represents one of the three components. A point is plotted so that a line drawn perpendicular from the point to each leg of the triangle intersect at the component values of the point.\nIn this hands-on, you will learn how to build ternary plot programmatically using R for visualising and analysing population structure of Singapore.\nThe hands-on exercise consists of four steps:\n\nInstall and launch tidyverse and ggtern packages.\nDerive three new measures using mutate() function of dplyr package.\nBuild a static ternary plot using ggtern() function of ggtern package.\nBuild an interactive ternary plot using plot-ly() function of Plotly R package."
  },
  {
    "objectID": "Hands-On_Exercise/Hands-On_Exercise05/HE05-1.html#getting-started",
    "href": "Hands-On_Exercise/Hands-On_Exercise05/HE05-1.html#getting-started",
    "title": "Hands-On Exercise 05-1",
    "section": "1 Getting Started",
    "text": "1 Getting Started\n\n1.1 Installing and launching R packages\nFor this exercise, two main R packages will be used in this hands-on exercise, they are:\n\nggtern, a ggplot extension specially designed to plot ternary diagrams. The package will be used to plot static ternary plots.\nPlotly R, an R package for creating interactive web-based graphs via plotly’s JavaScript graphing library, plotly.js . The plotly R libary contains the ggplotly function, which will convert ggplot2 figures into a Plotly object. We will also need to ensure that selected tidyverse family packages namely: readr, dplyr and tidyr are also installed and loaded.\n\nThe code chunks below will accomplish the task.\n\npacman::p_load(plotly, ggtern, tidyverse)"
  },
  {
    "objectID": "Hands-On_Exercise/Hands-On_Exercise05/HE05-1.html#data-preparation",
    "href": "Hands-On_Exercise/Hands-On_Exercise05/HE05-1.html#data-preparation",
    "title": "Hands-On Exercise 05-1",
    "section": "2 Data Preparation",
    "text": "2 Data Preparation\n\n2.1 The data\nFor the purpose of this hands-on exercise, the Singapore Residents by Planning AreaSubzone, Age Group, Sex and Type of Dwelling, June 2000-2018 data will be used. The data set has been downloaded and included in the data sub-folder of the hands-on exercise folder. It is called respopagsex2000to2018_tidy.csv and is in csv file format.\n\n\n2.2 Importing Data\nTo important respopagsex2000to2018_tidy.csv into R, read_csv() function of readr package will be used.\n\npop_data &lt;- read_csv(\"data/respopagsex2000to2018_tidy.csv\") \n\n\n\n2.3 Preparing the Data\nNext, use the mutate() function of dplyr package to derive three new measures, namely: young, active, and old.\n\n#Deriving the young, economy active and old measures\nagpop_mutated &lt;- pop_data %&gt;%\n  mutate(`Year` = as.character(Year))%&gt;%\n  spread(AG, Population) %&gt;%\n  mutate(YOUNG = rowSums(.[4:8]))%&gt;%\n  mutate(ACTIVE = rowSums(.[9:16]))  %&gt;%\n  mutate(OLD = rowSums(.[17:21])) %&gt;%\n  mutate(TOTAL = rowSums(.[22:24])) %&gt;%\n  filter(Year == 2018)%&gt;%\n  filter(TOTAL &gt; 0)"
  },
  {
    "objectID": "Hands-On_Exercise/Hands-On_Exercise05/HE05-1.html#plotting-ternary-diagram-with-r",
    "href": "Hands-On_Exercise/Hands-On_Exercise05/HE05-1.html#plotting-ternary-diagram-with-r",
    "title": "Hands-On Exercise 05-1",
    "section": "3 Plotting Ternary Diagram with R",
    "text": "3 Plotting Ternary Diagram with R\n\n3.1 Plotting a static ternary diagram\nUse ggtern() function of ggtern package to create a simple ternary plot.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n#Building the static ternary plot\nggtern(data=agpop_mutated,aes(x=YOUNG,y=ACTIVE, z=OLD)) +\n  geom_point()\n\n\n\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n#Building the static ternary plot\nggtern(data=agpop_mutated, aes(x=YOUNG,y=ACTIVE, z=OLD)) +\n  geom_point() +\n  labs(title=\"Population structure, 2015\") +\n  theme_rgbw()\n\n\n\n\n\n\n3.2 Plotting an interative ternary diagram\nThe code below create an interactive ternary plot using plot_ly() function of Plotly R.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n# reusable function for creating annotation object\nlabel &lt;- function(txt) {\n  list(\n    text = txt, \n    x = 0.1, y = 1,\n    ax = 0, ay = 0,\n    xref = \"paper\", yref = \"paper\", \n    align = \"center\",\n    font = list(family = \"serif\", size = 15, color = \"white\"),\n    bgcolor = \"#b3b3b3\", bordercolor = \"black\", borderwidth = 2\n  )\n}\n\n# reusable function for axis formatting\naxis &lt;- function(txt) {\n  list(\n    title = txt, tickformat = \".0%\", tickfont = list(size = 10)\n  )\n}\n\nternaryAxes &lt;- list(\n  aaxis = axis(\"Young\"), \n  baxis = axis(\"Active\"), \n  caxis = axis(\"Old\")\n)\n\n# Initiating a plotly visualization \nplot_ly(\n  agpop_mutated, \n  a = ~YOUNG, \n  b = ~ACTIVE, \n  c = ~OLD, \n  color = I(\"black\"), \n  type = \"scatterternary\"\n) %&gt;%\n  layout(\n    annotations = label(\"Ternary Markers\"), \n    ternary = ternaryAxes\n  )"
  },
  {
    "objectID": "Hands-On_Exercise/Hands-On_Exercise05/HE05-3.html",
    "href": "Hands-On_Exercise/Hands-On_Exercise05/HE05-3.html",
    "title": "Hands-On Exercise 05-3",
    "section": "",
    "text": "Heatmaps visualise data through variations in colouring. When applied to a tabular format, heatmaps are useful for cross-examining multivariate data, through placing variables in the columns and observation (or records) in rowa and colouring the cells within the table. Heatmaps are good for showing variance across multiple variables, revealing any patterns, displaying whether any variables are similar to each other, and for detecting if any correlations exist in-between them.\nIn this hands-on exercise, you will gain hands-on experience on using R to plot static and interactive heatmap for visualising and analysing multivariate data."
  },
  {
    "objectID": "Hands-On_Exercise/Hands-On_Exercise05/HE05-3.html#overview",
    "href": "Hands-On_Exercise/Hands-On_Exercise05/HE05-3.html#overview",
    "title": "Hands-On Exercise 05-3",
    "section": "",
    "text": "Heatmaps visualise data through variations in colouring. When applied to a tabular format, heatmaps are useful for cross-examining multivariate data, through placing variables in the columns and observation (or records) in rowa and colouring the cells within the table. Heatmaps are good for showing variance across multiple variables, revealing any patterns, displaying whether any variables are similar to each other, and for detecting if any correlations exist in-between them.\nIn this hands-on exercise, you will gain hands-on experience on using R to plot static and interactive heatmap for visualising and analysing multivariate data."
  },
  {
    "objectID": "Hands-On_Exercise/Hands-On_Exercise05/HE05-3.html#getting-started",
    "href": "Hands-On_Exercise/Hands-On_Exercise05/HE05-3.html#getting-started",
    "title": "Hands-On Exercise 05-3",
    "section": "1 Getting Started",
    "text": "1 Getting Started\n\n1.1 Installing and launching R packages\nBefore you get started, you are required to open a new Quarto document. Keep the default html as the authoring format.\nNext, you will use the code chunk below to install and launch seriation, heatmaply, dendextend and tidyverse in RStudio.\n\npacman::p_load(seriation, dendextend, heatmaply, tidyverse)"
  },
  {
    "objectID": "Hands-On_Exercise/Hands-On_Exercise05/HE05-3.html#importing-and-preparing-the-data-set",
    "href": "Hands-On_Exercise/Hands-On_Exercise05/HE05-3.html#importing-and-preparing-the-data-set",
    "title": "Hands-On Exercise 05-3",
    "section": "2 Importing and Preparing The Data Set",
    "text": "2 Importing and Preparing The Data Set\nIn this hands-on exercise, the data of World Happines 2018 report will be used. The data set is downloaded from here. The original data set is in Microsoft Excel format. It has been extracted and saved in csv file called WHData-2018.csv.\n\n2.1 Importing the data set\nIn the code chunk below, read_csv() of readr is used to import WHData-2018.csv into R and parsed it into tibble R data frame format.\n\nwh &lt;- read_csv(\"data/WHData-2018.csv\")\n\nThe output tibbled data frame is called wh.\n\n\n2.2 Preparing the data\nNext, we need to change the rows by country name instead of row number by using the code chunk below\n\nrow.names(wh) &lt;- wh$Country\n\nNotice that the row number has been replaced into the country name.\n\n\n2.3 Transforming the data frame into a matrix\nThe data was loaded into a data frame, but it has to be a data matrix to make your heatmap. The code chunk below will be used to transform wh data frame into a data matrix.\n\nwh1 &lt;- dplyr::select(wh, c(3, 7:12))\nwh_matrix &lt;- data.matrix(wh)\n\nNotice that wh_matrix is in R matrix format."
  },
  {
    "objectID": "Hands-On_Exercise/Hands-On_Exercise05/HE05-3.html#static-heatmap",
    "href": "Hands-On_Exercise/Hands-On_Exercise05/HE05-3.html#static-heatmap",
    "title": "Hands-On Exercise 05-3",
    "section": "3 Static Heatmap",
    "text": "3 Static Heatmap\n\n3.1 Introduction\nThere are many R packages and functions can be used to drawing static heatmaps, they are:\n\nheatmap()of R stats package. It draws a simple heatmap.\nheatmap.2() of gplots R package. It draws an enhanced heatmap compared to the R base function.\npheatmap() of pheatmap R package. pheatmap package also known as Pretty Heatmap. The package provides functions to draws pretty heatmaps and provides more control to change the appearance of heatmaps.\nComplexHeatmap package of R/Bioconductor package. The package draws, annotates and arranges complex heatmaps (very useful for genomic data analysis). The full reference guide of the package is available here.\nsuperheat package: A Graphical Tool for Exploring Complex Datasets Using Heatmaps. A system for generating extendable and customizable heatmaps for exploring complex datasets, including big data and data with multiple data types. The full reference guide of the package is available here.\n\nIn this section, you will learn how to plot static heatmaps by using heatmap() of R Stats package.\n\n\n3.2 heatmap() of R Stats\nIn this sub-section, we will plot a heatmap by using heatmap() of Base Stats. The code chunk is given below.\n\nwh_heatmap &lt;- heatmap(wh_matrix,\n                      Rowv=NA, Colv=NA)\n\n\n\n\n\n\n\n\nBy default, heatmap() plots a cluster heatmap. The arguments Rowv=NA and Colv=NA are used to switch off the option of plotting the row and column dendrograms.\nTo plot a cluster heatmap, we just have to use the default as shown in the code chunk below.\n\nwh_heatmap &lt;- heatmap(wh_matrix)\n\n\n\n\n\n\n\n\nThe order of both rows and columns is different compare to the native wh_matrix. This is because heatmap do a reordering using clusterisation: it calculates the distance between each pair of rows and columns and try to order them by similarity. Moreover, the corresponding dendrogram are provided beside the heatmap.\nHere, red cells denotes small values, and red small ones. This heatmap is not really informative. Indeed, the Happiness Score variable have relatively higher values, what makes that the other variables with small values all look the same. Thus, we need to normalize this matrix. This is done using the scale argument. It can be applied to rows or to columns following your needs.\nThe code chunk below normalises the matrix column-wise.\n\nwh_heatmap &lt;- heatmap(wh_matrix,\n                      scale=\"column\",\n                      cexRow = 0.6, \n                      cexCol = 0.8,\n                      margins = c(10, 4))\n\n\n\n\n\n\n\n\nNotice that the values are scaled now. Also note that margins argument is used to ensure that the entire x-axis labels are displayed completely and, cexRow and cexCol arguments are used to define the font size used for y-axis and x-axis labels respectively."
  },
  {
    "objectID": "Hands-On_Exercise/Hands-On_Exercise05/HE05-3.html#creating-interactive-heatmap",
    "href": "Hands-On_Exercise/Hands-On_Exercise05/HE05-3.html#creating-interactive-heatmap",
    "title": "Hands-On Exercise 05-3",
    "section": "4 Creating Interactive Heatmap",
    "text": "4 Creating Interactive Heatmap\n\n4.1 Introduction\nheatmaply is an R package for building interactive cluster heatmap that can be shared online as a stand-alone HTML file. It is designed and maintained by Tal Galili.\nBefore we get started, you should review the Introduction to Heatmaply to have an overall understanding of the features and functions of Heatmaply package. You are also required to have the user manualof the package handy with you for reference purposes.\nIn this section, you will gain hands-on experience on using heatmaply to design an interactive cluster heatmap. We will still use the wh_matrix as the input data.\n\n\n4.2 Working with heatmaply\n\nheatmaply(mtcars)\n\n\n\n\n\nThe code chunk below shows the basic syntax needed to create n interactive heatmap by using heatmaply package.\n\nheatmaply(wh_matrix[, -c(1, 2, 4, 5)])\n\n\n\n\n\n\nDifferent from heatmap(), for heatmaply() the default horizontal dendrogram is placed on the left hand side of the heatmap.\nThe text label of each raw, on the other hand, is placed on the right hand side of the heat map.\nWhen the x-axis marker labels are too long, they will be rotated by 135 degree from the north.\n\n\n\n4.3 Data trasformation\nWhen analysing multivariate data set, it is very common that the variables in the data sets includes values that reflect different types of measurement. In general, these variables’ values have their own range. In order to ensure that all the variables have comparable values, data transformation are commonly used before clustering.\nThree main data transformation methods are supported by heatmaply(), namely: scale, normalise and percentilse.\n\n4.3.1 Scaling method\n\nWhen all variables are came from or assumed to come from some normal distribution, then scaling (i.e.: subtract the mean and divide by the standard deviation) would bring them all close to the standard normal distribution.\nIn such a case, each value would reflect the distance from the mean in units of standard deviation.\nThe scale argument in heatmaply() supports column and row scaling.\n\nThe code chunk below is used to scale variable values columewise.\n\nheatmaply(wh_matrix[, -c(1, 2, 4, 5)],\n          scale = \"column\")\n\n\n\n\n\n\n\n4.3.2 Normalising method\n\nWhen variables in the data comes from possibly different (and non-normal) distributions, the normalize function can be used to bring data to the 0 to 1 scale by subtracting the minimum and dividing by the maximum of all observations.\nThis preserves the shape of each variable’s distribution while making them easily comparable on the same “scale”.\n\nDifferent from Scaling, the normalise method is performed on the input data set i.e. wh_matrix as shown in the code chunk below.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]))\n\n\n\n\n\n\n\n4.3.3 Percentising method\n\nThis is similar to ranking the variables, but instead of keeping the rank values, divide them by the maximal rank.\nThis is done by using the ecdf of the variables on their own values, bringing each value to its empirical percentile.\nThe benefit of the percentize function is that each value has a relatively clear interpretation, it is the percent of observations that got that value or below it.\n\nSimilar to Normalize method, the Percentize method is also performed on the input data set i.e. wh_matrix as shown in the code chunk below.\n\nheatmaply(percentize(wh_matrix[, -c(1, 2, 4, 5)]))\n\n\n\n\n\n\n\n\n4.4 Clustering algorithm\nheatmaply supports a variety of hierarchical clustering algorithm. The main arguments provided are:\n\ndistfun: function used to compute the distance (dissimilarity) between both rows and columns. Defaults to dist. The options “pearson”, “spearman” and “kendall” can be used to use correlation-based clustering, which uses as.dist(1 - cor(t(x))) as the distance metric (using the specified correlation method).\nhclustfun: function used to compute the hierarchical clustering when Rowv or Colv are not dendrograms. Defaults to hclust.\ndist_method default is NULL, which results in “euclidean” to be used. It can accept alternative character strings indicating the method to be passed to distfun. By default distfun is “dist”” hence this can be one of “euclidean”, “maximum”, “manhattan”, “canberra”, “binary” or “minkowski”.\nhclust_method default is NULL, which results in “complete” method to be used. It can accept alternative character strings indicating the method to be passed to hclustfun. By default hclustfun is hclust hence this can be one of “ward.D”, “ward.D2”, “single”, “complete”, “average” (= UPGMA), “mcquitty” (= WPGMA), “median” (= WPGMC) or “centroid” (= UPGMC).\n\nIn general, a clustering model can be calibrated either manually or statistically.\n\n\n4.5 Manual approach\nIn the code chunk below, the heatmap is plotted by using hierachical clustering algorithm with “Euclidean distance” and “ward.D” method.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          dist_method = \"euclidean\",\n          hclust_method = \"ward.D\")\n\n\n\n\n\n\n\n4.6 Statistical approach\nIn order to determine the best clustering method and number of cluster the dend_expend() and find_k() functions of dendextend package will be used.\nFirst, the dend_expend() will be used to determine the recommended clustering method to be used.\n\nwh_d &lt;- dist(normalize(wh_matrix[, -c(1, 2, 4, 5)]), method = \"euclidean\")\ndend_expend(wh_d)[[3]]\n\n  dist_methods hclust_methods     optim\n1      unknown         ward.D 0.6137851\n2      unknown        ward.D2 0.6289186\n3      unknown         single 0.4774362\n4      unknown       complete 0.6434009\n5      unknown        average 0.6701688\n6      unknown       mcquitty 0.5020102\n7      unknown         median 0.5901833\n8      unknown       centroid 0.6338734\n\n\nThe output table shows that “average” method should be used because it gave the high optimum value.\nNext, find_k() is used to determine the optimal number of cluster.\n\nwh_clust &lt;- hclust(wh_d, method = \"average\")\nnum_k &lt;- find_k(wh_clust)\nplot(num_k)\n\n\n\n\n\n\n\n\nFigure above shows that k=3 would be good.\nWith reference to the statistical analysis results, we can prepare the code chunk as shown below.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          dist_method = \"euclidean\",\n          hclust_method = \"average\",\n          k_row = 3)"
  },
  {
    "objectID": "Hands-On_Exercise/Hands-On_Exercise05/HE05-3.html#seriation",
    "href": "Hands-On_Exercise/Hands-On_Exercise05/HE05-3.html#seriation",
    "title": "Hands-On Exercise 05-3",
    "section": "5 Seriation",
    "text": "5 Seriation\nOne of the problems with hierarchical clustering is that it doesn’t actually place the rows in a definite order, it merely constrains the space of possible orderings. Take three items A, B and C. If you ignore reflections, there are three possible orderings: ABC, ACB, BAC. If clustering them gives you ((A+B)+C) as a tree, you know that C can’t end up between A and B, but it doesn’t tell you which way to flip the A+B cluster. It doesn’t tell you if the ABC ordering will lead to a clearer-looking heatmap than the BAC ordering.\nheatmaply uses the seriation package to find an optimal ordering of rows and columns. Optimal means to optimize the Hamiltonian path length that is restricted by the dendrogram structure. This, in other words, means to rotate the branches so that the sum of distances between each adjacent leaf (label) will be minimized. This is related to a restricted version of the travelling salesman problem.\nHere we meet our first seriation algorithm: Optimal Leaf Ordering (OLO). This algorithm starts with the output of an agglomerative clustering algorithm and produces a unique ordering, one that flips the various branches of the dendrogram around so as to minimize the sum of dissimilarities between adjacent leaves. Here is the result of applying Optimal Leaf Ordering to the same clustering result as the heatmap above.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"OLO\")\n\n\n\n\n\nThe default options is “OLO” (Optimal leaf ordering) which optimizes the above criterion (in O(n^4)). Another option is “GW” (Gruvaeus and Wainer) which aims for the same goal but uses a potentially faster heuristic.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"GW\")\n\n\n\n\n\nThe option “mean” gives the output we would get by default from heatmap functions in other packages such as gplots::heatmap.2.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"mean\")\n\n\n\n\n\nThe option “none” gives us the dendrograms without any rotation that is based on the data matrix.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"none\")"
  },
  {
    "objectID": "Hands-On_Exercise/Hands-On_Exercise05/HE05-3.html#working-with-colour-palettes",
    "href": "Hands-On_Exercise/Hands-On_Exercise05/HE05-3.html#working-with-colour-palettes",
    "title": "Hands-On Exercise 05-3",
    "section": "6 Working with colour palettes",
    "text": "6 Working with colour palettes\nThe default colour palette uses by heatmaply is viridis. heatmaply users, however, can use other colour palettes in order to improve the aestheticness and visual friendliness of the heatmap.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"none\",\n          colors = Blues)"
  },
  {
    "objectID": "Hands-On_Exercise/Hands-On_Exercise05/HE05-3.html#the-finishing-touch",
    "href": "Hands-On_Exercise/Hands-On_Exercise05/HE05-3.html#the-finishing-touch",
    "title": "Hands-On Exercise 05-3",
    "section": "7 The finishing touch",
    "text": "7 The finishing touch\nBeside providing a wide collection of arguments for meeting the statistical analysis needs, heatmaply also provides many plotting features to ensure cartographic quality heatmap can be produced.\nIn the code chunk below the following arguments are used:\n\nk_row is used to produce 5 groups.\nmargins is used to change the top margin to 60 and row margin to 200.\nfontsizw_row and fontsize_col are used to change the font size for row and column labels to 4.\nmain is used to write the main title of the plot.\nxlab and ylab are used to write the x-axis and y-axis labels respectively.\n\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          Colv=NA,\n          seriate = \"none\",\n          colors = Blues,\n          k_row = 5,\n          margins = c(NA,200,60,NA),\n          fontsize_row = 4,\n          fontsize_col = 5,\n          main=\"World Happiness Score and Variables by Country, 2018 \\nDataTransformation using Normalise Method\",\n          xlab = \"World Happiness Indicators\",\n          ylab = \"World Countries\"\n          )"
  },
  {
    "objectID": "In-Class_Exercise/In-Class_Exercise01/IE01.html",
    "href": "In-Class_Exercise/In-Class_Exercise01/IE01.html",
    "title": "In-Class Exercise 01",
    "section": "",
    "text": "This session utilizes Tableau to explore the logic behind constructing fundamental visualizations. The primary focus is on temporal dimension analysis: practicing the ability to switch between different time scales (Year/Month/Day) through drill-down functions. By adjusting the granularity of time, we can more accurately identify performance variances across different periods, thereby enhancing our capacity to interpret business trends.\n\n\n\nDashboard"
  },
  {
    "objectID": "In-Class_Exercise/In-Class_Exercise01/IE01.html#overview",
    "href": "In-Class_Exercise/In-Class_Exercise01/IE01.html#overview",
    "title": "In-Class Exercise 01",
    "section": "",
    "text": "This session utilizes Tableau to explore the logic behind constructing fundamental visualizations. The primary focus is on temporal dimension analysis: practicing the ability to switch between different time scales (Year/Month/Day) through drill-down functions. By adjusting the granularity of time, we can more accurately identify performance variances across different periods, thereby enhancing our capacity to interpret business trends.\n\n\n\nDashboard"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Visual Analytics and Applications",
    "section": "",
    "text": "Welcome to ISSS608 Visual Analytics and Applications homepage. In this website, you will find my coursework. Materials here are based on https://isss608-ay2025-26apr.netlify.app/ by Prof Kam Tin Seong from SMU.\nOverview:"
  },
  {
    "objectID": "index.html#hands-on-exercise",
    "href": "index.html#hands-on-exercise",
    "title": "Visual Analytics and Applications",
    "section": "Hands On Exercise",
    "text": "Hands On Exercise\n\n\n\n\n\n\n\n\n\nHands-On Exercise 01\n\n\n\nChun-Han\n\n\nJan 12, 2026\n\n\n\n\n\n\n\n\n\n\n\nHands-On Exercise 02\n\n\n\nChun-Han\n\n\nJan 19, 2026\n\n\n\n\n\n\n\n\n\n\n\nHands-On Exercise 03-1\n\n\n\nChun-Han\n\n\nJan 24, 2026\n\n\n\n\n\n\n\n\n\n\n\nHands-On Exercise 03-2\n\n\n\nChun-Han\n\n\nJan 24, 2026\n\n\n\n\n\n\n\n\n\n\n\nHands-On Exercise 04-1\n\n\n\nChun-Han\n\n\nJan 31, 2026\n\n\n\n\n\n\n\n\n\n\n\nHands-On Exercise 04-2\n\n\n\nChun-Han\n\n\nJan 31, 2026\n\n\n\n\n\n\n\n\n\n\n\nHands-On Exercise 04-3\n\n\n\nChun-Han\n\n\nFeb 1, 2026\n\n\n\n\n\n\n\n\n\n\n\nHands-On Exercise 04-4\n\n\n\nChun-Han\n\n\nFeb 1, 2026\n\n\n\n\n\n\n\n\n\n\n\nHands-On Exercise 05-1\n\n\n\nChun-Han\n\n\nFeb 8, 2026\n\n\n\n\n\n\n\n\n\n\n\nHands-On Exercise 05-2\n\n\n\nChun-Han\n\n\nFeb 8, 2026\n\n\n\n\n\n\n\n\n\n\n\nHands-On Exercise 05-3\n\n\n\nChun-Han\n\n\nFeb 8, 2026\n\n\n\n\n\n\n\n\n\n\n\nHands-On Exercise 05-4\n\n\n\nChun-Han\n\n\nFeb 8, 2026\n\n\n\n\n\n\n\n\n\n\n\nHands-On Exercise 05-5\n\n\n\nChun-Han\n\n\nFeb 8, 2026\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#in-class-exercise",
    "href": "index.html#in-class-exercise",
    "title": "Visual Analytics and Applications",
    "section": "In Class Exercise",
    "text": "In Class Exercise\n\n\n\n\n\n\n\n\n\nIn-Class Exercise 01\n\n\n\nChun-Han\n\n\nJan 25, 2026\n\n\n\n\n\n\n\n\n\n\n\nIn-Class Exercise 02\n\n\n\nChun-Han\n\n\nJan 25, 2026\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#take-home-exercise",
    "href": "index.html#take-home-exercise",
    "title": "Visual Analytics and Applications",
    "section": "Take Home Exercise",
    "text": "Take Home Exercise\n\n\n\n\n\n\n\n\n\nTake-Home Exercise 01\n\n\n\nChun-Han\n\n\nFeb 2, 2026\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "Hands-On_Exercise/Hands-On_Exercise05/HE05-5.html",
    "href": "Hands-On_Exercise/Hands-On_Exercise05/HE05-5.html",
    "title": "Hands-On Exercise 05-5",
    "section": "",
    "text": "In this hands-on exercise, you will gain hands-on experiences on designing treemap using appropriate R packages. The hands-on exercise consists of three main section. First, you will learn how to manipulate transaction data into a treemap strcuture by using selected functions provided in dplyr package. Then, you will learn how to plot static treemap by using treemap package. In the third section, you will learn how to design interactive treemap by using d3treeR package."
  },
  {
    "objectID": "Hands-On_Exercise/Hands-On_Exercise05/HE05-5.html#overview",
    "href": "Hands-On_Exercise/Hands-On_Exercise05/HE05-5.html#overview",
    "title": "Hands-On Exercise 05-5",
    "section": "",
    "text": "In this hands-on exercise, you will gain hands-on experiences on designing treemap using appropriate R packages. The hands-on exercise consists of three main section. First, you will learn how to manipulate transaction data into a treemap strcuture by using selected functions provided in dplyr package. Then, you will learn how to plot static treemap by using treemap package. In the third section, you will learn how to design interactive treemap by using d3treeR package."
  },
  {
    "objectID": "Hands-On_Exercise/Hands-On_Exercise05/HE05-5.html#getting-started",
    "href": "Hands-On_Exercise/Hands-On_Exercise05/HE05-5.html#getting-started",
    "title": "Hands-On Exercise 05-5",
    "section": "1 Getting Started",
    "text": "1 Getting Started\n\n1.1 Installing and Launching R Packages\nBefore we get started, you are required to check if treemap and tidyverse pacakges have been installed in you R.\n\npacman::p_load(treemap, treemapify, tidyverse) \n\n\n\n1.2 Data Wrangling\nIn this exercise, REALIS2018.csv data will be used. This dataset provides information of private property transaction records in 2018. The dataset is extracted from REALIS portal (https://spring.ura.gov.sg/lad/ore/login/index.cfm) of Urban Redevelopment Authority (URA).\n\n1.2.1 Importing the data set\nIn the code chunk below, read_csv() of readr is used to import realis2018.csv into R and parsed it into tibble R data.frame format.\n\nrealis2018 &lt;- read_csv(\"data/realis2018.csv\")\n\nThe output tibble data.frame is called realis2018.\n\n\n1.2.2 Data Wrangling and Manipulation\nThe data.frame realis2018 is in trasaction record form, which is highly disaggregated and not appropriate to be used to plot a treemap. In this section, we will perform the following steps to manipulate and prepare a data.frtame that is appropriate for treemap visualisation:\n\ngroup transaction records by Project Name, Planning Region, Planning Area, Property Type and Type of Sale, and\ncompute Total Unit Sold, Total Area, Median Unit Price and Median Transacted Price by applying appropriate summary statistics on No. of Units, Area (sqm), Unit Price ($ psm) and Transacted Price ($) respectively.\n\nTwo key verbs of dplyr package, namely: group_by() and summarize() will be used to perform these steps.\ngroup_by() breaks down a data.frame into specified groups of rows. When you then apply the verbs above on the resulting object they’ll be automatically applied “by group”.\nGrouping affects the verbs as follows:\n\ngrouped select() is the same as ungrouped select(), except that grouping variables are always retained.\ngrouped arrange() is the same as ungrouped; unless you set .by_group = TRUE, in which case it orders first by the grouping variables.\nmutate() and filter() are most useful in conjunction with window functions (like rank(), or min(x) == x). They are described in detail in vignette(“window-functions”).\nsample_n() and sample_frac() sample the specified number/fraction of rows in each group.\nsummarise() computes the summary for each group.\n\nIn our case, group_by() will used together with summarise() to derive the summarised data.frame.\n\nStudents who are new to dplyr methods should consult Introduction to dplyr before moving on to the next section.\n\n\n\n1.2.3 Grouped summaries without the Pipe\nThe code chank below shows a typical two lines code approach to perform the steps.\n\nrealis2018_grouped &lt;- group_by(realis2018, `Project Name`,\n                               `Planning Region`, `Planning Area`, \n                               `Property Type`, `Type of Sale`)\nrealis2018_summarised &lt;- summarise(realis2018_grouped, \n                          `Total Unit Sold` = sum(`No. of Units`, na.rm = TRUE),\n                          `Total Area` = sum(`Area (sqm)`, na.rm = TRUE),\n                          `Median Unit Price ($ psm)` = median(`Unit Price ($ psm)`, na.rm = TRUE), \n                          `Median Transacted Price` = median(`Transacted Price ($)`, na.rm = TRUE))\n\n\nAggregation functions such as sum() and meadian() obey the usual rule of missing values: if there’s any missing value in the input, the output will be a missing value. The argument na.rm = TRUE removes the missing values prior to computation.\n\nThe code chunk above is not very efficient because we have to give each intermediate data.frame a name, even though we don’t have to care about it.\n\n\n1.2.4 Grouped summaries with the pipe\nThe code chunk below shows a more efficient way to tackle the same processes by using the pipe, %&gt;%:\n\nTo learn more about pipe, visit this excellent article: Pipes in R Tutorial For Beginners.\n\n\nrealis2018_summarised &lt;- realis2018 %&gt;% \n  group_by(`Project Name`,`Planning Region`, \n           `Planning Area`, `Property Type`, \n           `Type of Sale`) %&gt;%\n  summarise(`Total Unit Sold` = sum(`No. of Units`, na.rm = TRUE), \n            `Total Area` = sum(`Area (sqm)`, na.rm = TRUE),\n            `Median Unit Price ($ psm)` = median(`Unit Price ($ psm)`, na.rm = TRUE),\n            `Median Transacted Price` = median(`Transacted Price ($)`, na.rm = TRUE))"
  },
  {
    "objectID": "Hands-On_Exercise/Hands-On_Exercise05/HE05-5.html#designing-treemap-with-treemap-package",
    "href": "Hands-On_Exercise/Hands-On_Exercise05/HE05-5.html#designing-treemap-with-treemap-package",
    "title": "Hands-On Exercise 05-5",
    "section": "2 Designing Treemap with treemap Package",
    "text": "2 Designing Treemap with treemap Package\ntreemap package is a R package specially designed to offer great flexibility in drawing treemaps. The core function, namely: treemap() offers at least 43 arguments. In this section, we will only explore the major arguments for designing elegent and yet truthful treemaps.\n\n2.1 Designing a static treemap\nIn this section, treemap() of Treemap package is used to plot a treemap showing the distribution of median unit prices and total unit sold of resale condominium by geographic hierarchy in 2017.\nFirst, we will select records belongs to resale condominium property type from realis2018_selected data frame.\n\nrealis2018_selected &lt;- realis2018_summarised %&gt;%\n  filter(`Property Type` == \"Condominium\", `Type of Sale` == \"Resale\")\n\n\n\n2.2 Using the basic arguments\nThe code chunk below designed a treemap by using three core arguments of treemap(), namely: index, vSize and vColor.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\nThings to learn from the three arguments used:\n\nindex\n\nThe index vector must consist of at least two column names or else no hierarchy treemap will be plotted.\nIf multiple column names are provided, such as the code chunk above, the first name is the highest aggregation level, the second name the second highest aggregation level, and so on.\n\nvSize\n\nThe column must not contain negative values. This is because it’s vaues will be used to map the sizes of the rectangles of the treemaps. Warning:\nThe treemap above was wrongly coloured. For a correctly designed treemap, the colours of the rectagles should be in different intensity showing, in our case, median unit prices.\nFor treemap(), vColor is used in combination with the argument type to determines the colours of the rectangles. Without defining type, like the code chunk above, treemap() assumes type = index, in our case, the hierarchy of planning areas.\n\n\n2.3 Working with vColor and type arguments\nIn the code chunk below, type argument is define as value.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type = \"value\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\nThinking to learn from the conde chunk above.\n\nThe rectangles are coloured with different intensity of green, reflecting their respective median unit prices.\nThe legend reveals that the values are binned into ten bins, i.e. 0-5000, 5000-10000, etc. with an equal interval of 5000.\n\n\n\n2.4 Colours in treemap package\nThere are two arguments that determine the mapping to color palettes: mapping and palette. The only difference between “value” and “manual” is the default value for mapping. The “value” treemap considers palette to be a diverging color palette (say ColorBrewer’s “RdYlBu”), and maps it in such a way that 0 corresponds to the middle color (typically white or yellow), -max(abs(values)) to the left-end color, and max(abs(values)), to the right-end color. The “manual” treemap simply maps min(values) to the left-end color, max(values) to the right-end color, and mean(range(values)) to the middle color.\n\n\n2.5 The “value” type treemap\nThe code chunk below shows a value type treemap.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"value\",\n        palette=\"RdYlBu\", \n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\nThing to learn from the code chunk above:\n\nalthough the colour palette used is RdYlBu but there are no red rectangles in the treemap above. This is because all the median unit prices are positive.\nThe reason why we see only 5000 to 45000 in the legend is because the range argument is by default c(min(values, max(values)) with some pretty rounding.\n\n\n\n2.6 The “manual” type treemap\nThe “manual” type does not interpret the values as the “value” type does. Instead, the value range is mapped linearly to the colour palette.\nThe code chunk below shows a manual type treemap.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"RdYlBu\", \n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\nThe colour scheme used is very copnfusing. This is because mapping = (min(values), mean(range(values)), max(values)). It is not wise to use diverging colour palette such as RdYlBu if the values are all positive or negative\n\nTo overcome this problem, a single colour palette such as Blues should be used.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"Blues\", \n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\n\n\n2.7 Treemap Layout\ntreemap() supports two popular treemap layouts, namely: “squarified” and “pivotSize”. The default is “pivotSize”.\nThe squarified treemap algorithm (Bruls et al., 2000) produces good aspect ratios, but ignores the sorting order of the rectangles (sortID). The ordered treemap, pivot-by-size, algorithm (Bederson et al., 2002) takes the sorting order (sortID) into account while aspect ratios are still acceptable.\n\n\n2.8 Working with algorithm argument\nThe code chunk below plots a squarified treemap by changing the algorithm argument.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"Blues\", \n        algorithm = \"squarified\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\n\n\n2.9 Using sortID\nWhen “pivotSize” algorithm is used, sortID argument can be used to dertemine the order in which the rectangles are placed from top left to bottom right.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"Blues\", \n        algorithm = \"pivotSize\",\n        sortID = \"Median Transacted Price\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )"
  },
  {
    "objectID": "Hands-On_Exercise/Hands-On_Exercise05/HE05-5.html#designing-treemap-using-treemapify-package",
    "href": "Hands-On_Exercise/Hands-On_Exercise05/HE05-5.html#designing-treemap-using-treemapify-package",
    "title": "Hands-On Exercise 05-5",
    "section": "3 Designing Treemap using treemapify Package",
    "text": "3 Designing Treemap using treemapify Package\ntreemapify is a R package specially developed to draw treemaps in ggplot2. In this section, you will learn how to designing treemps closely resemble treemaps designing in previous section by using treemapify. Before you getting started, you should read Introduction to “treemapify” its user guide.\n\n3.1 Designing a basic treemap\n\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`),\n       layout = \"scol\",\n       start = \"bottomleft\") + \n  geom_treemap() +\n  scale_fill_gradient(low = \"light blue\", high = \"blue\")\n\n\n\n\n\n\n\n\n\n\n3.2 Defining hierarchy\nGroup by Planning Region\n\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`),\n       start = \"topleft\") + \n  geom_treemap()\n\n\n\n\n\n\n\n\nGroup by Planning Area\n\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`,\n           subgroup2 = `Planning Area`)) + \n  geom_treemap()\n\n\n\n\n\n\n\n\nAdding boundary line\n\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`,\n           subgroup2 = `Planning Area`)) + \n  geom_treemap() +\n  geom_treemap_subgroup2_border(colour = \"gray40\",\n                                size = 2) +\n  geom_treemap_subgroup_border(colour = \"gray20\")"
  },
  {
    "objectID": "Hands-On_Exercise/Hands-On_Exercise05/HE05-5.html#designing-interactive-treemap-using-d3treer",
    "href": "Hands-On_Exercise/Hands-On_Exercise05/HE05-5.html#designing-interactive-treemap-using-d3treer",
    "title": "Hands-On Exercise 05-5",
    "section": "4 Designing Interactive Treemap using d3treeR",
    "text": "4 Designing Interactive Treemap using d3treeR\n\n4.1 Installing d3treeR package\nThis slide shows you how to install a R package which is not available in cran.\n\nIf this is the first time you install a package from github, you should install devtools package by using the code below or else you can skip this step.\n\n\n#install.packages(\"devtools\")\n\n\nNext, you will load the devtools library and install the package found in github by using the codes below.\n\n\nlibrary(devtools)\ninstall_github(\"timelyportfolio/d3treeR\")\n\n\nNow you are ready to launch d3treeR package\n\n\nlibrary(d3treeR)\n\n\n\n4.2 Designing An Interactive Treemap\nThe codes below perform two processes.\n\ntreemap() is used to build a treemap by using selected variables in condominium data.frame. The treemap created is save as object called tm.\n\n\ntm &lt;- treemap(realis2018_summarised,\n        index=c(\"Planning Region\", \"Planning Area\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"value\",\n        title=\"Private Residential Property Sold, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\n\nThen d3tree() is used to build an interactive treemap.\n\n\nd3tree(tm,rootname = \"Singapore\" )"
  }
]